{"version":3,"file":"index.js","sources":["../../$browser_shim$chalk","../../src/node/constants.ts","../../src/node/utils.ts","../../../../node_modules/.pnpm/mime@3.0.0/node_modules/mime/Mime.js","../../../../node_modules/.pnpm/mime@3.0.0/node_modules/mime/types/standard.js","../../../../node_modules/.pnpm/mime@3.0.0/node_modules/mime/lite.js","../../src/node/plugins/asset.ts","../../$browser_shim$fast-glob","../../$browser_shim$postcss-load-config","../../src/node/plugins/css.ts","../../src/node/importGlob.ts","../../src/node/plugins/importAnalysisBuild.ts","../../src/node/plugins/html.ts","../../src/node/plugins/esbuild.ts","../../src/node/packages.ts","../../src/node/plugins/resolve.ts","../../src/node/ssr/ssrExternal.ts","../../src/node/server/middlewares/error.ts","../../src/node/server/pluginContainer.ts","../../src/node/optimizer/scan.ts","../../src/node/build.ts","../../src/node/ssr/ssrTransform.ts","../../src/node/server/sourcemap.ts","../../src/node/server/middlewares/indexHtml.ts","../../src/node/server/middlewares/static.ts","../../src/node/server/transformRequest.ts","../../src/node/server/moduleGraph.ts","../../src/node/server/hmr.ts","../../src/node/ssr/ssrStacktrace.ts","../../src/node/optimizer/registerMissing.ts","../../src/node/plugins/json.ts","../../src/node/plugins/importAnalysis.ts","../../src/node/plugins/clientInjections.ts","../../src/node/plugins/wasm.ts","../../src/node/plugins/define.ts","../../src/node/config.ts","../../src/browser/plugins/resolve.ts","../../src/browser/plugins/preAlias.ts","../../src/browser/plugins/index.ts","../../src/browser/server/index.ts","../../src/browser/config.ts","../../src/browser/server/hmr.ts","../../src/browser/ssr/ssrModuleLoader.ts"],"sourcesContent":["const p = new Proxy(s=>s, { get() {return p;}});export default p;","import path from 'path'\n\nexport const DEFAULT_MAIN_FIELDS = [\n  'module',\n  'jsnext:main', // moment still uses this...\n  'jsnext'\n]\n\nexport const DEFAULT_EXTENSIONS = [\n  '.mjs',\n  '.js',\n  '.ts',\n  '.jsx',\n  '.tsx',\n  '.json'\n]\n\nexport const JS_TYPES_RE = /\\.(?:j|t)sx?$|\\.mjs$/\n\nexport const OPTIMIZABLE_ENTRY_RE = /\\.(?:m?js|ts)$/\n\nexport const SPECIAL_QUERY_RE = /[\\?&](?:worker|sharedworker|raw|url)\\b/\n\n/**\n * Prefix for resolved fs paths, since windows paths may not be valid as URLs.\n */\nexport const FS_PREFIX = `/@fs/`\n\n/**\n * Prefix for resolved Ids that are not valid browser import specifiers\n */\nexport const VALID_ID_PREFIX = `/@id/`\n\n/**\n * Plugins that use 'virtual modules' (e.g. for helper functions), prefix the\n * module ID with `\\0`, a convention from the rollup ecosystem.\n * This prevents other plugins from trying to process the id (like node resolution),\n * and core features like sourcemaps can use this info to differentiate between\n * virtual modules and regular files.\n * `\\0` is not a permitted char in import URLs so we have to replace them during\n * import analysis. The id will be decoded back before entering the plugins pipeline.\n * These encoded virtual ids are also prefixed by the VALID_ID_PREFIX, so virtual\n * modules in the browser end up encoded as `/@id/__x00__{id}`\n */\nexport const NULL_BYTE_PLACEHOLDER = `__x00__`\n\nexport const CLIENT_PUBLIC_PATH = `/@vite/client`\nexport const ENV_PUBLIC_PATH = `/@vite/env`\n// BROWSER VITE patch: disable require for browser build\n// eslint-disable-next-line node/no-missing-require\nexport const CLIENT_ENTRY = process.env.VITE_BROWSER ? 'browser-vite/dist/client/client.mjs' : require.resolve('browser-vite/dist/client/client.mjs')\n// eslint-disable-next-line node/no-missing-require\nexport const ENV_ENTRY = process.env.VITE_BROWSER ? 'browser-vite/dist/client/env.mjs' : require.resolve('browser-vite/dist/client/env.mjs')\nexport const CLIENT_DIR = path.dirname(CLIENT_ENTRY)\n\n// ** READ THIS ** before editing `KNOWN_ASSET_TYPES`.\n//   If you add an asset to `KNOWN_ASSET_TYPES`, make sure to also add it\n//   to the TypeScript declaration file `packages/vite/client.d.ts`.\nexport const KNOWN_ASSET_TYPES = [\n  // images\n  'png',\n  'jpe?g',\n  'gif',\n  'svg',\n  'ico',\n  'webp',\n  'avif',\n\n  // media\n  'mp4',\n  'webm',\n  'ogg',\n  'mp3',\n  'wav',\n  'flac',\n  'aac',\n\n  // fonts\n  'woff2?',\n  'eot',\n  'ttf',\n  'otf',\n\n  // other\n  'wasm',\n  'webmanifest',\n  'pdf'\n]\n\nexport const DEFAULT_ASSETS_RE = new RegExp(\n  `\\\\.(` + KNOWN_ASSET_TYPES.join('|') + `)(\\\\?.*)?$`\n)\n\nexport const DEP_VERSION_RE = /[\\?&](v=[\\w\\.-]+)\\b/\n","import debug from 'debug'\nimport chalk from 'chalk'\nimport fs from 'fs'\nimport os from 'os'\nimport path from 'path'\nimport { URL } from 'url'\nimport {\n  FS_PREFIX,\n  DEFAULT_EXTENSIONS,\n  VALID_ID_PREFIX,\n  CLIENT_PUBLIC_PATH,\n  ENV_PUBLIC_PATH\n} from './constants'\nimport resolve from 'resolve'\nimport { builtinModules } from 'module'\nimport { FSWatcher } from 'chokidar'\nimport remapping from '@ampproject/remapping'\nimport {\n  DecodedSourceMap,\n  RawSourceMap\n} from '@ampproject/remapping/dist/types/types'\nimport { performance } from 'perf_hooks'\n\nexport function slash(p: string): string {\n  return p.replace(/\\\\/g, '/')\n}\n\n// Strip valid id prefix. This is prepended to resolved Ids that are\n// not valid browser import specifiers by the importAnalysis plugin.\nexport function unwrapId(id: string): string {\n  return id.startsWith(VALID_ID_PREFIX) ? id.slice(VALID_ID_PREFIX.length) : id\n}\n\nexport const flattenId = (id: string): string =>\n  id.replace(/(\\s*>\\s*)/g, '__').replace(/[\\/\\.]/g, '_')\n\nexport const normalizeId = (id: string): string =>\n  id.replace(/(\\s*>\\s*)/g, ' > ')\n\n//TODO: revisit later to see if the edge case that \"compiling using node v12 code to be run in node v16 in the server\" is what we intend to support.\nconst builtins = new Set([\n  ...builtinModules,\n  'assert/strict',\n  'diagnostics_channel',\n  'dns/promises',\n  'fs/promises',\n  'path/posix',\n  'path/win32',\n  'readline/promises',\n  'stream/consumers',\n  'stream/promises',\n  'stream/web',\n  'timers/promises',\n  'util/types',\n  'wasi'\n])\n\nexport function isBuiltin(id: string): boolean {\n  return builtins.has(id.replace(/^node:/, ''))\n}\n\nexport function moduleListContains(\n  moduleList: string[] | undefined,\n  id: string\n): boolean | undefined {\n  return moduleList?.some((m) => m === id || id.startsWith(m + '/'))\n}\n\nexport const bareImportRE = /^[\\w@](?!.*:\\/\\/)/\nexport const deepImportRE = /^([^@][^/]*)\\/|^(@[^/]+\\/[^/]+)\\//\n\nexport let isRunningWithYarnPnp: boolean\ntry {\n  isRunningWithYarnPnp = Boolean(require('pnpapi'))\n} catch {}\n\nconst ssrExtensions = ['.js', '.cjs', '.json', '.node']\n\nexport function resolveFrom(\n  id: string,\n  basedir: string,\n  preserveSymlinks = false,\n  ssr = false\n): string {\n  return resolve.sync(id, {\n    basedir,\n    extensions: ssr ? ssrExtensions : DEFAULT_EXTENSIONS,\n    // necessary to work with pnpm\n    preserveSymlinks: preserveSymlinks || isRunningWithYarnPnp || false\n  })\n}\n\n/**\n * like `resolveFrom` but supports resolving `>` path in `id`,\n * for example: `foo > bar > baz`\n */\nexport function nestedResolveFrom(\n  id: string,\n  basedir: string,\n  preserveSymlinks = false\n): string {\n  const pkgs = id.split('>').map((pkg) => pkg.trim())\n  try {\n    for (const pkg of pkgs) {\n      basedir = resolveFrom(pkg, basedir, preserveSymlinks)\n    }\n  } catch {}\n  return basedir\n}\n\n// set in bin/vite.js\nconst filter = process.env.VITE_DEBUG_FILTER\n\nconst DEBUG = process.env.DEBUG\n\ninterface DebuggerOptions {\n  onlyWhenFocused?: boolean | string\n}\n\nexport type ViteDebugScope = `vite:${string}`\n\nexport function createDebugger(\n  namespace: ViteDebugScope,\n  options: DebuggerOptions = {}\n): debug.Debugger['log'] {\n  const log = debug(namespace)\n  const { onlyWhenFocused } = options\n  const focus =\n    typeof onlyWhenFocused === 'string' ? onlyWhenFocused : namespace\n  return (msg: string, ...args: any[]) => {\n    if (filter && !msg.includes(filter)) {\n      return\n    }\n    if (onlyWhenFocused && !DEBUG?.includes(focus)) {\n      return\n    }\n    log(msg, ...args)\n  }\n}\n\nexport const isWindows = os.platform() === 'win32'\nconst VOLUME_RE = /^[A-Z]:/i\n\nexport function normalizePath(id: string): string {\n  return path.posix.normalize(isWindows ? slash(id) : id)\n}\n\nexport function fsPathFromId(id: string): string {\n  const fsPath = normalizePath(id.slice(FS_PREFIX.length))\n  return fsPath.startsWith('/') || fsPath.match(VOLUME_RE)\n    ? fsPath\n    : `/${fsPath}`\n}\n\nexport function ensureVolumeInPath(file: string): string {\n  return isWindows ? path.resolve(file) : file\n}\n\nexport const queryRE = /\\?.*$/s\nexport const hashRE = /#.*$/s\n\nexport const cleanUrl = (url: string): string =>\n  url.replace(hashRE, '').replace(queryRE, '')\n\nexport const externalRE = /^(https?:)?\\/\\//\nexport const isExternalUrl = (url: string): boolean => externalRE.test(url)\n\nexport const dataUrlRE = /^\\s*data:/i\nexport const isDataUrl = (url: string): boolean => dataUrlRE.test(url)\n\nexport const virtualModuleRE = /^virtual-module:.*/\nexport const virtualModulePrefix = 'virtual-module:'\n\nconst knownJsSrcRE = /\\.((j|t)sx?|mjs|vue|marko|svelte|astro)($|\\?)/\nexport const isJSRequest = (url: string): boolean => {\n  url = cleanUrl(url)\n  if (knownJsSrcRE.test(url)) {\n    return true\n  }\n  if (!path.extname(url) && !url.endsWith('/')) {\n    return true\n  }\n  return false\n}\n\nconst knownTsRE = /\\.(ts|mts|cts|tsx)$/\nconst knownTsOutputRE = /\\.(js|mjs|cjs|jsx)$/\nexport const isTsRequest = (url: string) => knownTsRE.test(cleanUrl(url))\nexport const isPossibleTsOutput = (url: string) =>\n  knownTsOutputRE.test(cleanUrl(url))\nexport const getTsSrcPath = (filename: string) =>\n  filename.replace(/\\.([cm])?(js)(x?)(\\?|$)/, '.$1ts$3')\n\nconst importQueryRE = /(\\?|&)import=?(?:&|$)/\nconst internalPrefixes = [\n  FS_PREFIX,\n  VALID_ID_PREFIX,\n  CLIENT_PUBLIC_PATH,\n  ENV_PUBLIC_PATH\n]\nconst InternalPrefixRE = new RegExp(`^(?:${internalPrefixes.join('|')})`)\nconst trailingSeparatorRE = /[\\?&]$/\nexport const isImportRequest = (url: string): boolean => importQueryRE.test(url)\nexport const isInternalRequest = (url: string): boolean =>\n  InternalPrefixRE.test(url)\n\nexport function removeImportQuery(url: string): string {\n  return url.replace(importQueryRE, '$1').replace(trailingSeparatorRE, '')\n}\n\nexport function injectQuery(url: string, queryToInject: string): string {\n  // encode percents for consistent behavior with pathToFileURL\n  // see #2614 for details\n  // BROWSER VITE patch: fix logic for browser URL support\n  let resolvedUrl = new URL(url.replace(/%/g, '%25'), 'file:///')\n  // if (resolvedUrl.protocol !== 'relative:') {\n  //   resolvedUrl = pathToFileURL(url)\n  // }\n  let { pathname, search, hash } = resolvedUrl\n  // if (protocol === 'file:') {\n  //   pathname = pathname.slice(1)\n  // }\n  pathname = decodeURIComponent(pathname)\n  return `${pathname}?${queryToInject}${search ? `&` + search.slice(1) : ''}${\n    hash || ''\n  }`\n}\n\nconst timestampRE = /\\bt=\\d{13}&?\\b/\nexport function removeTimestampQuery(url: string): string {\n  return url.replace(timestampRE, '').replace(trailingSeparatorRE, '')\n}\n\nexport async function asyncReplace(\n  input: string,\n  re: RegExp,\n  replacer: (match: RegExpExecArray) => string | Promise<string>\n): Promise<string> {\n  let match: RegExpExecArray | null\n  let remaining = input\n  let rewritten = ''\n  while ((match = re.exec(remaining))) {\n    rewritten += remaining.slice(0, match.index)\n    rewritten += await replacer(match)\n    remaining = remaining.slice(match.index + match[0].length)\n  }\n  rewritten += remaining\n  return rewritten\n}\n\nexport function timeFrom(start: number, subtract = 0): string {\n  const time: number | string = performance.now() - start - subtract\n  const timeString = (time.toFixed(2) + `ms`).padEnd(5, ' ')\n  if (time < 10) {\n    return chalk.green(timeString)\n  } else if (time < 50) {\n    return chalk.yellow(timeString)\n  } else {\n    return chalk.red(timeString)\n  }\n}\n\n/**\n * pretty url for logging.\n */\nexport function prettifyUrl(url: string, root: string): string {\n  url = removeTimestampQuery(url)\n  const isAbsoluteFile = url.startsWith(root)\n  if (isAbsoluteFile || url.startsWith(FS_PREFIX)) {\n    let file = path.relative(root, isAbsoluteFile ? url : fsPathFromId(url))\n    const seg = file.split('/')\n    const npmIndex = seg.indexOf(`node_modules`)\n    const isSourceMap = file.endsWith('.map')\n    if (npmIndex > 0) {\n      file = seg[npmIndex + 1]\n      if (file.startsWith('@')) {\n        file = `${file}/${seg[npmIndex + 2]}`\n      }\n      file = `npm: ${chalk.dim(file)}${isSourceMap ? ` (source map)` : ``}`\n    }\n    return chalk.dim(file)\n  } else {\n    return chalk.dim(url)\n  }\n}\n\nexport function isObject(value: unknown): value is Record<string, any> {\n  return Object.prototype.toString.call(value) === '[object Object]'\n}\n\nexport function isDefined<T>(value: T | undefined | null): value is T {\n  return value != null\n}\n\nexport function lookupFile(\n  dir: string,\n  formats: string[],\n  pathOnly = false\n): string | undefined {\n  for (const format of formats) {\n    const fullPath = path.join(dir, format)\n    if (fs.existsSync(fullPath) && fs.statSync(fullPath).isFile()) {\n      return pathOnly ? fullPath : fs.readFileSync(fullPath, 'utf-8')\n    }\n  }\n  const parentDir = path.dirname(dir)\n  if (parentDir !== dir) {\n    return lookupFile(parentDir, formats, pathOnly)\n  }\n}\n\nconst splitRE = /\\r?\\n/\n\nconst range: number = 2\n\nexport function pad(source: string, n = 2): string {\n  const lines = source.split(splitRE)\n  return lines.map((l) => ` `.repeat(n) + l).join(`\\n`)\n}\n\nexport function posToNumber(\n  source: string,\n  pos: number | { line: number; column: number }\n): number {\n  if (typeof pos === 'number') return pos\n  const lines = source.split(splitRE)\n  const { line, column } = pos\n  let start = 0\n  for (let i = 0; i < line - 1; i++) {\n    start += lines[i].length + 1\n  }\n  return start + column\n}\n\nexport function numberToPos(\n  source: string,\n  offset: number | { line: number; column: number }\n): { line: number; column: number } {\n  if (typeof offset !== 'number') return offset\n  if (offset > source.length) {\n    throw new Error(\n      `offset is longer than source length! offset ${offset} > length ${source.length}`\n    )\n  }\n  const lines = source.split(splitRE)\n  let counted = 0\n  let line = 0\n  let column = 0\n  for (; line < lines.length; line++) {\n    const lineLength = lines[line].length + 1\n    if (counted + lineLength >= offset) {\n      column = offset - counted + 1\n      break\n    }\n    counted += lineLength\n  }\n  return { line: line + 1, column }\n}\n\nexport function generateCodeFrame(\n  source: string,\n  start: number | { line: number; column: number } = 0,\n  end?: number\n): string {\n  start = posToNumber(source, start)\n  end = end || start\n  const lines = source.split(splitRE)\n  let count = 0\n  const res: string[] = []\n  for (let i = 0; i < lines.length; i++) {\n    count += lines[i].length + 1\n    if (count >= start) {\n      for (let j = i - range; j <= i + range || end > count; j++) {\n        if (j < 0 || j >= lines.length) continue\n        const line = j + 1\n        res.push(\n          `${line}${' '.repeat(Math.max(3 - String(line).length, 0))}|  ${\n            lines[j]\n          }`\n        )\n        const lineLength = lines[j].length\n        if (j === i) {\n          // push underline\n          const pad = start - (count - lineLength) + 1\n          const length = Math.max(\n            1,\n            end > count ? lineLength - pad : end - start\n          )\n          res.push(`   |  ` + ' '.repeat(pad) + '^'.repeat(length))\n        } else if (j > i) {\n          if (end > count) {\n            const length = Math.max(Math.min(end - count, lineLength), 1)\n            res.push(`   |  ` + '^'.repeat(length))\n          }\n          count += lineLength + 1\n        }\n      }\n      break\n    }\n  }\n  return res.join('\\n')\n}\n\nexport function writeFile(\n  filename: string,\n  content: string | Uint8Array\n): void {\n  const dir = path.dirname(filename)\n  if (!fs.existsSync(dir)) {\n    fs.mkdirSync(dir, { recursive: true })\n  }\n  fs.writeFileSync(filename, content)\n}\n\n/**\n * Use instead of fs.existsSync(filename)\n * #2051 if we don't have read permission on a directory, existsSync() still\n * works and will result in massively slow subsequent checks (which are\n * unnecessary in the first place)\n */\nexport function isFileReadable(filename: string): boolean {\n  try {\n    fs.accessSync(filename, fs.constants.R_OK)\n    return true\n  } catch {\n    return false\n  }\n}\n\n/**\n * Delete every file and subdirectory. **The given directory must exist.**\n * Pass an optional `skip` array to preserve files in the root directory.\n */\nexport function emptyDir(dir: string, skip?: string[]): void {\n  for (const file of fs.readdirSync(dir)) {\n    if (skip?.includes(file)) {\n      continue\n    }\n    const abs = path.resolve(dir, file)\n    // baseline is Node 12 so can't use rmSync :(\n    if (fs.lstatSync(abs).isDirectory()) {\n      emptyDir(abs)\n      fs.rmdirSync(abs)\n    } else {\n      fs.unlinkSync(abs)\n    }\n  }\n}\n\nexport function copyDir(srcDir: string, destDir: string): void {\n  fs.mkdirSync(destDir, { recursive: true })\n  for (const file of fs.readdirSync(srcDir)) {\n    const srcFile = path.resolve(srcDir, file)\n    if (srcFile === destDir) {\n      continue\n    }\n    const destFile = path.resolve(destDir, file)\n    const stat = fs.statSync(srcFile)\n    if (stat.isDirectory()) {\n      copyDir(srcFile, destFile)\n    } else {\n      fs.copyFileSync(srcFile, destFile)\n    }\n  }\n}\n\nexport function ensureLeadingSlash(path: string): string {\n  return !path.startsWith('/') ? '/' + path : path\n}\n\nexport function ensureWatchedFile(\n  watcher: FSWatcher,\n  file: string | null,\n  root: string\n): void {\n  if (\n    file &&\n    // only need to watch if out of root\n    !file.startsWith(root + '/') &&\n    // some rollup plugins use null bytes for private resolved Ids\n    !file.includes('\\0') &&\n    fs.existsSync(file)\n  ) {\n    // resolve file to normalized system path\n    watcher.add(path.resolve(file))\n  }\n}\n\ninterface ImageCandidate {\n  url: string\n  descriptor: string\n}\nconst escapedSpaceCharacters = /( |\\\\t|\\\\n|\\\\f|\\\\r)+/g\nexport async function processSrcSet(\n  srcs: string,\n  replacer: (arg: ImageCandidate) => Promise<string>\n): Promise<string> {\n  const imageCandidates: ImageCandidate[] = srcs\n    .split(',')\n    .map((s) => {\n      const [url, descriptor] = s\n        .replace(escapedSpaceCharacters, ' ')\n        .trim()\n        .split(' ', 2)\n      return { url, descriptor }\n    })\n    .filter(({ url }) => !!url)\n\n  const ret = await Promise.all(\n    imageCandidates.map(async ({ url, descriptor }) => {\n      return {\n        url: await replacer({ url, descriptor }),\n        descriptor\n      }\n    })\n  )\n\n  return ret.reduce((prev, { url, descriptor }, index) => {\n    descriptor = descriptor || ''\n    return (prev +=\n      url + ` ${descriptor}${index === ret.length - 1 ? '' : ', '}`)\n  }, '')\n}\n\n// based on https://github.com/sveltejs/svelte/blob/abf11bb02b2afbd3e4cac509a0f70e318c306364/src/compiler/utils/mapped_code.ts#L221\nconst nullSourceMap: RawSourceMap = {\n  names: [],\n  sources: [],\n  mappings: '',\n  version: 3\n}\nexport function combineSourcemaps(\n  filename: string,\n  sourcemapList: Array<DecodedSourceMap | RawSourceMap>\n): RawSourceMap {\n  if (\n    sourcemapList.length === 0 ||\n    sourcemapList.every((m) => m.sources.length === 0)\n  ) {\n    return { ...nullSourceMap }\n  }\n\n  // We don't declare type here so we can convert/fake/map as RawSourceMap\n  let map //: SourceMap\n  let mapIndex = 1\n  const useArrayInterface =\n    sourcemapList.slice(0, -1).find((m) => m.sources.length !== 1) === undefined\n  if (useArrayInterface) {\n    map = remapping(sourcemapList, () => null, true)\n  } else {\n    map = remapping(\n      sourcemapList[0],\n      function loader(sourcefile) {\n        if (sourcefile === filename && sourcemapList[mapIndex]) {\n          return sourcemapList[mapIndex++]\n        } else {\n          return { ...nullSourceMap }\n        }\n      },\n      true\n    )\n  }\n  if (!map.file) {\n    delete map.file\n  }\n\n  return map as RawSourceMap\n}\n\nexport function unique<T>(arr: T[]): T[] {\n  return Array.from(new Set(arr))\n}\n\nexport interface Hostname {\n  // undefined sets the default behaviour of server.listen\n  host: string | undefined\n  // resolve to localhost when possible\n  name: string\n}\n\nexport function resolveHostname(\n  optionsHost: string | boolean | undefined\n): Hostname {\n  let host: string | undefined\n  if (\n    optionsHost === undefined ||\n    optionsHost === false ||\n    optionsHost === 'localhost'\n  ) {\n    // Use a secure default\n    host = '127.0.0.1'\n  } else if (optionsHost === true) {\n    // If passed --host in the CLI without arguments\n    host = undefined // undefined typically means 0.0.0.0 or :: (listen on all IPs)\n  } else {\n    host = optionsHost\n  }\n\n  // Set host name to localhost when possible, unless the user explicitly asked for '127.0.0.1'\n  const name =\n    (optionsHost !== '127.0.0.1' && host === '127.0.0.1') ||\n    host === '0.0.0.0' ||\n    host === '::' ||\n    host === undefined\n      ? 'localhost'\n      : host\n\n  return { host, name }\n}\n\nexport function arraify<T>(target: T | T[]): T[] {\n  return Array.isArray(target) ? target : [target]\n}\n\nexport function toUpperCaseDriveLetter(pathName: string): string {\n  return pathName.replace(/^\\w:/, (letter) => letter.toUpperCase())\n}\n\nexport const multilineCommentsRE = /\\/\\*(.|[\\r\\n])*?\\*\\//gm\nexport const singlelineCommentsRE = /\\/\\/.*/g\n\nexport const usingDynamicImport = typeof jest === 'undefined'\n/**\n * Dynamically import files. It will make sure it's not being compiled away by TS/Rollup.\n *\n * As a temporary workaround for Jest's lack of stable ESM support, we fallback to require\n * if we're in a Jest environment.\n * See https://github.com/vitejs/vite/pull/5197#issuecomment-938054077\n *\n * @param file File path to import.\n */\nexport const dynamicImport = usingDynamicImport\n  ? new Function('file', 'return import(file)')\n  : require\n","'use strict';\n\n/**\n * @param typeMap [Object] Map of MIME type -> Array[extensions]\n * @param ...\n */\nfunction Mime() {\n  this._types = Object.create(null);\n  this._extensions = Object.create(null);\n\n  for (let i = 0; i < arguments.length; i++) {\n    this.define(arguments[i]);\n  }\n\n  this.define = this.define.bind(this);\n  this.getType = this.getType.bind(this);\n  this.getExtension = this.getExtension.bind(this);\n}\n\n/**\n * Define mimetype -> extension mappings.  Each key is a mime-type that maps\n * to an array of extensions associated with the type.  The first extension is\n * used as the default extension for the type.\n *\n * e.g. mime.define({'audio/ogg', ['oga', 'ogg', 'spx']});\n *\n * If a type declares an extension that has already been defined, an error will\n * be thrown.  To suppress this error and force the extension to be associated\n * with the new type, pass `force`=true.  Alternatively, you may prefix the\n * extension with \"*\" to map the type to extension, without mapping the\n * extension to the type.\n *\n * e.g. mime.define({'audio/wav', ['wav']}, {'audio/x-wav', ['*wav']});\n *\n *\n * @param map (Object) type definitions\n * @param force (Boolean) if true, force overriding of existing definitions\n */\nMime.prototype.define = function(typeMap, force) {\n  for (let type in typeMap) {\n    let extensions = typeMap[type].map(function(t) {\n      return t.toLowerCase();\n    });\n    type = type.toLowerCase();\n\n    for (let i = 0; i < extensions.length; i++) {\n      const ext = extensions[i];\n\n      // '*' prefix = not the preferred type for this extension.  So fixup the\n      // extension, and skip it.\n      if (ext[0] === '*') {\n        continue;\n      }\n\n      if (!force && (ext in this._types)) {\n        throw new Error(\n          'Attempt to change mapping for \"' + ext +\n          '\" extension from \"' + this._types[ext] + '\" to \"' + type +\n          '\". Pass `force=true` to allow this, otherwise remove \"' + ext +\n          '\" from the list of extensions for \"' + type + '\".'\n        );\n      }\n\n      this._types[ext] = type;\n    }\n\n    // Use first extension as default\n    if (force || !this._extensions[type]) {\n      const ext = extensions[0];\n      this._extensions[type] = (ext[0] !== '*') ? ext : ext.substr(1);\n    }\n  }\n};\n\n/**\n * Lookup a mime type based on extension\n */\nMime.prototype.getType = function(path) {\n  path = String(path);\n  let last = path.replace(/^.*[/\\\\]/, '').toLowerCase();\n  let ext = last.replace(/^.*\\./, '').toLowerCase();\n\n  let hasPath = last.length < path.length;\n  let hasDot = ext.length < last.length - 1;\n\n  return (hasDot || !hasPath) && this._types[ext] || null;\n};\n\n/**\n * Return file extension associated with a mime type\n */\nMime.prototype.getExtension = function(type) {\n  type = /^\\s*([^;\\s]*)/.test(type) && RegExp.$1;\n  return type && this._extensions[type.toLowerCase()] || null;\n};\n\nmodule.exports = Mime;\n","module.exports = {\"application/andrew-inset\":[\"ez\"],\"application/applixware\":[\"aw\"],\"application/atom+xml\":[\"atom\"],\"application/atomcat+xml\":[\"atomcat\"],\"application/atomdeleted+xml\":[\"atomdeleted\"],\"application/atomsvc+xml\":[\"atomsvc\"],\"application/atsc-dwd+xml\":[\"dwd\"],\"application/atsc-held+xml\":[\"held\"],\"application/atsc-rsat+xml\":[\"rsat\"],\"application/bdoc\":[\"bdoc\"],\"application/calendar+xml\":[\"xcs\"],\"application/ccxml+xml\":[\"ccxml\"],\"application/cdfx+xml\":[\"cdfx\"],\"application/cdmi-capability\":[\"cdmia\"],\"application/cdmi-container\":[\"cdmic\"],\"application/cdmi-domain\":[\"cdmid\"],\"application/cdmi-object\":[\"cdmio\"],\"application/cdmi-queue\":[\"cdmiq\"],\"application/cu-seeme\":[\"cu\"],\"application/dash+xml\":[\"mpd\"],\"application/davmount+xml\":[\"davmount\"],\"application/docbook+xml\":[\"dbk\"],\"application/dssc+der\":[\"dssc\"],\"application/dssc+xml\":[\"xdssc\"],\"application/ecmascript\":[\"es\",\"ecma\"],\"application/emma+xml\":[\"emma\"],\"application/emotionml+xml\":[\"emotionml\"],\"application/epub+zip\":[\"epub\"],\"application/exi\":[\"exi\"],\"application/express\":[\"exp\"],\"application/fdt+xml\":[\"fdt\"],\"application/font-tdpfr\":[\"pfr\"],\"application/geo+json\":[\"geojson\"],\"application/gml+xml\":[\"gml\"],\"application/gpx+xml\":[\"gpx\"],\"application/gxf\":[\"gxf\"],\"application/gzip\":[\"gz\"],\"application/hjson\":[\"hjson\"],\"application/hyperstudio\":[\"stk\"],\"application/inkml+xml\":[\"ink\",\"inkml\"],\"application/ipfix\":[\"ipfix\"],\"application/its+xml\":[\"its\"],\"application/java-archive\":[\"jar\",\"war\",\"ear\"],\"application/java-serialized-object\":[\"ser\"],\"application/java-vm\":[\"class\"],\"application/javascript\":[\"js\",\"mjs\"],\"application/json\":[\"json\",\"map\"],\"application/json5\":[\"json5\"],\"application/jsonml+json\":[\"jsonml\"],\"application/ld+json\":[\"jsonld\"],\"application/lgr+xml\":[\"lgr\"],\"application/lost+xml\":[\"lostxml\"],\"application/mac-binhex40\":[\"hqx\"],\"application/mac-compactpro\":[\"cpt\"],\"application/mads+xml\":[\"mads\"],\"application/manifest+json\":[\"webmanifest\"],\"application/marc\":[\"mrc\"],\"application/marcxml+xml\":[\"mrcx\"],\"application/mathematica\":[\"ma\",\"nb\",\"mb\"],\"application/mathml+xml\":[\"mathml\"],\"application/mbox\":[\"mbox\"],\"application/mediaservercontrol+xml\":[\"mscml\"],\"application/metalink+xml\":[\"metalink\"],\"application/metalink4+xml\":[\"meta4\"],\"application/mets+xml\":[\"mets\"],\"application/mmt-aei+xml\":[\"maei\"],\"application/mmt-usd+xml\":[\"musd\"],\"application/mods+xml\":[\"mods\"],\"application/mp21\":[\"m21\",\"mp21\"],\"application/mp4\":[\"mp4s\",\"m4p\"],\"application/msword\":[\"doc\",\"dot\"],\"application/mxf\":[\"mxf\"],\"application/n-quads\":[\"nq\"],\"application/n-triples\":[\"nt\"],\"application/node\":[\"cjs\"],\"application/octet-stream\":[\"bin\",\"dms\",\"lrf\",\"mar\",\"so\",\"dist\",\"distz\",\"pkg\",\"bpk\",\"dump\",\"elc\",\"deploy\",\"exe\",\"dll\",\"deb\",\"dmg\",\"iso\",\"img\",\"msi\",\"msp\",\"msm\",\"buffer\"],\"application/oda\":[\"oda\"],\"application/oebps-package+xml\":[\"opf\"],\"application/ogg\":[\"ogx\"],\"application/omdoc+xml\":[\"omdoc\"],\"application/onenote\":[\"onetoc\",\"onetoc2\",\"onetmp\",\"onepkg\"],\"application/oxps\":[\"oxps\"],\"application/p2p-overlay+xml\":[\"relo\"],\"application/patch-ops-error+xml\":[\"xer\"],\"application/pdf\":[\"pdf\"],\"application/pgp-encrypted\":[\"pgp\"],\"application/pgp-signature\":[\"asc\",\"sig\"],\"application/pics-rules\":[\"prf\"],\"application/pkcs10\":[\"p10\"],\"application/pkcs7-mime\":[\"p7m\",\"p7c\"],\"application/pkcs7-signature\":[\"p7s\"],\"application/pkcs8\":[\"p8\"],\"application/pkix-attr-cert\":[\"ac\"],\"application/pkix-cert\":[\"cer\"],\"application/pkix-crl\":[\"crl\"],\"application/pkix-pkipath\":[\"pkipath\"],\"application/pkixcmp\":[\"pki\"],\"application/pls+xml\":[\"pls\"],\"application/postscript\":[\"ai\",\"eps\",\"ps\"],\"application/provenance+xml\":[\"provx\"],\"application/pskc+xml\":[\"pskcxml\"],\"application/raml+yaml\":[\"raml\"],\"application/rdf+xml\":[\"rdf\",\"owl\"],\"application/reginfo+xml\":[\"rif\"],\"application/relax-ng-compact-syntax\":[\"rnc\"],\"application/resource-lists+xml\":[\"rl\"],\"application/resource-lists-diff+xml\":[\"rld\"],\"application/rls-services+xml\":[\"rs\"],\"application/route-apd+xml\":[\"rapd\"],\"application/route-s-tsid+xml\":[\"sls\"],\"application/route-usd+xml\":[\"rusd\"],\"application/rpki-ghostbusters\":[\"gbr\"],\"application/rpki-manifest\":[\"mft\"],\"application/rpki-roa\":[\"roa\"],\"application/rsd+xml\":[\"rsd\"],\"application/rss+xml\":[\"rss\"],\"application/rtf\":[\"rtf\"],\"application/sbml+xml\":[\"sbml\"],\"application/scvp-cv-request\":[\"scq\"],\"application/scvp-cv-response\":[\"scs\"],\"application/scvp-vp-request\":[\"spq\"],\"application/scvp-vp-response\":[\"spp\"],\"application/sdp\":[\"sdp\"],\"application/senml+xml\":[\"senmlx\"],\"application/sensml+xml\":[\"sensmlx\"],\"application/set-payment-initiation\":[\"setpay\"],\"application/set-registration-initiation\":[\"setreg\"],\"application/shf+xml\":[\"shf\"],\"application/sieve\":[\"siv\",\"sieve\"],\"application/smil+xml\":[\"smi\",\"smil\"],\"application/sparql-query\":[\"rq\"],\"application/sparql-results+xml\":[\"srx\"],\"application/srgs\":[\"gram\"],\"application/srgs+xml\":[\"grxml\"],\"application/sru+xml\":[\"sru\"],\"application/ssdl+xml\":[\"ssdl\"],\"application/ssml+xml\":[\"ssml\"],\"application/swid+xml\":[\"swidtag\"],\"application/tei+xml\":[\"tei\",\"teicorpus\"],\"application/thraud+xml\":[\"tfi\"],\"application/timestamped-data\":[\"tsd\"],\"application/toml\":[\"toml\"],\"application/trig\":[\"trig\"],\"application/ttml+xml\":[\"ttml\"],\"application/ubjson\":[\"ubj\"],\"application/urc-ressheet+xml\":[\"rsheet\"],\"application/urc-targetdesc+xml\":[\"td\"],\"application/voicexml+xml\":[\"vxml\"],\"application/wasm\":[\"wasm\"],\"application/widget\":[\"wgt\"],\"application/winhlp\":[\"hlp\"],\"application/wsdl+xml\":[\"wsdl\"],\"application/wspolicy+xml\":[\"wspolicy\"],\"application/xaml+xml\":[\"xaml\"],\"application/xcap-att+xml\":[\"xav\"],\"application/xcap-caps+xml\":[\"xca\"],\"application/xcap-diff+xml\":[\"xdf\"],\"application/xcap-el+xml\":[\"xel\"],\"application/xcap-ns+xml\":[\"xns\"],\"application/xenc+xml\":[\"xenc\"],\"application/xhtml+xml\":[\"xhtml\",\"xht\"],\"application/xliff+xml\":[\"xlf\"],\"application/xml\":[\"xml\",\"xsl\",\"xsd\",\"rng\"],\"application/xml-dtd\":[\"dtd\"],\"application/xop+xml\":[\"xop\"],\"application/xproc+xml\":[\"xpl\"],\"application/xslt+xml\":[\"*xsl\",\"xslt\"],\"application/xspf+xml\":[\"xspf\"],\"application/xv+xml\":[\"mxml\",\"xhvml\",\"xvml\",\"xvm\"],\"application/yang\":[\"yang\"],\"application/yin+xml\":[\"yin\"],\"application/zip\":[\"zip\"],\"audio/3gpp\":[\"*3gpp\"],\"audio/adpcm\":[\"adp\"],\"audio/amr\":[\"amr\"],\"audio/basic\":[\"au\",\"snd\"],\"audio/midi\":[\"mid\",\"midi\",\"kar\",\"rmi\"],\"audio/mobile-xmf\":[\"mxmf\"],\"audio/mp3\":[\"*mp3\"],\"audio/mp4\":[\"m4a\",\"mp4a\"],\"audio/mpeg\":[\"mpga\",\"mp2\",\"mp2a\",\"mp3\",\"m2a\",\"m3a\"],\"audio/ogg\":[\"oga\",\"ogg\",\"spx\",\"opus\"],\"audio/s3m\":[\"s3m\"],\"audio/silk\":[\"sil\"],\"audio/wav\":[\"wav\"],\"audio/wave\":[\"*wav\"],\"audio/webm\":[\"weba\"],\"audio/xm\":[\"xm\"],\"font/collection\":[\"ttc\"],\"font/otf\":[\"otf\"],\"font/ttf\":[\"ttf\"],\"font/woff\":[\"woff\"],\"font/woff2\":[\"woff2\"],\"image/aces\":[\"exr\"],\"image/apng\":[\"apng\"],\"image/avif\":[\"avif\"],\"image/bmp\":[\"bmp\"],\"image/cgm\":[\"cgm\"],\"image/dicom-rle\":[\"drle\"],\"image/emf\":[\"emf\"],\"image/fits\":[\"fits\"],\"image/g3fax\":[\"g3\"],\"image/gif\":[\"gif\"],\"image/heic\":[\"heic\"],\"image/heic-sequence\":[\"heics\"],\"image/heif\":[\"heif\"],\"image/heif-sequence\":[\"heifs\"],\"image/hej2k\":[\"hej2\"],\"image/hsj2\":[\"hsj2\"],\"image/ief\":[\"ief\"],\"image/jls\":[\"jls\"],\"image/jp2\":[\"jp2\",\"jpg2\"],\"image/jpeg\":[\"jpeg\",\"jpg\",\"jpe\"],\"image/jph\":[\"jph\"],\"image/jphc\":[\"jhc\"],\"image/jpm\":[\"jpm\"],\"image/jpx\":[\"jpx\",\"jpf\"],\"image/jxr\":[\"jxr\"],\"image/jxra\":[\"jxra\"],\"image/jxrs\":[\"jxrs\"],\"image/jxs\":[\"jxs\"],\"image/jxsc\":[\"jxsc\"],\"image/jxsi\":[\"jxsi\"],\"image/jxss\":[\"jxss\"],\"image/ktx\":[\"ktx\"],\"image/ktx2\":[\"ktx2\"],\"image/png\":[\"png\"],\"image/sgi\":[\"sgi\"],\"image/svg+xml\":[\"svg\",\"svgz\"],\"image/t38\":[\"t38\"],\"image/tiff\":[\"tif\",\"tiff\"],\"image/tiff-fx\":[\"tfx\"],\"image/webp\":[\"webp\"],\"image/wmf\":[\"wmf\"],\"message/disposition-notification\":[\"disposition-notification\"],\"message/global\":[\"u8msg\"],\"message/global-delivery-status\":[\"u8dsn\"],\"message/global-disposition-notification\":[\"u8mdn\"],\"message/global-headers\":[\"u8hdr\"],\"message/rfc822\":[\"eml\",\"mime\"],\"model/3mf\":[\"3mf\"],\"model/gltf+json\":[\"gltf\"],\"model/gltf-binary\":[\"glb\"],\"model/iges\":[\"igs\",\"iges\"],\"model/mesh\":[\"msh\",\"mesh\",\"silo\"],\"model/mtl\":[\"mtl\"],\"model/obj\":[\"obj\"],\"model/step+xml\":[\"stpx\"],\"model/step+zip\":[\"stpz\"],\"model/step-xml+zip\":[\"stpxz\"],\"model/stl\":[\"stl\"],\"model/vrml\":[\"wrl\",\"vrml\"],\"model/x3d+binary\":[\"*x3db\",\"x3dbz\"],\"model/x3d+fastinfoset\":[\"x3db\"],\"model/x3d+vrml\":[\"*x3dv\",\"x3dvz\"],\"model/x3d+xml\":[\"x3d\",\"x3dz\"],\"model/x3d-vrml\":[\"x3dv\"],\"text/cache-manifest\":[\"appcache\",\"manifest\"],\"text/calendar\":[\"ics\",\"ifb\"],\"text/coffeescript\":[\"coffee\",\"litcoffee\"],\"text/css\":[\"css\"],\"text/csv\":[\"csv\"],\"text/html\":[\"html\",\"htm\",\"shtml\"],\"text/jade\":[\"jade\"],\"text/jsx\":[\"jsx\"],\"text/less\":[\"less\"],\"text/markdown\":[\"markdown\",\"md\"],\"text/mathml\":[\"mml\"],\"text/mdx\":[\"mdx\"],\"text/n3\":[\"n3\"],\"text/plain\":[\"txt\",\"text\",\"conf\",\"def\",\"list\",\"log\",\"in\",\"ini\"],\"text/richtext\":[\"rtx\"],\"text/rtf\":[\"*rtf\"],\"text/sgml\":[\"sgml\",\"sgm\"],\"text/shex\":[\"shex\"],\"text/slim\":[\"slim\",\"slm\"],\"text/spdx\":[\"spdx\"],\"text/stylus\":[\"stylus\",\"styl\"],\"text/tab-separated-values\":[\"tsv\"],\"text/troff\":[\"t\",\"tr\",\"roff\",\"man\",\"me\",\"ms\"],\"text/turtle\":[\"ttl\"],\"text/uri-list\":[\"uri\",\"uris\",\"urls\"],\"text/vcard\":[\"vcard\"],\"text/vtt\":[\"vtt\"],\"text/xml\":[\"*xml\"],\"text/yaml\":[\"yaml\",\"yml\"],\"video/3gpp\":[\"3gp\",\"3gpp\"],\"video/3gpp2\":[\"3g2\"],\"video/h261\":[\"h261\"],\"video/h263\":[\"h263\"],\"video/h264\":[\"h264\"],\"video/iso.segment\":[\"m4s\"],\"video/jpeg\":[\"jpgv\"],\"video/jpm\":[\"*jpm\",\"jpgm\"],\"video/mj2\":[\"mj2\",\"mjp2\"],\"video/mp2t\":[\"ts\"],\"video/mp4\":[\"mp4\",\"mp4v\",\"mpg4\"],\"video/mpeg\":[\"mpeg\",\"mpg\",\"mpe\",\"m1v\",\"m2v\"],\"video/ogg\":[\"ogv\"],\"video/quicktime\":[\"qt\",\"mov\"],\"video/webm\":[\"webm\"]};","'use strict';\n\nlet Mime = require('./Mime');\nmodule.exports = new Mime(require('./types/standard'));\n","import path from 'path'\nimport { parse as parseUrl } from 'url'\nimport fs, { promises as fsp } from 'fs'\nimport mime from 'mime/lite'\nimport { Plugin } from '../plugin'\nimport { ResolvedConfig } from '../config'\nimport { cleanUrl } from '../utils'\nimport { FS_PREFIX } from '../constants'\nimport { OutputOptions, PluginContext, RenderedChunk } from 'rollup'\nimport MagicString from 'magic-string'\nimport { createHash } from 'crypto'\nimport { normalizePath } from '../utils'\n\nexport const assetUrlRE = /__VITE_ASSET__([a-z\\d]{8})__(?:\\$_(.*?)__)?/g\n\nconst rawRE = /(\\?|&)raw(?:&|$)/\nconst urlRE = /(\\?|&)url(?:&|$)/\n\nexport const chunkToEmittedAssetsMap = new WeakMap<RenderedChunk, Set<string>>()\n\nconst assetCache = new WeakMap<ResolvedConfig, Map<string, string>>()\n\nconst assetHashToFilenameMap = new WeakMap<\n  ResolvedConfig,\n  Map<string, string>\n>()\n// save hashes of the files that has been emitted in build watch\nconst emittedHashMap = new WeakMap<ResolvedConfig, Set<string>>()\n\n/**\n * Also supports loading plain strings with import text from './foo.txt?raw'\n */\nexport function assetPlugin(config: ResolvedConfig): Plugin {\n  // assetHashToFilenameMap initialization in buildStart causes getAssetFilename to return undefined\n  assetHashToFilenameMap.set(config, new Map())\n  return {\n    name: 'vite:asset',\n\n    buildStart() {\n      assetCache.set(config, new Map())\n      emittedHashMap.set(config, new Set())\n    },\n\n    resolveId(id) {\n      if (!config.assetsInclude(cleanUrl(id))) {\n        return\n      }\n      // imports to absolute urls pointing to files in /public\n      // will fail to resolve in the main resolver. handle them here.\n      const publicFile = checkPublicFile(id, config)\n      if (publicFile) {\n        return id\n      }\n    },\n\n    async load(id) {\n      if (id.startsWith('\\0')) {\n        // Rollup convention, this id should be handled by the\n        // plugin that marked it with \\0\n        return\n      }\n\n      // raw requests, read from disk\n      if (rawRE.test(id)) {\n        const file = checkPublicFile(id, config) || cleanUrl(id)\n        // raw query, read file and return as string\n        return `export default ${JSON.stringify(\n          await fsp.readFile(file, 'utf-8')\n        )}`\n      }\n\n      if (!config.assetsInclude(cleanUrl(id)) && !urlRE.test(id)) {\n        return\n      }\n\n      id = id.replace(urlRE, '$1').replace(/[\\?&]$/, '')\n      const url = await fileToUrl(id, config, this)\n      return `export default ${JSON.stringify(url)}`\n    },\n\n    renderChunk(code, chunk) {\n      let match: RegExpExecArray | null\n      let s: MagicString | undefined\n\n      // Urls added with JS using e.g.\n      // imgElement.src = \"my/file.png\" are using quotes\n\n      // Urls added in CSS that is imported in JS end up like\n      // var inlined = \".inlined{color:green;background:url(__VITE_ASSET__5aa0ddc0__)}\\n\";\n\n      // In both cases, the wrapping should already be fine\n\n      while ((match = assetUrlRE.exec(code))) {\n        s = s || (s = new MagicString(code))\n        const [full, hash, postfix = ''] = match\n        // some internal plugins may still need to emit chunks (e.g. worker) so\n        // fallback to this.getFileName for that.\n        const file = getAssetFilename(hash, config) || this.getFileName(hash)\n        registerAssetToChunk(chunk, file)\n        const outputFilepath = config.base + file + postfix\n        s.overwrite(match.index, match.index + full.length, outputFilepath)\n      }\n\n      if (s) {\n        return {\n          code: s.toString(),\n          map: config.build.sourcemap ? s.generateMap({ hires: true }) : null\n        }\n      } else {\n        return null\n      }\n    },\n\n    generateBundle(_, bundle) {\n      // do not emit assets for SSR build\n      if (config.command === 'build' && config.build.ssr) {\n        for (const file in bundle) {\n          if (\n            bundle[file].type === 'asset' &&\n            !file.includes('ssr-manifest.json')\n          ) {\n            delete bundle[file]\n          }\n        }\n      }\n    }\n  }\n}\n\nexport function registerAssetToChunk(chunk: RenderedChunk, file: string): void {\n  let emitted = chunkToEmittedAssetsMap.get(chunk)\n  if (!emitted) {\n    emitted = new Set()\n    chunkToEmittedAssetsMap.set(chunk, emitted)\n  }\n  emitted.add(cleanUrl(file))\n}\n\nexport function checkPublicFile(\n  url: string,\n  { publicDir }: ResolvedConfig\n): string | undefined {\n  // note if the file is in /public, the resolver would have returned it\n  // as-is so it's not going to be a fully resolved path.\n  if (!publicDir || !url.startsWith('/')) {\n    return\n  }\n  const publicFile = path.join(publicDir, cleanUrl(url))\n  if (fs.existsSync(publicFile)) {\n    return publicFile\n  } else {\n    return\n  }\n}\n\nexport function fileToUrl(\n  id: string,\n  config: ResolvedConfig,\n  ctx: PluginContext\n): string | Promise<string> {\n  if (config.command === 'serve') {\n    return fileToDevUrl(id, config)\n  } else {\n    return fileToBuiltUrl(id, config, ctx)\n  }\n}\n\nfunction fileToDevUrl(id: string, config: ResolvedConfig) {\n  let rtn: string\n  if (checkPublicFile(id, config)) {\n    // in public dir, keep the url as-is\n    rtn = id\n  } else if (id.startsWith(config.root)) {\n    // in project root, infer short public path\n    rtn = '/' + path.posix.relative(config.root, id)\n  } else {\n    // outside of project root, use absolute fs path\n    // (this is special handled by the serve static middleware\n    rtn = path.posix.join(FS_PREFIX + id)\n  }\n  const origin = config.server?.origin ?? ''\n  return origin + config.base + rtn.replace(/^\\//, '')\n}\n\nexport function getAssetFilename(\n  hash: string,\n  config: ResolvedConfig\n): string | undefined {\n  return assetHashToFilenameMap.get(config)?.get(hash)\n}\n\n/**\n * converts the source filepath of the asset to the output filename based on the assetFileNames option. \\\n * this function imitates the behavior of rollup.js. \\\n * https://rollupjs.org/guide/en/#outputassetfilenames\n *\n * @example\n * ```ts\n * const content = Buffer.from('text');\n * const fileName = assetFileNamesToFileName(\n *   'assets/[name].[hash][extname]',\n *   '/path/to/file.txt',\n *   getAssetHash(content),\n *   content\n * )\n * // fileName: 'assets/file.982d9e3e.txt'\n * ```\n *\n * @param assetFileNames filename pattern. e.g. `'assets/[name].[hash][extname]'`\n * @param file filepath of the asset\n * @param contentHash hash of the asset. used for `'[hash]'` placeholder\n * @param content content of the asset. passed to `assetFileNames` if `assetFileNames` is a function\n * @returns output filename\n */\nexport function assetFileNamesToFileName(\n  assetFileNames: Exclude<OutputOptions['assetFileNames'], undefined>,\n  file: string,\n  contentHash: string,\n  content: string | Buffer\n): string {\n  const basename = path.basename(file)\n\n  // placeholders for `assetFileNames`\n  // `hash` is slightly different from the rollup's one\n  const extname = path.extname(basename)\n  const ext = extname.substring(1)\n  const name = basename.slice(0, -extname.length)\n  const hash = contentHash\n\n  if (typeof assetFileNames === 'function') {\n    assetFileNames = assetFileNames({\n      name: file,\n      source: content,\n      type: 'asset'\n    })\n    if (typeof assetFileNames !== 'string') {\n      throw new TypeError('assetFileNames must return a string')\n    }\n  } else if (typeof assetFileNames !== 'string') {\n    throw new TypeError('assetFileNames must be a string or a function')\n  }\n\n  const fileName = assetFileNames.replace(\n    /\\[\\w+\\]/g,\n    (placeholder: string): string => {\n      switch (placeholder) {\n        case '[ext]':\n          return ext\n\n        case '[extname]':\n          return extname\n\n        case '[hash]':\n          return hash\n\n        case '[name]':\n          return name\n      }\n      throw new Error(\n        `invalid placeholder ${placeholder} in assetFileNames \"${assetFileNames}\"`\n      )\n    }\n  )\n\n  return fileName\n}\n\n/**\n * Register an asset to be emitted as part of the bundle (if necessary)\n * and returns the resolved public URL\n */\nasync function fileToBuiltUrl(\n  id: string,\n  config: ResolvedConfig,\n  pluginContext: PluginContext,\n  skipPublicCheck = false\n): Promise<string> {\n  if (!skipPublicCheck && checkPublicFile(id, config)) {\n    return config.base + id.slice(1)\n  }\n\n  const cache = assetCache.get(config)!\n  const cached = cache.get(id)\n  if (cached) {\n    return cached\n  }\n\n  const file = cleanUrl(id)\n  const content = await fsp.readFile(file)\n\n  let url: string\n  if (\n    config.build.lib ||\n    (!file.endsWith('.svg') &&\n      content.length < Number(config.build.assetsInlineLimit))\n  ) {\n    // base64 inlined as a string\n    url = `data:${mime.getType(file)};base64,${content.toString('base64')}`\n  } else {\n    // emit as asset\n    // rollup supports `import.meta.ROLLUP_FILE_URL_*`, but it generates code\n    // that uses runtime url sniffing and it can be verbose when targeting\n    // non-module format. It also fails to cascade the asset content change\n    // into the chunk's hash, so we have to do our own content hashing here.\n    // https://bundlers.tooling.report/hashing/asset-cascade/\n    // https://github.com/rollup/rollup/issues/3415\n    const map = assetHashToFilenameMap.get(config)!\n    const contentHash = getAssetHash(content)\n    const { search, hash } = parseUrl(id)\n    const postfix = (search || '') + (hash || '')\n    const output = config.build?.rollupOptions?.output\n    const assetFileNames =\n      (output && !Array.isArray(output) ? output.assetFileNames : undefined) ??\n      // defaults to '<assetsDir>/[name].[hash][extname]'\n      // slightly different from rollup's one ('assets/[name]-[hash][extname]')\n      path.posix.join(config.build.assetsDir, '[name].[hash][extname]')\n    const fileName = assetFileNamesToFileName(\n      assetFileNames,\n      file,\n      contentHash,\n      content\n    )\n    if (!map.has(contentHash)) {\n      map.set(contentHash, fileName)\n    }\n    const emittedSet = emittedHashMap.get(config)!\n    if (!emittedSet.has(contentHash)) {\n      const name = normalizePath(path.relative(config.root, file))\n      pluginContext.emitFile({\n        name,\n        fileName,\n        type: 'asset',\n        source: content\n      })\n      emittedSet.add(contentHash)\n    }\n\n    url = `__VITE_ASSET__${contentHash}__${postfix ? `$_${postfix}__` : ``}`\n  }\n\n  cache.set(id, url)\n  return url\n}\n\nexport function getAssetHash(content: Buffer): string {\n  return createHash('sha256').update(content).digest('hex').slice(0, 8)\n}\n\nexport async function urlToBuiltUrl(\n  url: string,\n  importer: string,\n  config: ResolvedConfig,\n  pluginContext: PluginContext\n): Promise<string> {\n  if (checkPublicFile(url, config)) {\n    return config.base + url.slice(1)\n  }\n  const file = url.startsWith('/')\n    ? path.join(config.root, url)\n    : path.join(path.dirname(importer), url)\n  return fileToBuiltUrl(\n    file,\n    config,\n    pluginContext,\n    // skip public check since we just did it above\n    true\n  )\n}\n","export default { sync: () => [] }","export default () => {throw new Error(\"No PostCSS Config found\")}","import fs from 'fs'\nimport path from 'path'\nimport glob from 'fast-glob'\nimport {\n  // createDebugger,\n  isExternalUrl,\n  asyncReplace,\n  cleanUrl,\n  generateCodeFrame,\n  isDataUrl,\n  isObject,\n  normalizePath,\n  processSrcSet\n} from '../utils'\nimport { Plugin } from '../plugin'\nimport { ResolvedConfig } from '../config'\nimport postcssrc from 'postcss-load-config'\nimport {\n  NormalizedOutputOptions,\n  OutputChunk,\n  RenderedChunk,\n  RollupError,\n  SourceMap\n} from 'rollup'\nimport { dataToEsm } from '@rollup/pluginutils'\nimport chalk from 'chalk'\nimport { CLIENT_PUBLIC_PATH } from '../constants'\nimport { ResolveFn, ViteDevServer } from '../'\nimport {\n  getAssetFilename,\n  assetUrlRE,\n  registerAssetToChunk,\n  fileToUrl,\n  checkPublicFile\n} from './asset'\nimport MagicString from 'magic-string'\nimport * as Postcss from 'postcss'\nimport type Sass from 'sass'\n// We need to disable check of extraneous import which is buggy for stylus,\n// and causes the CI tests fail, see: https://github.com/vitejs/vite/pull/2860\nimport type Stylus from 'stylus' // eslint-disable-line node/no-extraneous-import\nimport type Less from 'less'\nimport { Alias } from 'types/alias'\nimport type { ModuleNode } from '../server/moduleGraph'\nimport { transform, formatMessages } from 'esbuild'\nimport { URL } from 'url'\n\n// const debug = createDebugger('vite:css')\n\nexport interface CSSOptions {\n  /**\n   * https://github.com/css-modules/postcss-modules\n   */\n  modules?: CSSModulesOptions | false\n  preprocessorOptions?: Record<string, any>\n  postcss?:\n    | string\n    | (Postcss.ProcessOptions & {\n        plugins?: Postcss.Plugin[]\n      })\n}\n\nexport interface CSSModulesOptions {\n  getJSON?: (\n    cssFileName: string,\n    json: Record<string, string>,\n    outputFileName: string\n  ) => void\n  scopeBehaviour?: 'global' | 'local'\n  globalModulePaths?: RegExp[]\n  generateScopedName?:\n    | string\n    | ((name: string, filename: string, css: string) => string)\n  hashPrefix?: string\n  /**\n   * default: null\n   */\n  localsConvention?:\n    | 'camelCase'\n    | 'camelCaseOnly'\n    | 'dashes'\n    | 'dashesOnly'\n    | null\n}\n\nconst cssLangs = `\\\\.(css|less|sass|scss|styl|stylus|pcss|postcss)($|\\\\?)`\nconst cssLangRE = new RegExp(cssLangs)\nconst cssModuleRE = new RegExp(`\\\\.module${cssLangs}`)\nconst directRequestRE = /(\\?|&)direct\\b/\nconst commonjsProxyRE = /\\?commonjs-proxy/\nconst inlineRE = /(\\?|&)inline\\b/\nconst usedRE = /(\\?|&)used\\b/\n\nconst enum PreprocessLang {\n  less = 'less',\n  sass = 'sass',\n  scss = 'scss',\n  styl = 'styl',\n  stylus = 'stylus'\n}\nconst enum PureCssLang {\n  css = 'css'\n}\ntype CssLang = keyof typeof PureCssLang | keyof typeof PreprocessLang\n\nexport const isCSSRequest = (request: string): boolean =>\n  cssLangRE.test(request)\n\nexport const isDirectCSSRequest = (request: string): boolean =>\n  cssLangRE.test(request) && directRequestRE.test(request)\n\nexport const isDirectRequest = (request: string): boolean =>\n  directRequestRE.test(request)\n\nconst cssModulesCache = new WeakMap<\n  ResolvedConfig,\n  Map<string, Record<string, string>>\n>()\n\nexport const chunkToEmittedCssFileMap = new WeakMap<\n  RenderedChunk,\n  Set<string>\n>()\n\nexport const removedPureCssFilesCache = new WeakMap<\n  ResolvedConfig,\n  Map<string, RenderedChunk>\n>()\n\nconst postcssConfigCache = new WeakMap<\n  ResolvedConfig,\n  PostCSSConfigResult | null\n>()\n\n/**\n * Plugin applied before user plugins\n */\nexport function cssPlugin(config: ResolvedConfig): Plugin {\n  let server: ViteDevServer\n  let moduleCache: Map<string, Record<string, string>>\n\n  const resolveUrl = config.createResolver({\n    preferRelative: true,\n    tryIndex: false,\n    extensions: []\n  })\n  const atImportResolvers = createCSSResolvers(config)\n\n  return {\n    name: 'vite:css',\n\n    configureServer(_server) {\n      server = _server\n    },\n\n    buildStart() {\n      // Ensure a new cache for every build (i.e. rebuilding in watch mode)\n      moduleCache = new Map<string, Record<string, string>>()\n      cssModulesCache.set(config, moduleCache)\n\n      removedPureCssFilesCache.set(config, new Map<string, RenderedChunk>())\n    },\n\n    async transform(raw, id, options) {\n      if (!isCSSRequest(id) || commonjsProxyRE.test(id)) {\n        return\n      }\n      const ssr = options?.ssr === true\n\n      const urlReplacer: CssUrlReplacer = async (url, importer) => {\n        if (checkPublicFile(url, config)) {\n          return config.base + url.slice(1)\n        }\n        const resolved = await resolveUrl(url, importer)\n        if (resolved) {\n          return fileToUrl(resolved, config, this)\n        }\n        return url\n      }\n\n      const {\n        code: css,\n        modules,\n        deps\n      } = await compileCSS(\n        id,\n        raw,\n        config,\n        urlReplacer,\n        atImportResolvers,\n        server\n      )\n      if (modules) {\n        moduleCache.set(id, modules)\n      }\n\n      // track deps for build watch mode\n      if (config.command === 'build' && config.build.watch && deps) {\n        for (const file of deps) {\n          this.addWatchFile(file)\n        }\n      }\n\n      // dev\n      if (server) {\n        // server only logic for handling CSS @import dependency hmr\n        const { moduleGraph } = server\n        const thisModule = moduleGraph.getModuleById(id)\n        if (thisModule) {\n          // CSS modules cannot self-accept since it exports values\n          const isSelfAccepting = !modules && !inlineRE.test(id)\n          if (deps) {\n            // record deps in the module graph so edits to @import css can trigger\n            // main import to hot update\n            const depModules = new Set<string | ModuleNode>()\n            for (const file of deps) {\n              depModules.add(\n                isCSSRequest(file)\n                  ? moduleGraph.createFileOnlyEntry(file)\n                  : await moduleGraph.ensureEntryFromUrl(\n                      (\n                        await fileToUrl(file, config, this)\n                      ).replace(\n                        (config.server?.origin ?? '') + config.base,\n                        '/'\n                      ),\n                      ssr\n                    )\n              )\n            }\n            moduleGraph.updateModuleInfo(\n              thisModule,\n              depModules,\n              // The root CSS proxy module is self-accepting and should not\n              // have an explicit accept list\n              new Set(),\n              isSelfAccepting,\n              ssr\n            )\n            for (const file of deps) {\n              this.addWatchFile(file)\n            }\n          } else {\n            thisModule.isSelfAccepting = isSelfAccepting\n          }\n        }\n      }\n\n      return {\n        code: css,\n        // TODO CSS source map\n        map: { mappings: '' }\n      }\n    }\n  }\n}\n\n/**\n * Plugin applied after user plugins\n */\nexport function cssPostPlugin(config: ResolvedConfig): Plugin {\n  // styles initialization in buildStart causes a styling loss in watch\n  const styles: Map<string, string> = new Map<string, string>()\n  let pureCssChunks: Set<string>\n\n  // when there are multiple rollup outputs and extracting CSS, only emit once,\n  // since output formats have no effect on the generated CSS.\n  let outputToExtractedCSSMap: Map<NormalizedOutputOptions, string>\n  let hasEmitted = false\n\n  return {\n    name: 'vite:css-post',\n\n    buildStart() {\n      // Ensure new caches for every build (i.e. rebuilding in watch mode)\n      pureCssChunks = new Set<string>()\n      outputToExtractedCSSMap = new Map<NormalizedOutputOptions, string>()\n      hasEmitted = false\n    },\n\n    async transform(css, id, options) {\n      if (!isCSSRequest(id) || commonjsProxyRE.test(id)) {\n        return\n      }\n\n      const inlined = inlineRE.test(id)\n      const modules = cssModulesCache.get(config)!.get(id)\n      const modulesCode =\n        modules && dataToEsm(modules, { namedExports: true, preferConst: true })\n\n      if (config.command === 'serve') {\n        if (isDirectCSSRequest(id)) {\n          return css\n        } else {\n          // server only\n          if (options?.ssr) {\n            return modulesCode || `export default ${JSON.stringify(css)}`\n          }\n          if (inlined) {\n            return `export default ${JSON.stringify(css)}`\n          }\n          return [\n            `import { updateStyle, removeStyle } from ${JSON.stringify(\n              path.posix.join(config.base, CLIENT_PUBLIC_PATH)\n            )}`,\n            `const id = ${JSON.stringify(id)}`,\n            `const css = ${JSON.stringify(css)}`,\n            `updateStyle(id, css)`,\n            // css modules exports change on edit so it can't self accept\n            `${modulesCode || `import.meta.hot.accept()\\nexport default css`}`,\n            `import.meta.hot.prune(() => removeStyle(id))`\n          ].join('\\n')\n        }\n      }\n\n      // build CSS handling ----------------------------------------------------\n\n      // record css\n      if (!inlined) {\n        styles.set(id, css)\n      }\n\n      return {\n        code:\n          modulesCode ||\n          (usedRE.test(id)\n            ? `export default ${JSON.stringify(\n                inlined ? await minifyCSS(css, config) : css\n              )}`\n            : `export default ''`),\n        map: { mappings: '' },\n        // avoid the css module from being tree-shaken so that we can retrieve\n        // it in renderChunk()\n        moduleSideEffects: inlined ? false : 'no-treeshake'\n      }\n    },\n\n    async renderChunk(code, chunk, opts) {\n      let chunkCSS = ''\n      let isPureCssChunk = true\n      const ids = Object.keys(chunk.modules)\n      for (const id of ids) {\n        if (\n          !isCSSRequest(id) ||\n          cssModuleRE.test(id) ||\n          commonjsProxyRE.test(id)\n        ) {\n          isPureCssChunk = false\n        }\n        if (styles.has(id)) {\n          chunkCSS += styles.get(id)\n        }\n      }\n\n      if (!chunkCSS) {\n        return null\n      }\n\n      // resolve asset URL placeholders to their built file URLs and perform\n      // minification if necessary\n      const processChunkCSS = async (\n        css: string,\n        {\n          inlined,\n          minify\n        }: {\n          inlined: boolean\n          minify: boolean\n        }\n      ) => {\n        // replace asset url references with resolved url.\n        const isRelativeBase = config.base === '' || config.base.startsWith('.')\n        css = css.replace(assetUrlRE, (_, fileHash, postfix = '') => {\n          const filename = getAssetFilename(fileHash, config) + postfix\n          registerAssetToChunk(chunk, filename)\n          if (!isRelativeBase || inlined) {\n            // absolute base or relative base but inlined (injected as style tag into\n            // index.html) use the base as-is\n            return config.base + filename\n          } else {\n            // relative base + extracted CSS - asset file will be in the same dir\n            return `./${path.posix.basename(filename)}`\n          }\n        })\n        // only external @imports should exist at this point - and they need to\n        // be hoisted to the top of the CSS chunk per spec (#1845)\n        if (css.includes('@import')) {\n          css = await hoistAtImports(css)\n        }\n        if (minify && config.build.minify) {\n          css = await minifyCSS(css, config)\n        }\n        return css\n      }\n\n      if (config.build.cssCodeSplit) {\n        if (isPureCssChunk) {\n          // this is a shared CSS-only chunk that is empty.\n          pureCssChunks.add(chunk.fileName)\n        }\n        if (opts.format === 'es' || opts.format === 'cjs') {\n          chunkCSS = await processChunkCSS(chunkCSS, {\n            inlined: false,\n            minify: true\n          })\n          // emit corresponding css file\n          const fileHandle = this.emitFile({\n            name: chunk.name + '.css',\n            type: 'asset',\n            source: chunkCSS\n          })\n          chunkToEmittedCssFileMap.set(\n            chunk,\n            new Set([this.getFileName(fileHandle)])\n          )\n        } else if (!config.build.ssr) {\n          // legacy build, inline css\n          chunkCSS = await processChunkCSS(chunkCSS, {\n            inlined: true,\n            minify: true\n          })\n          const style = `__vite_style__`\n          const injectCode =\n            `var ${style} = document.createElement('style');` +\n            `${style}.innerHTML = ${JSON.stringify(chunkCSS)};` +\n            `document.head.appendChild(${style});`\n          if (config.build.sourcemap) {\n            const s = new MagicString(code)\n            s.prepend(injectCode)\n            return {\n              code: s.toString(),\n              map: s.generateMap({ hires: true })\n            }\n          } else {\n            return { code: injectCode + code }\n          }\n        }\n      } else {\n        // non-split extracted CSS will be minified together\n        chunkCSS = await processChunkCSS(chunkCSS, {\n          inlined: false,\n          minify: false\n        })\n        outputToExtractedCSSMap.set(\n          opts,\n          (outputToExtractedCSSMap.get(opts) || '') + chunkCSS\n        )\n      }\n      return null\n    },\n\n    async generateBundle(opts, bundle) {\n      // remove empty css chunks and their imports\n      if (pureCssChunks.size) {\n        const emptyChunkFiles = [...pureCssChunks]\n          .map((file) => path.basename(file))\n          .join('|')\n          .replace(/\\./g, '\\\\.')\n        const emptyChunkRE = new RegExp(\n          opts.format === 'es'\n            ? `\\\\bimport\\\\s*\"[^\"]*(?:${emptyChunkFiles})\";\\n?`\n            : `\\\\brequire\\\\(\\\\s*\"[^\"]*(?:${emptyChunkFiles})\"\\\\);\\n?`,\n          'g'\n        )\n        for (const file in bundle) {\n          const chunk = bundle[file]\n          if (chunk.type === 'chunk') {\n            // remove pure css chunk from other chunk's imports,\n            // and also register the emitted CSS files under the importer\n            // chunks instead.\n            chunk.imports = chunk.imports.filter((file) => {\n              if (pureCssChunks.has(file)) {\n                const css = chunkToEmittedCssFileMap.get(\n                  bundle[file] as OutputChunk\n                )\n                if (css) {\n                  let existing = chunkToEmittedCssFileMap.get(chunk)\n                  if (!existing) {\n                    existing = new Set()\n                  }\n                  css.forEach((file) => existing!.add(file))\n                  chunkToEmittedCssFileMap.set(chunk, existing)\n                }\n                return false\n              }\n              return true\n            })\n            chunk.code = chunk.code.replace(\n              emptyChunkRE,\n              // remove css import while preserving source map location\n              (m) => `/* empty css ${''.padEnd(m.length - 15)}*/`\n            )\n          }\n        }\n        const removedPureCssFiles = removedPureCssFilesCache.get(config)!\n        pureCssChunks.forEach((fileName) => {\n          removedPureCssFiles.set(fileName, bundle[fileName] as RenderedChunk)\n          delete bundle[fileName]\n        })\n      }\n\n      let extractedCss = outputToExtractedCSSMap.get(opts)\n      if (extractedCss && !hasEmitted) {\n        hasEmitted = true\n        // minify css\n        if (config.build.minify) {\n          extractedCss = await minifyCSS(extractedCss, config)\n        }\n        this.emitFile({\n          name: 'style.css',\n          type: 'asset',\n          source: extractedCss\n        })\n      }\n    }\n  }\n}\n\ninterface CSSAtImportResolvers {\n  css: ResolveFn\n  sass: ResolveFn\n  less: ResolveFn\n}\n\nfunction createCSSResolvers(config: ResolvedConfig): CSSAtImportResolvers {\n  let cssResolve: ResolveFn | undefined\n  let sassResolve: ResolveFn | undefined\n  let lessResolve: ResolveFn | undefined\n  return {\n    get css() {\n      return (\n        cssResolve ||\n        (cssResolve = config.createResolver({\n          extensions: ['.css'],\n          mainFields: ['style'],\n          tryIndex: false,\n          preferRelative: true\n        }))\n      )\n    },\n\n    get sass() {\n      return (\n        sassResolve ||\n        (sassResolve = config.createResolver({\n          extensions: ['.scss', '.sass', '.css'],\n          mainFields: ['sass', 'style'],\n          tryIndex: true,\n          tryPrefix: '_',\n          preferRelative: true\n        }))\n      )\n    },\n\n    get less() {\n      return (\n        lessResolve ||\n        (lessResolve = config.createResolver({\n          extensions: ['.less', '.css'],\n          mainFields: ['less', 'style'],\n          tryIndex: false,\n          preferRelative: true\n        }))\n      )\n    }\n  }\n}\n\nfunction getCssResolversKeys(\n  resolvers: CSSAtImportResolvers\n): Array<keyof CSSAtImportResolvers> {\n  return Object.keys(resolvers) as unknown as Array<keyof CSSAtImportResolvers>\n}\n\nasync function compileCSS(\n  id: string,\n  code: string,\n  config: ResolvedConfig,\n  urlReplacer: CssUrlReplacer,\n  atImportResolvers: CSSAtImportResolvers,\n  server?: ViteDevServer\n): Promise<{\n  code: string\n  map?: SourceMap\n  ast?: Postcss.Result\n  modules?: Record<string, string>\n  deps?: Set<string>\n}> {\n  const { modules: modulesOptions, preprocessorOptions } = config.css || {}\n  const isModule = modulesOptions !== false && cssModuleRE.test(id)\n  // although at serve time it can work without processing, we do need to\n  // crawl them in order to register watch dependencies.\n  const needInlineImport = code.includes('@import')\n  const hasUrl = cssUrlRE.test(code) || cssImageSetRE.test(code)\n  const postcssConfig = await resolvePostcssConfig(config)\n  const lang = id.match(cssLangRE)?.[1] as CssLang | undefined\n\n  // 1. plain css that needs no processing\n  if (\n    lang === 'css' &&\n    !postcssConfig &&\n    !isModule &&\n    !needInlineImport &&\n    !hasUrl\n  ) {\n    return { code }\n  }\n\n  let map: SourceMap | undefined\n  let modules: Record<string, string> | undefined\n  const deps = new Set<string>()\n\n  // 2. pre-processors: sass etc.\n  if (isPreProcessor(lang)) {\n    const preProcessor = preProcessors[lang]\n    let opts = (preprocessorOptions && preprocessorOptions[lang]) || {}\n    // support @import from node dependencies by default\n    switch (lang) {\n      case PreprocessLang.scss:\n      case PreprocessLang.sass:\n        opts = {\n          includePaths: ['node_modules'],\n          alias: config.resolve.alias,\n          ...opts\n        }\n        break\n      case PreprocessLang.less:\n      case PreprocessLang.styl:\n      case PreprocessLang.stylus:\n        opts = {\n          paths: ['node_modules'],\n          alias: config.resolve.alias,\n          ...opts\n        }\n    }\n    // important: set this for relative import resolving\n    opts.filename = cleanUrl(id)\n    const preprocessResult = await preProcessor(\n      code,\n      config.root,\n      opts,\n      atImportResolvers\n    )\n    if (preprocessResult.errors.length) {\n      throw preprocessResult.errors[0]\n    }\n\n    code = preprocessResult.code\n    map = preprocessResult.map as SourceMap\n    if (preprocessResult.deps) {\n      preprocessResult.deps.forEach((dep) => {\n        // sometimes sass registers the file itself as a dep\n        if (normalizePath(dep) !== normalizePath(opts.filename)) {\n          deps.add(dep)\n        }\n      })\n    }\n  }\n\n  // 3. postcss\n  const postcssOptions = (postcssConfig && postcssConfig.options) || {}\n  const postcssPlugins =\n    postcssConfig && postcssConfig.plugins ? postcssConfig.plugins.slice() : []\n\n  if (needInlineImport) {\n    postcssPlugins.unshift(\n      (await import('postcss-import')).default({\n        async resolve(id, basedir) {\n          const resolved = await atImportResolvers.css(\n            id,\n            path.join(basedir, '*')\n          )\n          if (resolved) {\n            return path.resolve(resolved)\n          }\n          return id\n        }\n      })\n    )\n  }\n  postcssPlugins.push(\n    UrlRewritePostcssPlugin({\n      replacer: urlReplacer\n    }) as Postcss.Plugin\n  )\n\n  if (isModule) {\n    postcssPlugins.unshift(\n      (await import('postcss-modules')).default({\n        ...modulesOptions,\n        getJSON(\n          cssFileName: string,\n          _modules: Record<string, string>,\n          outputFileName: string\n        ) {\n          modules = _modules\n          if (modulesOptions && typeof modulesOptions.getJSON === 'function') {\n            modulesOptions.getJSON(cssFileName, _modules, outputFileName)\n          }\n        },\n        async resolve(id: string) {\n          for (const key of getCssResolversKeys(atImportResolvers)) {\n            const resolved = await atImportResolvers[key](id)\n            if (resolved) {\n              return path.resolve(resolved)\n            }\n          }\n\n          return id\n        }\n      })\n    )\n  }\n\n  if (!postcssPlugins.length) {\n    return {\n      code,\n      map\n    }\n  }\n\n  // postcss is an unbundled dep and should be lazy imported\n  const postcssResult = await (await import('postcss'))\n    .default(postcssPlugins)\n    .process(code, {\n      ...postcssOptions,\n      to: id,\n      from: id,\n      map: {\n        inline: false,\n        annotation: false,\n        prev: map\n      }\n    })\n\n  // record CSS dependencies from @imports\n  for (const message of postcssResult.messages) {\n    if (message.type === 'dependency') {\n      deps.add(message.file as string)\n    } else if (message.type === 'dir-dependency') {\n      // https://github.com/postcss/postcss/blob/main/docs/guidelines/plugin.md#3-dependencies\n      const { dir, glob: globPattern = '**' } = message\n      const pattern =\n        normalizePath(path.resolve(path.dirname(id), dir)) + `/` + globPattern\n      const files = glob.sync(pattern, {\n        ignore: ['**/node_modules/**']\n      })\n      for (let i = 0; i < files.length; i++) {\n        deps.add(files[i])\n      }\n      if (server) {\n        // register glob importers so we can trigger updates on file add/remove\n        if (!(id in server._globImporters)) {\n          server._globImporters[id] = {\n            module: server.moduleGraph.getModuleById(id)!,\n            importGlobs: []\n          }\n        }\n        server._globImporters[id].importGlobs.push({\n          base: config.root,\n          pattern\n        })\n      }\n    } else if (message.type === 'warning') {\n      let msg = `[vite:css] ${message.text}`\n      if (message.line && message.column) {\n        msg += `\\n${generateCodeFrame(code, {\n          line: message.line,\n          column: message.column\n        })}`\n      }\n      config.logger.warn(chalk.yellow(msg))\n    }\n  }\n\n  return {\n    ast: postcssResult,\n    code: postcssResult.css,\n    map: postcssResult.map as any,\n    modules,\n    deps\n  }\n}\n\ninterface PostCSSConfigResult {\n  options: Postcss.ProcessOptions\n  plugins: Postcss.Plugin[]\n}\n\nasync function resolvePostcssConfig(\n  config: ResolvedConfig\n): Promise<PostCSSConfigResult | null> {\n  let result = postcssConfigCache.get(config)\n  if (result !== undefined) {\n    return result\n  }\n\n  // inline postcss config via vite config\n  const inlineOptions = config.css?.postcss\n  if (isObject(inlineOptions)) {\n    const options = { ...inlineOptions }\n\n    delete options.plugins\n    result = {\n      options,\n      plugins: inlineOptions.plugins || []\n    }\n  } else {\n    try {\n      const searchPath =\n        typeof inlineOptions === 'string' ? inlineOptions : config.root\n      // @ts-ignore\n      result = await postcssrc({}, searchPath)\n    } catch (e) {\n      if (!/No PostCSS Config found/.test(e.message)) {\n        throw e\n      }\n      result = null\n    }\n  }\n\n  postcssConfigCache.set(config, result)\n  return result\n}\n\ntype CssUrlReplacer = (\n  url: string,\n  importer?: string\n) => string | Promise<string>\n// https://drafts.csswg.org/css-syntax-3/#identifier-code-point\n// BROWSER VITE patch: no lookbehind for safari support\nexport const cssUrlRE =\n  /(?:^|[^\\w\\-\\u0080-\\uffff])url\\(\\s*('[^']+'|\"[^\"]+\"|[^'\")]+)\\s*\\)/\nconst cssImageSetRE = /image-set\\(([^)]+)\\)/\n\nconst UrlRewritePostcssPlugin: Postcss.PluginCreator<{\n  replacer: CssUrlReplacer\n}> = (opts) => {\n  if (!opts) {\n    throw new Error('base or replace is required')\n  }\n\n  return {\n    postcssPlugin: 'vite-url-rewrite',\n    Once(root) {\n      const promises: Promise<void>[] = []\n      root.walkDecls((declaration) => {\n        const isCssUrl = cssUrlRE.test(declaration.value)\n        const isCssImageSet = cssImageSetRE.test(declaration.value)\n        if (isCssUrl || isCssImageSet) {\n          const replacerForDeclaration = (rawUrl: string) => {\n            const importer = declaration.source?.input.file\n            return opts.replacer(rawUrl, importer)\n          }\n          const rewriterToUse = isCssUrl ? rewriteCssUrls : rewriteCssImageSet\n          promises.push(\n            rewriterToUse(declaration.value, replacerForDeclaration).then(\n              (url) => {\n                declaration.value = url\n              }\n            )\n          )\n        }\n      })\n      if (promises.length) {\n        return Promise.all(promises) as any\n      }\n    }\n  }\n}\nUrlRewritePostcssPlugin.postcss = true\n\nfunction rewriteCssUrls(\n  css: string,\n  replacer: CssUrlReplacer\n): Promise<string> {\n  return asyncReplace(css, cssUrlRE, async (match) => {\n    const [matched, rawUrl] = match\n    return await doUrlReplace(rawUrl, matched, replacer)\n  })\n}\n\nfunction rewriteCssImageSet(\n  css: string,\n  replacer: CssUrlReplacer\n): Promise<string> {\n  return asyncReplace(css, cssImageSetRE, async (match) => {\n    const [matched, rawUrl] = match\n    const url = await processSrcSet(rawUrl, ({ url }) =>\n      doUrlReplace(url, matched, replacer)\n    )\n    return `image-set(${url})`\n  })\n}\nasync function doUrlReplace(\n  rawUrl: string,\n  matched: string,\n  replacer: CssUrlReplacer\n) {\n  let wrap = ''\n  const first = rawUrl[0]\n  if (first === `\"` || first === `'`) {\n    wrap = first\n    rawUrl = rawUrl.slice(1, -1)\n  }\n  if (isExternalUrl(rawUrl) || isDataUrl(rawUrl) || rawUrl.startsWith('#')) {\n    return matched\n  }\n\n  return `url(${wrap}${await replacer(rawUrl)}${wrap})`\n}\n\nasync function minifyCSS(css: string, config: ResolvedConfig) {\n  const { code, warnings } = await transform(css, {\n    loader: 'css',\n    minify: true,\n    target: config.build.cssTarget || undefined\n  })\n  if (warnings.length) {\n    const msgs = await formatMessages(warnings, { kind: 'warning' })\n    config.logger.warn(\n      chalk.yellow(`warnings when minifying css:\\n${msgs.join('\\n')}`)\n    )\n  }\n  return code\n}\n\n// #1845\n// CSS @import can only appear at top of the file. We need to hoist all @import\n// to top when multiple files are concatenated.\nasync function hoistAtImports(css: string) {\n  const postcss = await import('postcss')\n  return (await postcss.default([AtImportHoistPlugin]).process(css)).css\n}\n\nconst AtImportHoistPlugin: Postcss.PluginCreator<any> = () => {\n  return {\n    postcssPlugin: 'vite-hoist-at-imports',\n    Once(root) {\n      const imports: Postcss.AtRule[] = []\n      root.walkAtRules((rule) => {\n        if (rule.name === 'import') {\n          // record in reverse so that can simply prepend to preserve order\n          imports.unshift(rule)\n        }\n      })\n      imports.forEach((i) => root.prepend(i))\n    }\n  }\n}\nAtImportHoistPlugin.postcss = true\n\n// Preprocessor support. This logic is largely replicated from @vue/compiler-sfc\n\ntype PreprocessorAdditionalData =\n  | string\n  | ((source: string, filename: string) => string | Promise<string>)\n\ntype StylePreprocessorOptions = {\n  [key: string]: any\n  additionalData?: PreprocessorAdditionalData\n  filename: string\n  alias: Alias[]\n}\n\ntype SassStylePreprocessorOptions = StylePreprocessorOptions & Sass.Options\n\ntype StylePreprocessor = (\n  source: string,\n  root: string,\n  options: StylePreprocessorOptions,\n  resolvers: CSSAtImportResolvers\n) => StylePreprocessorResults | Promise<StylePreprocessorResults>\n\ntype SassStylePreprocessor = (\n  source: string,\n  root: string,\n  options: SassStylePreprocessorOptions,\n  resolvers: CSSAtImportResolvers\n) => StylePreprocessorResults | Promise<StylePreprocessorResults>\n\nexport interface StylePreprocessorResults {\n  code: string\n  map?: object\n  errors: RollupError[]\n  deps: string[]\n}\n\nconst loadedPreprocessors: Partial<Record<PreprocessLang, any>> = {}\n\nfunction loadPreprocessor(lang: PreprocessLang.scss, root: string): typeof Sass\nfunction loadPreprocessor(lang: PreprocessLang.sass, root: string): typeof Sass\nfunction loadPreprocessor(lang: PreprocessLang.less, root: string): typeof Less\nfunction loadPreprocessor(\n  lang: PreprocessLang.stylus,\n  root: string\n): typeof Stylus\nfunction loadPreprocessor(lang: PreprocessLang, root: string): any {\n  if (lang in loadedPreprocessors) {\n    return loadedPreprocessors[lang]\n  }\n  try {\n    // Search for the preprocessor in the root directory first, and fall back\n    // to the default require paths.\n    const fallbackPaths = require.resolve.paths?.(lang) || []\n    const resolved = require.resolve(lang, { paths: [root, ...fallbackPaths] })\n    return (loadedPreprocessors[lang] = require(resolved))\n  } catch (e) {\n    if (e.code === 'MODULE_NOT_FOUND') {\n      throw new Error(\n        `Preprocessor dependency \"${lang}\" not found. Did you install it?`\n      )\n    } else {\n      const message = new Error(\n        `Preprocessor dependency \"${lang}\" failed to load:\\n${e.message}`\n      )\n      message.stack = e.stack + '\\n' + message.stack\n      throw message\n    }\n  }\n}\n\n// .scss/.sass processor\nconst scss: SassStylePreprocessor = async (\n  source,\n  root,\n  options,\n  resolvers\n) => {\n  // BROWSER VITE patch: when running in-browser, sass will provide importer as location.origin based url\n  const toLocal = (url: string) =>\n    isExternalUrl(url) ? new URL(url).pathname : url\n\n  // BROWSER VITE patch: dynamic sass import\n  const render = (await import('sass').then((m)=>m.default||m)).render\n  const internalImporter: Sass.Importer = (url, importer, done) => {\n    importer = toLocal(importer)\n    resolvers.sass(url, importer).then((resolved) => {\n      if (resolved) {\n        // BROWSER VITE patch: fix https://github.com/vitejs/vite/issues/5337\n        const file = path.resolve(resolved)\n        done?.({ file, contents: fs.readFileSync(file, 'utf-8') })\n      } else {\n        done?.(null)\n      }\n    })\n  }\n  const importer = [internalImporter]\n  if (options.importer) {\n    Array.isArray(options.importer)\n      ? importer.push(...options.importer)\n      : importer.push(options.importer)\n  }\n\n  const finalOptions: Sass.Options = {\n    ...options,\n    data: await getSource(source, options.filename, options.additionalData),\n    file: options.filename,\n    outFile: options.filename,\n    importer\n  }\n\n  try {\n    const result = await new Promise<Sass.Result>((resolve, reject) => {\n      render(finalOptions, (err, res) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(res)\n        }\n      })\n    })\n    const deps = result.stats.includedFiles?.map((file) => toLocal(file))\n\n    return {\n      code: result.css.toString(),\n      errors: [],\n      deps\n    }\n  } catch (e) {\n    // normalize SASS error\n    e.id = e.file\n    e.frame = e.formatted\n    return { code: '', errors: [e], deps: [] }\n  }\n}\n\nconst sass: SassStylePreprocessor = (source, root, options, aliasResolver) =>\n  scss(\n    source,\n    root,\n    {\n      ...options,\n      indentedSyntax: true\n    },\n    aliasResolver\n  )\n\n/**\n * relative url() inside \\@imported sass and less files must be rebased to use\n * root file as base.\n */\nasync function rebaseUrls(\n  file: string,\n  rootFile: string,\n  alias: Alias[]\n): Promise<Sass.ImporterReturnType> {\n  file = path.resolve(file) // ensure os-specific flashes\n  // in the same dir, no need to rebase\n  const fileDir = path.dirname(file)\n  const rootDir = path.dirname(rootFile)\n  // no url()\n  const content = fs.readFileSync(file, 'utf-8')\n  // BROWSER VITE patch: always return content (browser sass has no FS access)\n  if (fileDir === rootDir || !cssUrlRE.test(content)) {\n    return { file, contents: content }\n  }\n  const rebased = await rewriteCssUrls(content, (url) => {\n    if (url.startsWith('/')) return url\n    // match alias, no need to rewrite\n    for (const { find } of alias) {\n      const matches =\n        typeof find === 'string' ? url.startsWith(find) : find.test(url)\n      if (matches) {\n        return url\n      }\n    }\n    const absolute = path.resolve(fileDir, url)\n    const relative = path.relative(rootDir, absolute)\n    return normalizePath(relative)\n  })\n  return {\n    file,\n    contents: rebased\n  }\n}\n\n// .less\nconst less: StylePreprocessor = async (source, root, options, resolvers) => {\n  const nodeLess = loadPreprocessor(PreprocessLang.less, root)\n  const viteResolverPlugin = createViteLessPlugin(\n    nodeLess,\n    options.filename,\n    options.alias,\n    resolvers\n  )\n  source = await getSource(source, options.filename, options.additionalData)\n\n  let result: Less.RenderOutput | undefined\n  try {\n    result = await nodeLess.render(source, {\n      ...options,\n      plugins: [viteResolverPlugin, ...(options.plugins || [])]\n    })\n  } catch (e) {\n    const error = e as Less.RenderError\n    // normalize error info\n    const normalizedError: RollupError = new Error(error.message || error.type)\n    normalizedError.loc = {\n      file: error.filename || options.filename,\n      line: error.line,\n      column: error.column\n    }\n    return { code: '', errors: [normalizedError], deps: [] }\n  }\n  return {\n    code: result.css.toString(),\n    deps: result.imports,\n    errors: []\n  }\n}\n\n/**\n * Less manager, lazy initialized\n */\nlet ViteLessManager: any\n\nfunction createViteLessPlugin(\n  less: typeof Less,\n  rootFile: string,\n  alias: Alias[],\n  resolvers: CSSAtImportResolvers\n): Less.Plugin {\n  if (!ViteLessManager) {\n    ViteLessManager = class ViteManager extends less.FileManager {\n      resolvers\n      rootFile\n      alias\n      constructor(\n        rootFile: string,\n        resolvers: CSSAtImportResolvers,\n        alias: Alias[]\n      ) {\n        super()\n        this.rootFile = rootFile\n        this.resolvers = resolvers\n        this.alias = alias\n      }\n      override supports() {\n        return true\n      }\n      override supportsSync() {\n        return false\n      }\n      override async loadFile(\n        filename: string,\n        dir: string,\n        opts: any,\n        env: any\n      ): Promise<Less.FileLoadResult> {\n        const resolved = await this.resolvers.less(\n          filename,\n          path.join(dir, '*')\n        )\n        if (resolved) {\n          const result = await rebaseUrls(resolved, this.rootFile, this.alias)\n          let contents: string\n          if (result && 'contents' in result) {\n            contents = result.contents\n          } else {\n            contents = fs.readFileSync(resolved, 'utf-8')\n          }\n          return {\n            filename: path.resolve(resolved),\n            contents\n          }\n        } else {\n          return super.loadFile(filename, dir, opts, env)\n        }\n      }\n    }\n  }\n\n  return {\n    install(_, pluginManager) {\n      pluginManager.addFileManager(\n        new ViteLessManager(rootFile, resolvers, alias)\n      )\n    },\n    minVersion: [3, 0, 0]\n  }\n}\n\n// .styl\nconst styl: StylePreprocessor = async (source, root, options) => {\n  const nodeStylus = loadPreprocessor(PreprocessLang.stylus, root)\n  // Get source with preprocessor options.additionalData. Make sure a new line separator\n  // is added to avoid any render error, as added stylus content may not have semi-colon separators\n  source = await getSource(\n    source,\n    options.filename,\n    options.additionalData,\n    '\\n'\n  )\n  // Get preprocessor options.imports dependencies as stylus\n  // does not return them with its builtin `.deps()` method\n  const importsDeps = (options.imports ?? []).map((dep: string) =>\n    path.resolve(dep)\n  )\n  try {\n    const ref = nodeStylus(source, options)\n\n    // if (map) ref.set('sourcemap', { inline: false, comment: false })\n\n    const result = ref.render()\n\n    // Concat imports deps with computed deps\n    const deps = [...ref.deps(), ...importsDeps]\n\n    return { code: result, errors: [], deps }\n  } catch (e) {\n    return { code: '', errors: [e], deps: [] }\n  }\n}\n\nfunction getSource(\n  source: string,\n  filename: string,\n  additionalData?: PreprocessorAdditionalData,\n  sep: string = ''\n): string | Promise<string> {\n  if (!additionalData) return source\n  if (typeof additionalData === 'function') {\n    return additionalData(source, filename)\n  }\n  return additionalData + sep + source\n}\n\nconst preProcessors = Object.freeze({\n  [PreprocessLang.less]: less,\n  [PreprocessLang.sass]: sass,\n  [PreprocessLang.scss]: scss,\n  [PreprocessLang.styl]: styl,\n  [PreprocessLang.stylus]: styl\n})\n\nfunction isPreProcessor(lang: any): lang is PreprocessLang {\n  return lang && lang in preProcessors\n}\n","import path from 'path'\nimport glob from 'fast-glob'\nimport {\n  isModernFlag,\n  preloadMethod,\n  preloadMarker\n} from './plugins/importAnalysisBuild'\nimport { cleanUrl } from './utils'\nimport { RollupError } from 'rollup'\n\nexport async function transformImportGlob(\n  source: string,\n  pos: number,\n  importer: string,\n  importIndex: number,\n  root: string,\n  normalizeUrl?: (url: string, pos: number) => Promise<[string, string]>,\n  preload = true\n): Promise<{\n  importsString: string\n  imports: string[]\n  exp: string\n  endIndex: number\n  isEager: boolean\n  pattern: string\n  base: string\n}> {\n  const isEager = source.slice(pos, pos + 21) === 'import.meta.globEager'\n  const isEagerDefault =\n    isEager && source.slice(pos + 21, pos + 28) === 'Default'\n\n  const err = (msg: string) => {\n    const e = new Error(`Invalid glob import syntax: ${msg}`)\n    ;(e as any).pos = pos\n    return e\n  }\n\n  importer = cleanUrl(importer)\n  const importerBasename = path.basename(importer)\n\n  let [pattern, endIndex] = lexGlobPattern(source, pos)\n  if (!pattern.startsWith('.') && !pattern.startsWith('/')) {\n    throw err(`pattern must start with \".\" or \"/\" (relative to project root)`)\n  }\n  let base: string\n  let parentDepth = 0\n  const isAbsolute = pattern.startsWith('/')\n  if (isAbsolute) {\n    base = path.resolve(root)\n    pattern = pattern.slice(1)\n  } else {\n    base = path.dirname(importer)\n    while (pattern.startsWith('../')) {\n      pattern = pattern.slice(3)\n      base = path.resolve(base, '../')\n      parentDepth++\n    }\n    if (pattern.startsWith('./')) {\n      pattern = pattern.slice(2)\n    }\n  }\n  const files = glob.sync(pattern, {\n    cwd: base,\n    ignore: ['**/node_modules/**']\n  })\n  const imports: string[] = []\n  let importsString = ``\n  let entries = ``\n  for (let i = 0; i < files.length; i++) {\n    // skip importer itself\n    if (files[i] === importerBasename) continue\n    const file = isAbsolute\n      ? `/${files[i]}`\n      : parentDepth\n      ? `${'../'.repeat(parentDepth)}${files[i]}`\n      : `./${files[i]}`\n    let importee = file\n    if (normalizeUrl) {\n      ;[importee] = await normalizeUrl(file, pos)\n    }\n    imports.push(importee)\n    const identifier = `__glob_${importIndex}_${i}`\n    if (isEager) {\n      importsString += `import ${\n        isEagerDefault ? `` : `* as `\n      }${identifier} from ${JSON.stringify(importee)};`\n      entries += ` ${JSON.stringify(file)}: ${identifier},`\n    } else {\n      let imp = `import(${JSON.stringify(importee)})`\n      if (!normalizeUrl && preload) {\n        imp =\n          `(${isModernFlag}` +\n          `? ${preloadMethod}(()=>${imp},\"${preloadMarker}\")` +\n          `: ${imp})`\n      }\n      entries += ` ${JSON.stringify(file)}: () => ${imp},`\n    }\n  }\n\n  return {\n    imports,\n    importsString,\n    exp: `{${entries}}`,\n    endIndex,\n    isEager,\n    pattern,\n    base\n  }\n}\n\nconst enum LexerState {\n  inCall,\n  inSingleQuoteString,\n  inDoubleQuoteString,\n  inTemplateString\n}\n\nfunction lexGlobPattern(code: string, pos: number): [string, number] {\n  let state = LexerState.inCall\n  let pattern = ''\n\n  let i = code.indexOf(`(`, pos) + 1\n  outer: for (; i < code.length; i++) {\n    const char = code.charAt(i)\n    switch (state) {\n      case LexerState.inCall:\n        if (char === `'`) {\n          state = LexerState.inSingleQuoteString\n        } else if (char === `\"`) {\n          state = LexerState.inDoubleQuoteString\n        } else if (char === '`') {\n          state = LexerState.inTemplateString\n        } else if (/\\s/.test(char)) {\n          continue\n        } else {\n          error(i)\n        }\n        break\n      case LexerState.inSingleQuoteString:\n        if (char === `'`) {\n          break outer\n        } else {\n          pattern += char\n        }\n        break\n      case LexerState.inDoubleQuoteString:\n        if (char === `\"`) {\n          break outer\n        } else {\n          pattern += char\n        }\n        break\n      case LexerState.inTemplateString:\n        if (char === '`') {\n          break outer\n        } else {\n          pattern += char\n        }\n        break\n      default:\n        throw new Error('unknown import.meta.glob lexer state')\n    }\n  }\n  return [pattern, code.indexOf(`)`, i) + 1]\n}\n\nfunction error(pos: number) {\n  const err = new Error(\n    `import.meta.glob() can only accept string literals.`\n  ) as RollupError\n  err.pos = pos\n  throw err\n}\n","import path from 'path'\nimport { ResolvedConfig } from '../config'\nimport { Plugin } from '../plugin'\nimport MagicString from 'magic-string'\nimport { ImportSpecifier, init, parse as parseImports } from 'es-module-lexer'\nimport { OutputChunk } from 'rollup'\nimport {\n  chunkToEmittedCssFileMap,\n  isCSSRequest,\n  removedPureCssFilesCache\n} from './css'\nimport { transformImportGlob } from '../importGlob'\nimport { bareImportRE } from '../utils'\n\n/**\n * A flag for injected helpers. This flag will be set to `false` if the output\n * target is not native es - so that injected helper logic can be conditionally\n * dropped.\n */\nexport const isModernFlag = `__VITE_IS_MODERN__`\nexport const preloadMethod = `__vitePreload`\nexport const preloadMarker = `__VITE_PRELOAD__`\nexport const preloadBaseMarker = `__VITE_PRELOAD_BASE__`\n\nconst preloadHelperId = 'vite/preload-helper'\nconst preloadMarkerRE = new RegExp(`\"${preloadMarker}\"`, 'g')\n\n/**\n * Helper for preloading CSS and direct imports of async chunks in parallel to\n * the async chunk itself.\n */\n\nfunction detectScriptRel() {\n  // @ts-ignore\n  const relList = document.createElement('link').relList\n  // @ts-ignore\n  return relList && relList.supports && relList.supports('modulepreload')\n    ? 'modulepreload'\n    : 'preload'\n}\n\ndeclare const scriptRel: string\nfunction preload(baseModule: () => Promise<{}>, deps?: string[]) {\n  // @ts-ignore\n  if (!__VITE_IS_MODERN__ || !deps || deps.length === 0) {\n    return baseModule()\n  }\n\n  return Promise.all(\n    deps.map((dep) => {\n      // @ts-ignore\n      dep = `${base}${dep}`\n      // @ts-ignore\n      if (dep in seen) return\n      // @ts-ignore\n      seen[dep] = true\n      const isCss = dep.endsWith('.css')\n      const cssSelector = isCss ? '[rel=\"stylesheet\"]' : ''\n      // @ts-ignore check if the file is already preloaded by SSR markup\n      if (document.querySelector(`link[href=\"${dep}\"]${cssSelector}`)) {\n        return\n      }\n      // @ts-ignore\n      const link = document.createElement('link')\n      // @ts-ignore\n      link.rel = isCss ? 'stylesheet' : scriptRel\n      if (!isCss) {\n        link.as = 'script'\n        link.crossOrigin = ''\n      }\n      link.href = dep\n      // @ts-ignore\n      document.head.appendChild(link)\n      if (isCss) {\n        return new Promise((res, rej) => {\n          link.addEventListener('load', res)\n          link.addEventListener('error', rej)\n        })\n      }\n    })\n  ).then(() => baseModule())\n}\n\n/**\n * Build only. During serve this is performed as part of ./importAnalysis.\n */\nexport function buildImportAnalysisPlugin(config: ResolvedConfig): Plugin {\n  const ssr = !!config.build.ssr\n  const insertPreload = !(ssr || !!config.build.lib)\n\n  const scriptRel = config.build.polyfillModulePreload\n    ? `'modulepreload'`\n    : `(${detectScriptRel.toString()})()`\n  const preloadCode = `const scriptRel = ${scriptRel};const seen = {};const base = '${preloadBaseMarker}';export const ${preloadMethod} = ${preload.toString()}`\n\n  return {\n    name: 'vite:build-import-analysis',\n\n    resolveId(id) {\n      if (id === preloadHelperId) {\n        return id\n      }\n    },\n\n    load(id) {\n      if (id === preloadHelperId) {\n        return preloadCode.replace(preloadBaseMarker, config.base)\n      }\n    },\n\n    async transform(source, importer) {\n      if (\n        importer.includes('node_modules') &&\n        !source.includes('import.meta.glob')\n      ) {\n        return\n      }\n\n      await init\n\n      let imports: readonly ImportSpecifier[] = []\n      try {\n        imports = parseImports(source)[0]\n      } catch (e: any) {\n        this.error(e, e.idx)\n      }\n\n      if (!imports.length) {\n        return null\n      }\n\n      let s: MagicString | undefined\n      const str = () => s || (s = new MagicString(source))\n      let needPreloadHelper = false\n\n      for (let index = 0; index < imports.length; index++) {\n        const {\n          s: start,\n          e: end,\n          ss: expStart,\n          n: specifier,\n          d: dynamicIndex\n        } = imports[index]\n\n        // import.meta.glob\n        if (\n          source.slice(start, end) === 'import.meta' &&\n          source.slice(end, end + 5) === '.glob'\n        ) {\n          const { importsString, exp, endIndex, isEager } =\n            await transformImportGlob(\n              source,\n              start,\n              importer,\n              index,\n              config.root,\n              undefined,\n              insertPreload\n            )\n          str().prepend(importsString)\n          str().overwrite(expStart, endIndex, exp)\n          if (!isEager) {\n            needPreloadHelper = true\n          }\n          continue\n        }\n\n        if (dynamicIndex > -1 && insertPreload) {\n          needPreloadHelper = true\n          const dynamicEnd = source.indexOf(`)`, end) + 1\n          const original = source.slice(dynamicIndex, dynamicEnd)\n          const replacement = `${preloadMethod}(() => ${original},${isModernFlag}?\"${preloadMarker}\":void 0)`\n          str().overwrite(dynamicIndex, dynamicEnd, replacement)\n        }\n\n        // Differentiate CSS imports that use the default export from those that\n        // do not by injecting a ?used query - this allows us to avoid including\n        // the CSS string when unnecessary (esbuild has trouble tree-shaking\n        // them)\n        if (\n          specifier &&\n          isCSSRequest(specifier) &&\n          source.slice(expStart, start).includes('from') &&\n          // edge case for package names ending with .css (e.g normalize.css)\n          !(bareImportRE.test(specifier) && !specifier.includes('/'))\n        ) {\n          const url = specifier.replace(/\\?|$/, (m) => `?used${m ? '&' : ''}`)\n          str().overwrite(start, end, dynamicIndex > -1 ? `'${url}'` : url)\n        }\n      }\n\n      if (\n        needPreloadHelper &&\n        insertPreload &&\n        !source.includes(`const ${preloadMethod} =`)\n      ) {\n        str().prepend(`import { ${preloadMethod} } from \"${preloadHelperId}\";`)\n      }\n\n      if (s) {\n        return {\n          code: s.toString(),\n          map: config.build.sourcemap ? s.generateMap({ hires: true }) : null\n        }\n      }\n    },\n\n    renderChunk(code, _, { format }) {\n      // make sure we only perform the preload logic in modern builds.\n      if (code.indexOf(isModernFlag) > -1) {\n        const re = new RegExp(isModernFlag, 'g')\n        const isModern = String(format === 'es')\n        if (config.build.sourcemap) {\n          const s = new MagicString(code)\n          let match: RegExpExecArray | null\n          while ((match = re.exec(code))) {\n            s.overwrite(\n              match.index,\n              match.index + isModernFlag.length,\n              isModern\n            )\n          }\n          return {\n            code: s.toString(),\n            map: s.generateMap({ hires: true })\n          }\n        } else {\n          return code.replace(re, isModern)\n        }\n      }\n      return null\n    },\n\n    generateBundle({ format }, bundle) {\n      if (format !== 'es' || ssr) {\n        return\n      }\n\n      for (const file in bundle) {\n        const chunk = bundle[file]\n        // can't use chunk.dynamicImports.length here since some modules e.g.\n        // dynamic import to constant json may get inlined.\n        if (chunk.type === 'chunk' && chunk.code.indexOf(preloadMarker) > -1) {\n          const code = chunk.code\n          let imports: ImportSpecifier[]\n          try {\n            imports = parseImports(code)[0].filter((i) => i.d > -1)\n          } catch (e: any) {\n            this.error(e, e.idx)\n          }\n\n          if (imports.length) {\n            const s = new MagicString(code)\n            for (let index = 0; index < imports.length; index++) {\n              // To handle escape sequences in specifier strings, the .n field will be provided where possible.\n              const {\n                n: name,\n                s: start,\n                e: end,\n                d: dynamicIndex\n              } = imports[index]\n              // check the chunk being imported\n              let url = name\n              if (!url) {\n                const rawUrl = code.slice(start, end)\n                if (rawUrl[0] === `\"` && rawUrl[rawUrl.length - 1] === `\"`)\n                  url = rawUrl.slice(1, -1)\n              }\n              const deps: Set<string> = new Set()\n              let hasRemovedPureCssChunk = false\n\n              if (url) {\n                const ownerFilename = chunk.fileName\n                // literal import - trace direct imports and add to deps\n                const analyzed: Set<string> = new Set<string>()\n                const addDeps = (filename: string) => {\n                  if (filename === ownerFilename) return\n                  if (analyzed.has(filename)) return\n                  analyzed.add(filename)\n                  const chunk = bundle[filename] as OutputChunk | undefined\n                  if (chunk) {\n                    deps.add(chunk.fileName)\n                    const cssFiles = chunkToEmittedCssFileMap.get(chunk)\n                    if (cssFiles) {\n                      cssFiles.forEach((file) => {\n                        deps.add(file)\n                      })\n                    }\n                    chunk.imports.forEach(addDeps)\n                  } else {\n                    const removedPureCssFiles =\n                      removedPureCssFilesCache.get(config)!\n                    const chunk = removedPureCssFiles.get(filename)\n                    if (chunk) {\n                      const cssFiles = chunkToEmittedCssFileMap.get(chunk)\n                      if (cssFiles && cssFiles.size > 0) {\n                        cssFiles.forEach((file) => {\n                          deps.add(file)\n                        })\n                        hasRemovedPureCssChunk = true\n                      }\n\n                      s.overwrite(dynamicIndex, end + 1, 'Promise.resolve({})')\n                    }\n                  }\n                }\n                const normalizedFile = path.posix.join(\n                  path.posix.dirname(chunk.fileName),\n                  url\n                )\n                addDeps(normalizedFile)\n              }\n\n              let markPos = code.indexOf(preloadMarker, end)\n              // fix issue #3051\n              if (markPos === -1 && imports.length === 1) {\n                markPos = code.indexOf(preloadMarker)\n              }\n\n              if (markPos > 0) {\n                s.overwrite(\n                  markPos - 1,\n                  markPos + preloadMarker.length + 1,\n                  // the dep list includes the main chunk, so only need to\n                  // preload when there are actual other deps.\n                  deps.size > 1 ||\n                    // main chunk is removed\n                    (hasRemovedPureCssChunk && deps.size > 0)\n                    ? `[${[...deps].map((d) => JSON.stringify(d)).join(',')}]`\n                    : `[]`\n                )\n              }\n            }\n            chunk.code = s.toString()\n            // TODO source map\n          }\n\n          // there may still be markers due to inlined dynamic imports, remove\n          // all the markers regardless\n          chunk.code = chunk.code.replace(preloadMarkerRE, 'void 0')\n        }\n      }\n    }\n  }\n}\n","import path from 'path'\nimport { Plugin } from '../plugin'\nimport { ViteDevServer } from '../server'\nimport { OutputAsset, OutputBundle, OutputChunk } from 'rollup'\nimport {\n  cleanUrl,\n  generateCodeFrame,\n  isDataUrl,\n  isExternalUrl,\n  normalizePath,\n  processSrcSet,\n  slash\n} from '../utils'\nimport { ResolvedConfig } from '../config'\nimport MagicString from 'magic-string'\nimport {\n  checkPublicFile,\n  assetUrlRE,\n  urlToBuiltUrl,\n  getAssetFilename\n} from './asset'\nimport { isCSSRequest, chunkToEmittedCssFileMap } from './css'\nimport { modulePreloadPolyfillId } from './modulePreloadPolyfill'\nimport {\n  AttributeNode,\n  NodeTransform,\n  NodeTypes,\n  ElementNode\n} from '@vue/compiler-dom'\n\nconst htmlProxyRE = /\\?html-proxy&index=(\\d+)\\.js$/\nexport const isHTMLProxy = (id: string): boolean => htmlProxyRE.test(id)\n\n// HTML Proxy Caches are stored by config -> filePath -> index\nexport const htmlProxyMap = new WeakMap<\n  ResolvedConfig,\n  Map<string, Array<string>>\n>()\n\nexport function htmlInlineScriptProxyPlugin(config: ResolvedConfig): Plugin {\n  return {\n    name: 'vite:html-inline-script-proxy',\n\n    resolveId(id) {\n      if (htmlProxyRE.test(id)) {\n        return id\n      }\n    },\n\n    buildStart() {\n      htmlProxyMap.set(config, new Map())\n    },\n\n    load(id) {\n      const proxyMatch = id.match(htmlProxyRE)\n      if (proxyMatch) {\n        const index = Number(proxyMatch[1])\n        const file = cleanUrl(id)\n        const url = file.replace(normalizePath(config.root), '')\n        const result = htmlProxyMap.get(config)!.get(url)![index]\n        if (result) {\n          return result\n        } else {\n          throw new Error(`No matching HTML proxy module found from ${id}`)\n        }\n      }\n    }\n  }\n}\n\n/** Add script to cache */\nexport function addToHTMLProxyCache(\n  config: ResolvedConfig,\n  filePath: string,\n  index: number,\n  code: string\n): void {\n  if (!htmlProxyMap.get(config)) {\n    htmlProxyMap.set(config, new Map())\n  }\n  if (!htmlProxyMap.get(config)!.get(filePath)) {\n    htmlProxyMap.get(config)!.set(filePath, [])\n  }\n  htmlProxyMap.get(config)!.get(filePath)![index] = code\n}\n\n// this extends the config in @vue/compiler-sfc with <link href>\nexport const assetAttrsConfig: Record<string, string[]> = {\n  link: ['href'],\n  video: ['src', 'poster'],\n  source: ['src', 'srcset'],\n  img: ['src', 'srcset'],\n  image: ['xlink:href', 'href'],\n  use: ['xlink:href', 'href']\n}\n\nexport const isAsyncScriptMap = new WeakMap<\n  ResolvedConfig,\n  Map<string, boolean>\n>()\n\nexport async function traverseHtml(\n  html: string,\n  filePath: string,\n  visitor: NodeTransform\n): Promise<void> {\n  // lazy load compiler\n  const { parse, transform } = await import('@vue/compiler-dom')\n  // @vue/compiler-core doesn't like lowercase doctypes\n  html = html.replace(/<!doctype\\s/i, '<!DOCTYPE ')\n  try {\n    const ast = parse(html, { comments: true })\n    transform(ast, {\n      nodeTransforms: [visitor]\n    })\n  } catch (e) {\n    const parseError = {\n      loc: filePath,\n      frame: '',\n      ...formatParseError(e, filePath, html)\n    }\n    throw new Error(\n      `Unable to parse ${JSON.stringify(parseError.loc)}\\n${parseError.frame}`\n    )\n  }\n}\n\nexport function getScriptInfo(node: ElementNode): {\n  src: AttributeNode | undefined\n  isModule: boolean\n  isAsync: boolean\n} {\n  let src: AttributeNode | undefined\n  let isModule = false\n  let isAsync = false\n  for (let i = 0; i < node.props.length; i++) {\n    const p = node.props[i]\n    if (p.type === NodeTypes.ATTRIBUTE) {\n      if (p.name === 'src') {\n        src = p\n      } else if (p.name === 'type' && p.value && p.value.content === 'module') {\n        isModule = true\n      } else if (p.name === 'async') {\n        isAsync = true\n      }\n    }\n  }\n  return { src, isModule, isAsync }\n}\n\nfunction formatParseError(e: any, id: string, html: string): Error {\n  // normalize the error to rollup format\n  if (e.loc) {\n    e.frame = generateCodeFrame(html, e.loc.start.offset)\n    e.loc = {\n      file: id,\n      line: e.loc.start.line,\n      column: e.loc.start.column\n    }\n  }\n  return e\n}\n\n/**\n * Compiles index.html into an entry js module\n */\nexport function buildHtmlPlugin(config: ResolvedConfig): Plugin {\n  const [preHooks, postHooks] = resolveHtmlTransforms(config.plugins)\n  const processedHtml = new Map<string, string>()\n  const isExcludedUrl = (url: string) =>\n    url.startsWith('#') ||\n    isExternalUrl(url) ||\n    isDataUrl(url) ||\n    checkPublicFile(url, config)\n\n  return {\n    name: 'vite:build-html',\n\n    buildStart() {\n      isAsyncScriptMap.set(config, new Map())\n    },\n\n    async transform(html, id) {\n      if (id.endsWith('.html')) {\n        const publicPath = `/${slash(path.relative(config.root, id))}`\n        // pre-transform\n        html = await applyHtmlTransforms(html, preHooks, {\n          path: publicPath,\n          filename: id\n        })\n\n        let js = ''\n        const s = new MagicString(html)\n        const assetUrls: AttributeNode[] = []\n        let inlineModuleIndex = -1\n\n        let everyScriptIsAsync = true\n        let someScriptsAreAsync = false\n        let someScriptsAreDefer = false\n\n        await traverseHtml(html, id, (node) => {\n          if (node.type !== NodeTypes.ELEMENT) {\n            return\n          }\n\n          let shouldRemove = false\n\n          // script tags\n          if (node.tag === 'script') {\n            const { src, isModule, isAsync } = getScriptInfo(node)\n\n            const url = src && src.value && src.value.content\n            const isPublicFile = !!(url && checkPublicFile(url, config))\n            if (isPublicFile) {\n              // referencing public dir url, prefix with base\n              s.overwrite(\n                src!.value!.loc.start.offset,\n                src!.value!.loc.end.offset,\n                `\"${config.base + url.slice(1)}\"`\n              )\n            }\n\n            if (isModule) {\n              inlineModuleIndex++\n              if (url && !isExcludedUrl(url)) {\n                // <script type=\"module\" src=\"...\"/>\n                // add it as an import\n                js += `\\nimport ${JSON.stringify(url)}`\n                shouldRemove = true\n              } else if (node.children.length) {\n                const contents = node.children\n                  .map((child: any) => child.content || '')\n                  .join('')\n                // <script type=\"module\">...</script>\n                const filePath = id.replace(normalizePath(config.root), '')\n                addToHTMLProxyCache(\n                  config,\n                  filePath,\n                  inlineModuleIndex,\n                  contents\n                )\n                js += `\\nimport \"${id}?html-proxy&index=${inlineModuleIndex}.js\"`\n                shouldRemove = true\n              }\n\n              everyScriptIsAsync &&= isAsync\n              someScriptsAreAsync ||= isAsync\n              someScriptsAreDefer ||= !isAsync\n            } else if (url && !isPublicFile) {\n              config.logger.warn(\n                `<script src=\"${url}\"> in \"${publicPath}\" can't be bundled without type=\"module\" attribute`\n              )\n            }\n          }\n\n          // For asset references in index.html, also generate an import\n          // statement for each - this will be handled by the asset plugin\n          const assetAttrs = assetAttrsConfig[node.tag]\n          if (assetAttrs) {\n            for (const p of node.props) {\n              if (\n                p.type === NodeTypes.ATTRIBUTE &&\n                p.value &&\n                assetAttrs.includes(p.name)\n              ) {\n                const url = p.value.content\n                if (!isExcludedUrl(url)) {\n                  if (node.tag === 'link' && isCSSRequest(url)) {\n                    // CSS references, convert to import\n                    js += `\\nimport ${JSON.stringify(url)}`\n                    shouldRemove = true\n                  } else {\n                    assetUrls.push(p)\n                  }\n                } else if (checkPublicFile(url, config)) {\n                  s.overwrite(\n                    p.value.loc.start.offset,\n                    p.value.loc.end.offset,\n                    `\"${config.base + url.slice(1)}\"`\n                  )\n                }\n              }\n            }\n          }\n\n          if (shouldRemove) {\n            // remove the script tag from the html. we are going to inject new\n            // ones in the end.\n            s.remove(node.loc.start.offset, node.loc.end.offset)\n          }\n        })\n\n        isAsyncScriptMap.get(config)!.set(id, everyScriptIsAsync)\n\n        if (someScriptsAreAsync && someScriptsAreDefer) {\n          config.logger.warn(\n            `\\nMixed async and defer script modules in ${id}, output script will fallback to defer. Every script, including inline ones, need to be marked as async for your output script to be async.`\n          )\n        }\n\n        // for each encountered asset url, rewrite original html so that it\n        // references the post-build location.\n        for (const attr of assetUrls) {\n          const value = attr.value!\n          try {\n            const url =\n              attr.name === 'srcset'\n                ? await processSrcSet(value.content, ({ url }) =>\n                    urlToBuiltUrl(url, id, config, this)\n                  )\n                : await urlToBuiltUrl(value.content, id, config, this)\n\n            s.overwrite(\n              value.loc.start.offset,\n              value.loc.end.offset,\n              `\"${url}\"`\n            )\n          } catch (e) {\n            // #1885 preload may be pointing to urls that do not exist\n            // locally on disk\n            if (e.code !== 'ENOENT') {\n              throw e\n            }\n          }\n        }\n\n        processedHtml.set(id, s.toString())\n\n        // inject module preload polyfill only when configured and needed\n        if (\n          config.build.polyfillModulePreload &&\n          (someScriptsAreAsync || someScriptsAreDefer)\n        ) {\n          js = `import \"${modulePreloadPolyfillId}\";\\n${js}`\n        }\n\n        return js\n      }\n    },\n\n    async generateBundle(options, bundle) {\n      const analyzedChunk: Map<OutputChunk, number> = new Map()\n      const getImportedChunks = (\n        chunk: OutputChunk,\n        seen: Set<string> = new Set()\n      ): OutputChunk[] => {\n        const chunks: OutputChunk[] = []\n        chunk.imports.forEach((file) => {\n          const importee = bundle[file]\n          if (importee?.type === 'chunk' && !seen.has(file)) {\n            seen.add(file)\n\n            // post-order traversal\n            chunks.push(...getImportedChunks(importee, seen))\n            chunks.push(importee)\n          }\n        })\n        return chunks\n      }\n\n      const toScriptTag = (\n        chunk: OutputChunk,\n        isAsync: boolean\n      ): HtmlTagDescriptor => ({\n        tag: 'script',\n        attrs: {\n          ...(isAsync ? { async: true } : {}),\n          type: 'module',\n          crossorigin: true,\n          src: toPublicPath(chunk.fileName, config)\n        }\n      })\n\n      const toPreloadTag = (chunk: OutputChunk): HtmlTagDescriptor => ({\n        tag: 'link',\n        attrs: {\n          rel: 'modulepreload',\n          href: toPublicPath(chunk.fileName, config)\n        }\n      })\n\n      const getCssTagsForChunk = (\n        chunk: OutputChunk,\n        seen: Set<string> = new Set()\n      ): HtmlTagDescriptor[] => {\n        const tags: HtmlTagDescriptor[] = []\n        if (!analyzedChunk.has(chunk)) {\n          analyzedChunk.set(chunk, 1)\n          chunk.imports.forEach((file) => {\n            const importee = bundle[file]\n            if (importee?.type === 'chunk') {\n              tags.push(...getCssTagsForChunk(importee, seen))\n            }\n          })\n        }\n\n        const cssFiles = chunkToEmittedCssFileMap.get(chunk)\n        if (cssFiles) {\n          cssFiles.forEach((file) => {\n            if (!seen.has(file)) {\n              seen.add(file)\n              tags.push({\n                tag: 'link',\n                attrs: {\n                  rel: 'stylesheet',\n                  href: toPublicPath(file, config)\n                }\n              })\n            }\n          })\n        }\n        return tags\n      }\n\n      for (const [id, html] of processedHtml) {\n        const isAsync = isAsyncScriptMap.get(config)!.get(id)!\n\n        // resolve asset url references\n        let result = html.replace(assetUrlRE, (_, fileHash, postfix = '') => {\n          return config.base + getAssetFilename(fileHash, config) + postfix\n        })\n\n        // find corresponding entry chunk\n        const chunk = Object.values(bundle).find(\n          (chunk) =>\n            chunk.type === 'chunk' &&\n            chunk.isEntry &&\n            chunk.facadeModuleId === id\n        ) as OutputChunk | undefined\n\n        let canInlineEntry = false\n\n        // inject chunk asset links\n        if (chunk) {\n          // an entry chunk can be inlined if\n          //  - it's an ES module (e.g. not generated by the legacy plugin)\n          //  - it contains no meaningful code other than import statements\n          if (options.format === 'es' && isEntirelyImport(chunk.code)) {\n            canInlineEntry = true\n          }\n\n          // when not inlined, inject <script> for entry and modulepreload its dependencies\n          // when inlined, discard entry chunk and inject <script> for everything in post-order\n          const imports = getImportedChunks(chunk)\n          const assetTags = canInlineEntry\n            ? imports.map((chunk) => toScriptTag(chunk, isAsync))\n            : [toScriptTag(chunk, isAsync), ...imports.map(toPreloadTag)]\n\n          assetTags.push(...getCssTagsForChunk(chunk))\n\n          result = injectToHead(result, assetTags)\n        }\n\n        // inject css link when cssCodeSplit is false\n        if (!config.build.cssCodeSplit) {\n          const cssChunk = Object.values(bundle).find(\n            (chunk) => chunk.type === 'asset' && chunk.name === 'style.css'\n          ) as OutputAsset | undefined\n          if (cssChunk) {\n            result = injectToHead(result, [\n              {\n                tag: 'link',\n                attrs: {\n                  rel: 'stylesheet',\n                  href: toPublicPath(cssChunk.fileName, config)\n                }\n              }\n            ])\n          }\n        }\n\n        const shortEmitName = path.posix.relative(config.root, id)\n        result = await applyHtmlTransforms(result, postHooks, {\n          path: '/' + shortEmitName,\n          filename: id,\n          bundle,\n          chunk\n        })\n\n        if (chunk && canInlineEntry) {\n          // all imports from entry have been inlined to html, prevent rollup from outputting it\n          delete bundle[chunk.fileName]\n        }\n\n        this.emitFile({\n          type: 'asset',\n          fileName: shortEmitName,\n          source: result\n        })\n      }\n    }\n  }\n}\n\nexport interface HtmlTagDescriptor {\n  tag: string\n  attrs?: Record<string, string | boolean | undefined>\n  children?: string | HtmlTagDescriptor[]\n  /**\n   * default: 'head-prepend'\n   */\n  injectTo?: 'head' | 'body' | 'head-prepend' | 'body-prepend'\n}\n\nexport type IndexHtmlTransformResult =\n  | string\n  | HtmlTagDescriptor[]\n  | {\n      html: string\n      tags: HtmlTagDescriptor[]\n    }\n\nexport interface IndexHtmlTransformContext {\n  /**\n   * public path when served\n   */\n  path: string\n  /**\n   * filename on disk\n   */\n  filename: string\n  server?: ViteDevServer\n  bundle?: OutputBundle\n  chunk?: OutputChunk\n  originalUrl?: string\n}\n\nexport type IndexHtmlTransformHook = (\n  html: string,\n  ctx: IndexHtmlTransformContext\n) => IndexHtmlTransformResult | void | Promise<IndexHtmlTransformResult | void>\n\nexport type IndexHtmlTransform =\n  | IndexHtmlTransformHook\n  | {\n      enforce?: 'pre' | 'post'\n      transform: IndexHtmlTransformHook\n    }\n\nexport function resolveHtmlTransforms(\n  plugins: readonly Plugin[]\n): [IndexHtmlTransformHook[], IndexHtmlTransformHook[]] {\n  const preHooks: IndexHtmlTransformHook[] = []\n  const postHooks: IndexHtmlTransformHook[] = []\n\n  for (const plugin of plugins) {\n    const hook = plugin.transformIndexHtml\n    if (hook) {\n      if (typeof hook === 'function') {\n        postHooks.push(hook)\n      } else if (hook.enforce === 'pre') {\n        preHooks.push(hook.transform)\n      } else {\n        postHooks.push(hook.transform)\n      }\n    }\n  }\n\n  return [preHooks, postHooks]\n}\n\nexport async function applyHtmlTransforms(\n  html: string,\n  hooks: IndexHtmlTransformHook[],\n  ctx: IndexHtmlTransformContext\n): Promise<string> {\n  const headTags: HtmlTagDescriptor[] = []\n  const headPrependTags: HtmlTagDescriptor[] = []\n  const bodyTags: HtmlTagDescriptor[] = []\n  const bodyPrependTags: HtmlTagDescriptor[] = []\n\n  for (const hook of hooks) {\n    const res = await hook(html, ctx)\n    if (!res) {\n      continue\n    }\n    if (typeof res === 'string') {\n      html = res\n    } else {\n      let tags: HtmlTagDescriptor[]\n      if (Array.isArray(res)) {\n        tags = res\n      } else {\n        html = res.html || html\n        tags = res.tags\n      }\n      for (const tag of tags) {\n        if (tag.injectTo === 'body') {\n          bodyTags.push(tag)\n        } else if (tag.injectTo === 'body-prepend') {\n          bodyPrependTags.push(tag)\n        } else if (tag.injectTo === 'head') {\n          headTags.push(tag)\n        } else {\n          headPrependTags.push(tag)\n        }\n      }\n    }\n  }\n\n  // inject tags\n  if (headPrependTags.length) {\n    html = injectToHead(html, headPrependTags, true)\n  }\n  if (headTags.length) {\n    html = injectToHead(html, headTags)\n  }\n  if (bodyPrependTags.length) {\n    html = injectToBody(html, bodyPrependTags, true)\n  }\n  if (bodyTags.length) {\n    html = injectToBody(html, bodyTags)\n  }\n\n  return html\n}\n\nconst importRE = /\\bimport\\s*(\"[^\"]*[^\\\\]\"|'[^']*[^\\\\]');*/g\nconst commentRE = /\\/\\*[\\s\\S]*?\\*\\/|\\/\\/.*$/gm\nfunction isEntirelyImport(code: string) {\n  // only consider \"side-effect\" imports, which match <script type=module> semantics exactly\n  // the regexes will remove too little in some exotic cases, but false-negatives are alright\n  return !code.replace(importRE, '').replace(commentRE, '').trim().length\n}\n\nfunction toPublicPath(filename: string, config: ResolvedConfig) {\n  return isExternalUrl(filename) ? filename : config.base + filename\n}\n\nconst headInjectRE = /([ \\t]*)<\\/head>/i\nconst headPrependInjectRE = /([ \\t]*)<head[^>]*>/i\n\nconst htmlInjectRE = /<\\/html>/i\nconst htmlPrependInjectRE = /([ \\t]*)<html[^>]*>/i\n\nconst bodyInjectRE = /([ \\t]*)<\\/body>/i\nconst bodyPrependInjectRE = /([ \\t]*)<body[^>]*>/i\n\nconst doctypePrependInjectRE = /<!doctype html>/i\n\nfunction injectToHead(\n  html: string,\n  tags: HtmlTagDescriptor[],\n  prepend = false\n) {\n  if (prepend) {\n    // inject as the first element of head\n    if (headPrependInjectRE.test(html)) {\n      return html.replace(\n        headPrependInjectRE,\n        (match, p1) => `${match}\\n${serializeTags(tags, incrementIndent(p1))}`\n      )\n    }\n  } else {\n    // inject before head close\n    if (headInjectRE.test(html)) {\n      // respect indentation of head tag\n      return html.replace(\n        headInjectRE,\n        (match, p1) => `${serializeTags(tags, incrementIndent(p1))}${match}`\n      )\n    }\n    // try to inject before the body tag\n    if (bodyPrependInjectRE.test(html)) {\n      return html.replace(\n        bodyPrependInjectRE,\n        (match, p1) => `${serializeTags(tags, p1)}\\n${match}`\n      )\n    }\n  }\n  // if no head tag is present, we prepend the tag for both prepend and append\n  return prependInjectFallback(html, tags)\n}\n\nfunction injectToBody(\n  html: string,\n  tags: HtmlTagDescriptor[],\n  prepend = false\n) {\n  if (prepend) {\n    // inject after body open\n    if (bodyPrependInjectRE.test(html)) {\n      return html.replace(\n        bodyPrependInjectRE,\n        (match, p1) => `${match}\\n${serializeTags(tags, incrementIndent(p1))}`\n      )\n    }\n    // if no there is no body tag, inject after head or fallback to prepend in html\n    if (headInjectRE.test(html)) {\n      return html.replace(\n        headInjectRE,\n        (match, p1) => `${match}\\n${serializeTags(tags, p1)}`\n      )\n    }\n    return prependInjectFallback(html, tags)\n  } else {\n    // inject before body close\n    if (bodyInjectRE.test(html)) {\n      return html.replace(\n        bodyInjectRE,\n        (match, p1) => `${serializeTags(tags, incrementIndent(p1))}${match}`\n      )\n    }\n    // if no body tag is present, append to the html tag, or at the end of the file\n    if (htmlInjectRE.test(html)) {\n      return html.replace(htmlInjectRE, `${serializeTags(tags)}\\n$&`)\n    }\n    return html + `\\n` + serializeTags(tags)\n  }\n}\n\nfunction prependInjectFallback(html: string, tags: HtmlTagDescriptor[]) {\n  // prepend to the html tag, append after doctype, or the document start\n  if (htmlPrependInjectRE.test(html)) {\n    return html.replace(htmlPrependInjectRE, `$&\\n${serializeTags(tags)}`)\n  }\n  if (doctypePrependInjectRE.test(html)) {\n    return html.replace(doctypePrependInjectRE, `$&\\n${serializeTags(tags)}`)\n  }\n  return serializeTags(tags) + html\n}\n\nconst unaryTags = new Set(['link', 'meta', 'base'])\n\nfunction serializeTag(\n  { tag, attrs, children }: HtmlTagDescriptor,\n  indent: string = ''\n): string {\n  if (unaryTags.has(tag)) {\n    return `<${tag}${serializeAttrs(attrs)}>`\n  } else {\n    return `<${tag}${serializeAttrs(attrs)}>${serializeTags(\n      children,\n      incrementIndent(indent)\n    )}</${tag}>`\n  }\n}\n\nfunction serializeTags(\n  tags: HtmlTagDescriptor['children'],\n  indent: string = ''\n): string {\n  if (typeof tags === 'string') {\n    return tags\n  } else if (tags && tags.length) {\n    return tags.map((tag) => `${indent}${serializeTag(tag, indent)}\\n`).join('')\n  }\n  return ''\n}\n\nfunction serializeAttrs(attrs: HtmlTagDescriptor['attrs']): string {\n  let res = ''\n  for (const key in attrs) {\n    if (typeof attrs[key] === 'boolean') {\n      res += attrs[key] ? ` ${key}` : ``\n    } else {\n      res += ` ${key}=${JSON.stringify(attrs[key])}`\n    }\n  }\n  return res\n}\n\nfunction incrementIndent(indent: string = '') {\n  return `${indent}${indent[0] === '\\t' ? '\\t' : '  '}`\n}\n","import path from 'path'\nimport chalk from 'chalk'\nimport { Plugin } from '../plugin'\nimport {\n  transform,\n  Message,\n  Loader,\n  TransformOptions,\n  TransformResult\n} from 'esbuild'\nimport {\n  cleanUrl,\n  createDebugger,\n  ensureWatchedFile,\n  generateCodeFrame,\n  toUpperCaseDriveLetter\n} from '../utils'\nimport { RawSourceMap } from '@ampproject/remapping/dist/types/types'\nimport { SourceMap } from 'rollup'\nimport { ResolvedConfig, ViteDevServer } from '..'\nimport { createFilter } from '@rollup/pluginutils'\nimport { combineSourcemaps } from '../utils'\nimport { parse, TSConfckParseError, TSConfckParseResult } from 'tsconfck'\n\nconst debug = createDebugger('vite:esbuild')\n\nlet server: ViteDevServer\n\nexport interface ESBuildOptions extends TransformOptions {\n  include?: string | RegExp | string[] | RegExp[]\n  exclude?: string | RegExp | string[] | RegExp[]\n  jsxInject?: string\n}\n\nexport type ESBuildTransformResult = Omit<TransformResult, 'map'> & {\n  map: SourceMap\n}\n\ntype TSConfigJSON = {\n  extends?: string\n  compilerOptions?: {\n    target?: string\n    jsxFactory?: string\n    jsxFragmentFactory?: string\n    useDefineForClassFields?: boolean\n    importsNotUsedAsValues?: 'remove' | 'preserve' | 'error'\n  }\n  [key: string]: any\n}\ntype TSCompilerOptions = NonNullable<TSConfigJSON['compilerOptions']>\n\nexport async function transformWithEsbuild(\n  code: string,\n  filename: string,\n  options?: TransformOptions,\n  inMap?: object\n): Promise<ESBuildTransformResult> {\n  let loader = options?.loader\n\n  if (!loader) {\n    // if the id ends with a valid ext, use it (e.g. vue blocks)\n    // otherwise, cleanup the query before checking the ext\n    const ext = path\n      .extname(/\\.\\w+$/.test(filename) ? filename : cleanUrl(filename))\n      .slice(1)\n\n    if (ext === 'cjs' || ext === 'mjs') {\n      loader = 'js'\n    } else {\n      loader = ext as Loader\n    }\n  }\n\n  let tsconfigRaw = options?.tsconfigRaw\n\n  // if options provide tsconfigraw in string, it takes highest precedence\n  if (typeof tsconfigRaw !== 'string') {\n    // these fields would affect the compilation result\n    // https://esbuild.github.io/content-types/#tsconfig-json\n    const meaningfulFields: Array<keyof TSCompilerOptions> = [\n      'jsxFactory',\n      'jsxFragmentFactory',\n      'useDefineForClassFields',\n      'importsNotUsedAsValues'\n    ]\n    const compilerOptionsForFile: TSCompilerOptions = {}\n    if (loader === 'ts' || loader === 'tsx') {\n      const loadedTsconfig = await loadTsconfigJsonForFile(filename)\n      const loadedCompilerOptions = loadedTsconfig.compilerOptions ?? {}\n\n      for (const field of meaningfulFields) {\n        if (field in loadedCompilerOptions) {\n          // @ts-ignore TypeScript can't tell they are of the same type\n          compilerOptionsForFile[field] = loadedCompilerOptions[field]\n        }\n      }\n\n      // align with TypeScript 4.3\n      // https://github.com/microsoft/TypeScript/pull/42663\n      if (loadedCompilerOptions.target?.toLowerCase() === 'esnext') {\n        compilerOptionsForFile.useDefineForClassFields =\n          loadedCompilerOptions.useDefineForClassFields ?? true\n      }\n    }\n\n    tsconfigRaw = {\n      ...tsconfigRaw,\n      compilerOptions: {\n        ...compilerOptionsForFile,\n        ...tsconfigRaw?.compilerOptions\n      }\n    }\n  }\n\n  const resolvedOptions = {\n    sourcemap: true,\n    // ensure source file name contains full query\n    sourcefile: filename,\n    ...options,\n    loader,\n    tsconfigRaw\n  } as ESBuildOptions\n\n  delete resolvedOptions.include\n  delete resolvedOptions.exclude\n  delete resolvedOptions.jsxInject\n\n  try {\n    const result = await transform(code, resolvedOptions)\n    let map: SourceMap\n    if (inMap && resolvedOptions.sourcemap) {\n      const nextMap = JSON.parse(result.map)\n      nextMap.sourcesContent = []\n      map = combineSourcemaps(filename, [\n        nextMap as RawSourceMap,\n        inMap as RawSourceMap\n      ]) as SourceMap\n    } else {\n      map = resolvedOptions.sourcemap\n        ? JSON.parse(result.map)\n        : { mappings: '' }\n    }\n    if (Array.isArray(map.sources)) {\n      map.sources = map.sources.map((it) => toUpperCaseDriveLetter(it))\n    }\n    return {\n      ...result,\n      map\n    }\n  } catch (e: any) {\n    debug(`esbuild error with options used: `, resolvedOptions)\n    // patch error information\n    if (e.errors) {\n      e.frame = ''\n      e.errors.forEach((m: Message) => {\n        e.frame += `\\n` + prettifyMessage(m, code)\n      })\n      e.loc = e.errors[0].location\n    }\n    throw e\n  }\n}\n\nexport function esbuildPlugin(options: ESBuildOptions = {}): Plugin {\n  const filter = createFilter(\n    options.include || /\\.(tsx?|jsx)$/,\n    options.exclude || /\\.js$/\n  )\n\n  return {\n    name: 'vite:esbuild',\n    configureServer(_server) {\n      server = _server\n      server.watcher\n        .on('add', reloadOnTsconfigChange)\n        .on('change', reloadOnTsconfigChange)\n        .on('unlink', reloadOnTsconfigChange)\n    },\n    async transform(code, id) {\n      if (filter(id) || filter(cleanUrl(id))) {\n        const result = await transformWithEsbuild(code, id, options)\n        if (result.warnings.length) {\n          result.warnings.forEach((m) => {\n            this.warn(prettifyMessage(m, code))\n          })\n        }\n        if (options.jsxInject && /\\.(?:j|t)sx\\b/.test(id)) {\n          result.code = options.jsxInject + ';' + result.code\n        }\n        return {\n          code: result.code,\n          map: result.map\n        }\n      }\n    }\n  }\n}\n\nconst rollupToEsbuildFormatMap: Record<\n  string,\n  TransformOptions['format'] | undefined\n> = {\n  es: 'esm',\n  cjs: 'cjs',\n\n  // passing `var Lib = (() => {})()` to esbuild with format = \"iife\"\n  // will turn it to `(() => { var Lib = (() => {})() })()`,\n  // so we remove the format config to tell esbuild not doing this\n  //\n  // although esbuild doesn't change format, there is still possibility\n  // that `{ treeShaking: true }` removes a top-level no-side-effect variable\n  // like: `var Lib = 1`, which becomes `` after esbuild transforming,\n  // but thankfully rollup does not do this optimization now\n  iife: undefined\n}\n\nexport const buildEsbuildPlugin = (config: ResolvedConfig): Plugin => {\n  return {\n    name: 'vite:esbuild-transpile',\n    async renderChunk(code, chunk, opts) {\n      // @ts-ignore injected by @vitejs/plugin-legacy\n      if (opts.__vite_skip_esbuild__) {\n        return null\n      }\n\n      const target = config.build.target\n      const minify =\n        config.build.minify === 'esbuild' &&\n        // Do not minify ES lib output since that would remove pure annotations\n        // and break tree-shaking\n        // https://github.com/vuejs/vue-next/issues/2860#issuecomment-926882793\n        !(config.build.lib && opts.format === 'es')\n\n      if ((!target || target === 'esnext') && !minify) {\n        return null\n      }\n\n      const res = await transformWithEsbuild(code, chunk.fileName, {\n        ...config.esbuild,\n        target: target || undefined,\n        ...(minify\n          ? {\n              minify,\n              treeShaking: true,\n              format: rollupToEsbuildFormatMap[opts.format]\n            }\n          : undefined)\n      })\n      return res\n    }\n  }\n}\n\nfunction prettifyMessage(m: Message, code: string): string {\n  let res = chalk.yellow(m.text)\n  if (m.location) {\n    const lines = code.split(/\\r?\\n/g)\n    const line = Number(m.location.line)\n    const column = Number(m.location.column)\n    const offset =\n      lines\n        .slice(0, line - 1)\n        .map((l) => l.length)\n        .reduce((total, l) => total + l + 1, 0) + column\n    res += `\\n` + generateCodeFrame(code, offset, offset + 1)\n  }\n  return res + `\\n`\n}\n\nconst tsconfigCache = new Map<string, TSConfckParseResult>()\nasync function loadTsconfigJsonForFile(\n  filename: string\n): Promise<TSConfigJSON> {\n  try {\n    const result = await parse(filename, {\n      cache: tsconfigCache,\n      resolveWithEmptyIfConfigNotFound: true\n    })\n    // tsconfig could be out of root, make sure it is watched on dev\n    if (server && result.tsconfigFile !== 'no_tsconfig_file_found') {\n      ensureWatchedFile(server.watcher, result.tsconfigFile, server.config.root)\n    }\n    return result.tsconfig\n  } catch (e) {\n    if (e instanceof TSConfckParseError) {\n      // tsconfig could be out of root, make sure it is watched on dev\n      if (server && e.tsconfigFile) {\n        ensureWatchedFile(server.watcher, e.tsconfigFile, server.config.root)\n      }\n    }\n    throw e\n  }\n}\n\nfunction reloadOnTsconfigChange(changedFile: string) {\n  // any tsconfig.json that's added in the workspace could be closer to a code file than a previously cached one\n  // any json file in the tsconfig cache could have been used to compile ts\n  if (\n    path.basename(changedFile) === 'tsconfig.json' ||\n    (changedFile.endsWith('.json') && tsconfigCache.has(changedFile))\n  ) {\n    server.config.logger.info(\n      `changed tsconfig file detected: ${changedFile} - Clearing cache and forcing full-reload to ensure typescript is compiled with updated config values.`,\n      { clear: server.config.clearScreen, timestamp: true }\n    )\n    // clear tsconfig cache so that recompile works with up2date configs\n    tsconfigCache.clear()\n    // clear module graph to remove code compiled with outdated config\n    server.moduleGraph.invalidateAll()\n    // force full reload\n    server.ws.send({\n      type: 'full-reload',\n      path: '*'\n    })\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport { createFilter } from '@rollup/pluginutils'\nimport { createDebugger, resolveFrom } from './utils'\nimport { ResolvedConfig } from './config'\nimport { Plugin } from './plugin'\n\nconst isDebug = process.env.DEBUG\nconst debug = createDebugger('vite:resolve-details', {\n  onlyWhenFocused: true\n})\n\n/** Cache for package.json resolution and package.json contents */\nexport type PackageCache = Map<string, PackageData>\n\nexport interface PackageData {\n  dir: string\n  hasSideEffects: (id: string) => boolean | 'no-treeshake'\n  webResolvedImports: Record<string, string | undefined>\n  nodeResolvedImports: Record<string, string | undefined>\n  setResolvedCache: (key: string, entry: string, targetWeb: boolean) => void\n  getResolvedCache: (key: string, targetWeb: boolean) => string | undefined\n  data: {\n    [field: string]: any\n    version: string\n    main: string\n    module: string\n    browser: string | Record<string, string | false>\n    exports: string | Record<string, any> | string[]\n    dependencies: Record<string, string>\n  }\n}\n\nexport function invalidatePackageData(\n  packageCache: PackageCache,\n  pkgPath: string\n): void {\n  packageCache.delete(pkgPath)\n  const pkgDir = path.dirname(pkgPath)\n  packageCache.forEach((pkg, cacheKey) => {\n    if (pkg.dir === pkgDir) {\n      packageCache.delete(cacheKey)\n    }\n  })\n}\n\nexport function resolvePackageData(\n  id: string,\n  basedir: string,\n  preserveSymlinks = false,\n  packageCache?: PackageCache\n): PackageData | null {\n  let pkg: PackageData | undefined\n  let cacheKey: string | undefined\n  if (packageCache) {\n    cacheKey = `${id}&${basedir}&${preserveSymlinks}`\n    if ((pkg = packageCache.get(cacheKey))) {\n      return pkg\n    }\n  }\n  let pkgPath: string | undefined\n  try {\n    pkgPath = resolveFrom(`${id}/package.json`, basedir, preserveSymlinks)\n    pkg = loadPackageData(pkgPath, true, packageCache)\n    if (packageCache) {\n      packageCache.set(cacheKey!, pkg)\n    }\n    return pkg\n  } catch (e) {\n    if (e instanceof SyntaxError) {\n      isDebug && debug(`Parsing failed: ${pkgPath}`)\n    }\n    // Ignore error for missing package.json\n    else if (e.code !== 'MODULE_NOT_FOUND') {\n      throw e\n    }\n  }\n  return null\n}\n\nexport function loadPackageData(\n  pkgPath: string,\n  preserveSymlinks?: boolean,\n  packageCache?: PackageCache\n): PackageData {\n  if (!preserveSymlinks) {\n    pkgPath = fs.realpathSync.native(pkgPath)\n  }\n\n  let cached: PackageData | undefined\n  if ((cached = packageCache?.get(pkgPath))) {\n    return cached\n  }\n\n  const data = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'))\n  const pkgDir = path.dirname(pkgPath)\n  const { sideEffects } = data\n  let hasSideEffects: (id: string) => boolean\n  if (typeof sideEffects === 'boolean') {\n    hasSideEffects = () => sideEffects\n  } else if (Array.isArray(sideEffects)) {\n    hasSideEffects = createFilter(sideEffects, null, { resolve: pkgDir })\n  } else {\n    hasSideEffects = () => true\n  }\n\n  const pkg: PackageData = {\n    dir: pkgDir,\n    data,\n    hasSideEffects,\n    webResolvedImports: {},\n    nodeResolvedImports: {},\n    setResolvedCache(key: string, entry: string, targetWeb: boolean) {\n      if (targetWeb) {\n        pkg.webResolvedImports[key] = entry\n      } else {\n        pkg.nodeResolvedImports[key] = entry\n      }\n    },\n    getResolvedCache(key: string, targetWeb: boolean) {\n      if (targetWeb) {\n        return pkg.webResolvedImports[key]\n      } else {\n        return pkg.nodeResolvedImports[key]\n      }\n    }\n  }\n\n  packageCache?.set(pkgPath, pkg)\n  return pkg\n}\n\nexport function watchPackageDataPlugin(config: ResolvedConfig): Plugin {\n  const watchQueue = new Set<string>()\n  let watchFile = (id: string) => {\n    watchQueue.add(id)\n  }\n\n  const { packageCache } = config\n  const setPackageData = packageCache.set.bind(packageCache)\n  packageCache.set = (id, pkg) => {\n    if (id.endsWith('.json')) {\n      watchFile(id)\n    }\n    return setPackageData(id, pkg)\n  }\n\n  return {\n    name: 'vite:watch-package-data',\n    buildStart() {\n      watchFile = this.addWatchFile\n      watchQueue.forEach(watchFile)\n      watchQueue.clear()\n    },\n    buildEnd() {\n      watchFile = (id) => watchQueue.add(id)\n    },\n    watchChange(id) {\n      if (id.endsWith('/package.json')) {\n        invalidatePackageData(packageCache, id)\n      }\n    }\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport { Plugin } from '../plugin'\nimport chalk from 'chalk'\nimport {\n  FS_PREFIX,\n  SPECIAL_QUERY_RE,\n  DEFAULT_EXTENSIONS,\n  DEFAULT_MAIN_FIELDS,\n  OPTIMIZABLE_ENTRY_RE\n} from '../constants'\nimport {\n  isBuiltin,\n  bareImportRE,\n  createDebugger,\n  injectQuery,\n  isExternalUrl,\n  isObject,\n  normalizePath,\n  fsPathFromId,\n  ensureVolumeInPath,\n  resolveFrom,\n  isDataUrl,\n  cleanUrl,\n  slash,\n  nestedResolveFrom,\n  isFileReadable,\n  isTsRequest,\n  isPossibleTsOutput,\n  getTsSrcPath\n} from '../utils'\nimport { ViteDevServer, SSROptions } from '..'\nimport { PartialResolvedId } from 'rollup'\nimport { resolve as _resolveExports } from 'resolve.exports'\nimport {\n  loadPackageData,\n  PackageCache,\n  PackageData,\n  resolvePackageData\n} from '../packages'\n\n// special id for paths marked with browser: false\n// https://github.com/defunctzombie/package-browser-field-spec#ignore-a-module\nexport const browserExternalId = '__vite-browser-external'\n\nconst isDebug = process.env.DEBUG\nconst debug = createDebugger('vite:resolve-details', {\n  onlyWhenFocused: true\n})\n\nexport interface ResolveOptions {\n  mainFields?: string[]\n  conditions?: string[]\n  extensions?: string[]\n  dedupe?: string[]\n  preserveSymlinks?: boolean\n}\n\nexport interface InternalResolveOptions extends ResolveOptions {\n  root: string\n  isBuild: boolean\n  isProduction: boolean\n  ssrConfig?: SSROptions\n  packageCache?: PackageCache\n  /**\n   * src code mode also attempts the following:\n   * - resolving /xxx as URLs\n   * - resolving bare imports from optimized deps\n   */\n  asSrc?: boolean\n  tryIndex?: boolean\n  tryPrefix?: string\n  skipPackageJson?: boolean\n  preferRelative?: boolean\n  preserveSymlinks?: boolean\n  isRequire?: boolean\n  // #3040\n  // when the importer is a ts module,\n  // if the specifier requests a non-existent `.js/jsx/mjs/cjs` file,\n  // should also try import from `.ts/tsx/mts/cts` source file as fallback.\n  isFromTsImporter?: boolean\n  tryEsmOnly?: boolean\n}\n\nexport function resolvePlugin(baseOptions: InternalResolveOptions): Plugin {\n  const {\n    root,\n    isProduction,\n    asSrc,\n    ssrConfig,\n    preferRelative = false\n  } = baseOptions\n  let server: ViteDevServer | undefined\n\n  const { target: ssrTarget, noExternal: ssrNoExternal } = ssrConfig ?? {}\n\n  return {\n    name: 'vite:resolve',\n\n    configureServer(_server) {\n      server = _server\n    },\n\n    resolveId(id, importer, resolveOpts) {\n      const ssr = resolveOpts?.ssr === true\n      if (id.startsWith(browserExternalId)) {\n        return id\n      }\n\n      // fast path for commonjs proxy modules\n      if (/\\?commonjs/.test(id) || id === 'commonjsHelpers.js') {\n        return\n      }\n\n      const targetWeb = !ssr || ssrTarget === 'webworker'\n\n      // this is passed by @rollup/plugin-commonjs\n      const isRequire: boolean =\n        resolveOpts?.custom?.['node-resolve']?.isRequire ?? false\n\n      const options: InternalResolveOptions = {\n        isRequire,\n\n        ...baseOptions,\n        isFromTsImporter: isTsRequest(importer ?? '')\n      }\n\n      let res: string | PartialResolvedId | undefined\n\n      // explicit fs paths that starts with /@fs/*\n      if (asSrc && id.startsWith(FS_PREFIX)) {\n        const fsPath = fsPathFromId(id)\n        res = tryFsResolve(fsPath, options)\n        isDebug && debug(`[@fs] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n        // always return here even if res doesn't exist since /@fs/ is explicit\n        // if the file doesn't exist it should be a 404\n        return res || fsPath\n      }\n\n      // URL\n      // /foo -> /fs-root/foo\n      if (asSrc && id.startsWith('/')) {\n        const fsPath = path.resolve(root, id.slice(1))\n        if ((res = tryFsResolve(fsPath, options))) {\n          isDebug && debug(`[url] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n          return res\n        }\n      }\n\n      // relative\n      if (id.startsWith('.') || (preferRelative && /^\\w/.test(id))) {\n        const basedir = importer ? path.dirname(importer) : process.cwd()\n        const fsPath = path.resolve(basedir, id)\n        // handle browser field mapping for relative imports\n\n        const normalizedFsPath = normalizePath(fsPath)\n        const pathFromBasedir = normalizedFsPath.slice(basedir.length)\n        if (pathFromBasedir.startsWith('/node_modules/')) {\n          // normalize direct imports from node_modules to bare imports, so the\n          // hashing logic is shared and we avoid duplicated modules #2503\n          const bareImport = pathFromBasedir.slice('/node_modules/'.length)\n          if (\n            (res = tryNodeResolve(\n              bareImport,\n              importer,\n              options,\n              targetWeb,\n              server,\n              ssr\n            )) &&\n            res.id.startsWith(normalizedFsPath)\n          ) {\n            return res\n          }\n        }\n\n        if (\n          targetWeb &&\n          (res = tryResolveBrowserMapping(fsPath, importer, options, true))\n        ) {\n          return res\n        }\n\n        if ((res = tryFsResolve(fsPath, options))) {\n          isDebug && debug(`[relative] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n          const pkg = importer != null && idToPkgMap.get(importer)\n          if (pkg) {\n            idToPkgMap.set(res, pkg)\n            return {\n              id: res,\n              moduleSideEffects: pkg.hasSideEffects(res)\n            }\n          }\n          return res\n        }\n      }\n\n      // absolute fs paths\n      if (path.isAbsolute(id) && (res = tryFsResolve(id, options))) {\n        isDebug && debug(`[fs] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n        return res\n      }\n\n      // external\n      if (isExternalUrl(id)) {\n        return {\n          id,\n          external: true\n        }\n      }\n\n      // data uri: pass through (this only happens during build and will be\n      // handled by dedicated plugin)\n      if (isDataUrl(id)) {\n        return null\n      }\n\n      // bare package imports, perform node resolve\n      if (bareImportRE.test(id)) {\n        if (\n          asSrc &&\n          server &&\n          !ssr &&\n          (res = tryOptimizedResolve(id, server, importer))\n        ) {\n          return res\n        }\n\n        if (\n          targetWeb &&\n          (res = tryResolveBrowserMapping(id, importer, options, false))\n        ) {\n          return res\n        }\n\n        if (\n          (res = tryNodeResolve(id, importer, options, targetWeb, server, ssr))\n        ) {\n          return res\n        }\n\n        // node built-ins.\n        // externalize if building for SSR, otherwise redirect to empty module\n        if (isBuiltin(id)) {\n          if (ssr) {\n            if (ssrNoExternal === true) {\n              let message = `Cannot bundle Node.js built-in \"${id}\"`\n              if (importer) {\n                message += ` imported from \"${path.relative(\n                  process.cwd(),\n                  importer\n                )}\"`\n              }\n              message += `. Consider disabling ssr.noExternal or remove the built-in dependency.`\n              this.error(message)\n            }\n\n            return {\n              id,\n              external: true\n            }\n          } else {\n            if (!asSrc) {\n              debug(\n                `externalized node built-in \"${id}\" to empty module. ` +\n                  `(imported by: ${chalk.white.dim(importer)})`\n              )\n            }\n            return isProduction\n              ? browserExternalId\n              : `${browserExternalId}:${id}`\n          }\n        }\n      }\n\n      isDebug && debug(`[fallthrough] ${chalk.dim(id)}`)\n    },\n\n    load(id) {\n      if (id.startsWith(browserExternalId)) {\n        return isProduction\n          ? `export default {}`\n          : `export default new Proxy({}, {\n  get() {\n    throw new Error('Module \"${id.slice(\n      browserExternalId.length + 1\n    )}\" has been externalized for browser compatibility and cannot be accessed in client code.')\n  }\n})`\n      }\n    }\n  }\n}\n\nfunction tryFsResolve(\n  fsPath: string,\n  options: InternalResolveOptions,\n  tryIndex = true,\n  targetWeb = true\n): string | undefined {\n  let file = fsPath\n  let postfix = ''\n\n  let postfixIndex = fsPath.indexOf('?')\n  if (postfixIndex < 0) {\n    postfixIndex = fsPath.indexOf('#')\n  }\n  if (postfixIndex > 0) {\n    file = fsPath.slice(0, postfixIndex)\n    postfix = fsPath.slice(postfixIndex)\n  }\n\n  let res: string | undefined\n\n  // if we fould postfix exist, we should first try resolving file with postfix. details see #4703.\n  if (\n    postfix &&\n    (res = tryResolveFile(\n      fsPath,\n      '',\n      options,\n      false,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  if (\n    (res = tryResolveFile(\n      file,\n      postfix,\n      options,\n      false,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  for (const ext of options.extensions || DEFAULT_EXTENSIONS) {\n    if (\n      postfix &&\n      (res = tryResolveFile(\n        fsPath + ext,\n        '',\n        options,\n        false,\n        targetWeb,\n        options.tryPrefix,\n        options.skipPackageJson\n      ))\n    ) {\n      return res\n    }\n\n    if (\n      (res = tryResolveFile(\n        file + ext,\n        postfix,\n        options,\n        false,\n        targetWeb,\n        options.tryPrefix,\n        options.skipPackageJson\n      ))\n    ) {\n      return res\n    }\n  }\n\n  if (\n    postfix &&\n    (res = tryResolveFile(\n      fsPath,\n      '',\n      options,\n      tryIndex,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  if (\n    (res = tryResolveFile(\n      file,\n      postfix,\n      options,\n      tryIndex,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n}\n\nfunction tryResolveFile(\n  file: string,\n  postfix: string,\n  options: InternalResolveOptions,\n  tryIndex: boolean,\n  targetWeb: boolean,\n  tryPrefix?: string,\n  skipPackageJson?: boolean\n): string | undefined {\n  // #2051 if we don't have read permission on a directory, existsSync() still\n  // works and will result in massively slow subsequent checks (which are\n  // unnecessary in the first place)\n  if (isFileReadable(file)) {\n    if (!fs.statSync(file).isDirectory()) {\n      return getRealPath(file, options.preserveSymlinks) + postfix\n    } else if (tryIndex) {\n      if (!skipPackageJson) {\n        const pkgPath = file + '/package.json'\n        try {\n          // path points to a node package\n          const pkg = loadPackageData(pkgPath, options.preserveSymlinks)\n          const resolved = resolvePackageEntry(file, pkg, targetWeb, options)\n          return resolved\n        } catch (e) {\n          if (e.code !== 'ENOENT') {\n            throw e\n          }\n        }\n      }\n      const index = tryFsResolve(file + '/index', options)\n      if (index) return index + postfix\n    }\n  }\n\n  const tryTsExtension = options.isFromTsImporter && isPossibleTsOutput(file)\n  if (tryTsExtension) {\n    const tsSrcPath = getTsSrcPath(file)\n    return tryResolveFile(\n      tsSrcPath,\n      postfix,\n      options,\n      tryIndex,\n      targetWeb,\n      tryPrefix,\n      skipPackageJson\n    )\n  }\n\n  if (tryPrefix) {\n    const prefixed = `${path.dirname(file)}/${tryPrefix}${path.basename(file)}`\n    return tryResolveFile(prefixed, postfix, options, tryIndex, targetWeb)\n  }\n}\n\nexport const idToPkgMap = new Map<string, PackageData>()\n\nexport function tryNodeResolve(\n  id: string,\n  importer: string | null | undefined,\n  options: InternalResolveOptions,\n  targetWeb: boolean,\n  server?: ViteDevServer,\n  ssr?: boolean\n): PartialResolvedId | undefined {\n  const { root, dedupe, isBuild, preserveSymlinks, packageCache } = options\n\n  // split id by last '>' for nested selected packages, for example:\n  // 'foo > bar > baz' => 'foo > bar' & 'baz'\n  // 'foo'             => ''          & 'foo'\n  const lastArrowIndex = id.lastIndexOf('>')\n  const nestedRoot = id.substring(0, lastArrowIndex).trim()\n  const nestedPath = id.substring(lastArrowIndex + 1).trim()\n\n  const possiblePkgIds: string[] = []\n  for (let prevSlashIndex = -1; ; ) {\n    let slashIndex = nestedPath.indexOf('/', prevSlashIndex + 1)\n    if (slashIndex < 0) {\n      slashIndex = nestedPath.length\n    }\n\n    const part = nestedPath.slice(\n      prevSlashIndex + 1,\n      (prevSlashIndex = slashIndex)\n    )\n    if (!part) {\n      break\n    }\n\n    // Assume path parts with an extension are not package roots, except for the\n    // first path part (since periods are sadly allowed in package names).\n    // At the same time, skip the first path part if it begins with \"@\"\n    // (since \"@foo/bar\" should be treated as the top-level path).\n    if (possiblePkgIds.length ? path.extname(part) : part[0] === '@') {\n      continue\n    }\n\n    const possiblePkgId = nestedPath.slice(0, slashIndex)\n    possiblePkgIds.push(possiblePkgId)\n  }\n\n  let basedir: string\n  if (dedupe?.some((id) => possiblePkgIds.includes(id))) {\n    basedir = root\n  } else if (\n    importer &&\n    path.isAbsolute(importer) &&\n    fs.existsSync(cleanUrl(importer))\n  ) {\n    basedir = path.dirname(importer)\n  } else {\n    basedir = root\n  }\n\n  // nested node module, step-by-step resolve to the basedir of the nestedPath\n  if (nestedRoot) {\n    basedir = nestedResolveFrom(nestedRoot, basedir, preserveSymlinks)\n  }\n\n  let pkg: PackageData | undefined\n  const pkgId = possiblePkgIds.reverse().find((pkgId) => {\n    pkg = resolvePackageData(pkgId, basedir, preserveSymlinks, packageCache)!\n    return pkg\n  })!\n\n  if (!pkg) {\n    return\n  }\n\n  let resolveId = resolvePackageEntry\n  let unresolvedId = pkgId\n  if (unresolvedId !== nestedPath) {\n    resolveId = resolveDeepImport\n    unresolvedId = '.' + nestedPath.slice(pkgId.length)\n  }\n\n  let resolved: string | undefined\n  try {\n    resolved = resolveId(unresolvedId, pkg, targetWeb, options)\n  } catch (err) {\n    if (!options.tryEsmOnly) {\n      throw err\n    }\n  }\n  if (!resolved && options.tryEsmOnly) {\n    resolved = resolveId(unresolvedId, pkg, targetWeb, {\n      ...options,\n      isRequire: false,\n      mainFields: DEFAULT_MAIN_FIELDS,\n      extensions: DEFAULT_EXTENSIONS\n    })\n  }\n  if (!resolved) {\n    return\n  }\n\n  // link id to pkg for browser field mapping check\n  idToPkgMap.set(resolved, pkg)\n  if (isBuild) {\n    // Resolve package side effects for build so that rollup can better\n    // perform tree-shaking\n    return {\n      id: resolved,\n      moduleSideEffects: pkg.hasSideEffects(resolved)\n    }\n  } else {\n    if (\n      !resolved.includes('node_modules') || // linked\n      !server || // build\n      server._isRunningOptimizer || // optimizing\n      !server._optimizeDepsMetadata\n    ) {\n      return { id: resolved }\n    }\n    // if we reach here, it's a valid dep import that hasn't been optimized.\n    const isJsType = OPTIMIZABLE_ENTRY_RE.test(resolved)\n    const exclude = server.config.optimizeDeps?.exclude\n    if (\n      !isJsType ||\n      importer?.includes('node_modules') ||\n      exclude?.includes(pkgId) ||\n      exclude?.includes(nestedPath) ||\n      SPECIAL_QUERY_RE.test(resolved) ||\n      ssr\n    ) {\n      // excluded from optimization\n      // Inject a version query to npm deps so that the browser\n      // can cache it without re-validation, but only do so for known js types.\n      // otherwise we may introduce duplicated modules for externalized files\n      // from pre-bundled deps.\n      const versionHash = server._optimizeDepsMetadata?.browserHash\n      if (versionHash && isJsType) {\n        resolved = injectQuery(resolved, `v=${versionHash}`)\n      }\n    } else {\n      // this is a missing import.\n      // queue optimize-deps re-run.\n      server._registerMissingImport?.(id, resolved, ssr)\n    }\n    return { id: resolved }\n  }\n}\n\nexport function tryOptimizedResolve(\n  id: string,\n  server: ViteDevServer,\n  importer?: string\n): string | undefined {\n  const cacheDir = server.config.cacheDir\n  const depData = server._optimizeDepsMetadata\n\n  if (!cacheDir || !depData) return\n\n  const getOptimizedUrl = (optimizedData: typeof depData.optimized[string]) => {\n    return (\n      optimizedData.file +\n      `?v=${depData.browserHash}${\n        optimizedData.needsInterop ? `&es-interop` : ``\n      }`\n    )\n  }\n\n  // check if id has been optimized\n  const isOptimized = depData.optimized[id]\n  if (isOptimized) {\n    return getOptimizedUrl(isOptimized)\n  }\n\n  if (!importer) return\n\n  // further check if id is imported by nested dependency\n  let resolvedSrc: string | undefined\n\n  for (const [pkgPath, optimizedData] of Object.entries(depData.optimized)) {\n    // check for scenarios, e.g.\n    //   pkgPath  => \"my-lib > foo\"\n    //   id       => \"foo\"\n    // this narrows the need to do a full resolve\n    if (!pkgPath.endsWith(id)) continue\n\n    // lazily initialize resolvedSrc\n    if (resolvedSrc == null) {\n      try {\n        // this may throw errors if unable to resolve, e.g. aliased id\n        resolvedSrc = normalizePath(resolveFrom(id, path.dirname(importer)))\n      } catch {\n        // this is best-effort only so swallow errors\n        break\n      }\n    }\n\n    // match by src to correctly identify if id belongs to nested dependency\n    if (optimizedData.src === resolvedSrc) {\n      return getOptimizedUrl(optimizedData)\n    }\n  }\n}\n\nexport function resolvePackageEntry(\n  id: string,\n  { dir, data, setResolvedCache, getResolvedCache }: PackageData,\n  targetWeb: boolean,\n  options: InternalResolveOptions\n): string | undefined {\n  const cached = getResolvedCache('.', targetWeb)\n  if (cached) {\n    return cached\n  }\n  try {\n    let entryPoint: string | undefined | void\n\n    // resolve exports field with highest priority\n    // using https://github.com/lukeed/resolve.exports\n    if (data.exports) {\n      entryPoint = resolveExports(data, '.', options, targetWeb)\n    }\n\n    // if exports resolved to .mjs, still resolve other fields.\n    // This is because .mjs files can technically import .cjs files which would\n    // make them invalid for pure ESM environments - so if other module/browser\n    // fields are present, prioritize those instead.\n    if (targetWeb && (!entryPoint || entryPoint.endsWith('.mjs'))) {\n      // check browser field\n      // https://github.com/defunctzombie/package-browser-field-spec\n      const browserEntry =\n        typeof data.browser === 'string'\n          ? data.browser\n          : isObject(data.browser) && data.browser['.']\n      if (browserEntry) {\n        // check if the package also has a \"module\" field.\n        if (typeof data.module === 'string' && data.module !== browserEntry) {\n          // if both are present, we may have a problem: some package points both\n          // to ESM, with \"module\" targeting Node.js, while some packages points\n          // \"module\" to browser ESM and \"browser\" to UMD.\n          // the heuristics here is to actually read the browser entry when\n          // possible and check for hints of UMD. If it is UMD, prefer \"module\"\n          // instead; Otherwise, assume it's ESM and use it.\n          const resolvedBrowserEntry = tryFsResolve(\n            path.join(dir, browserEntry),\n            options\n          )\n          if (resolvedBrowserEntry) {\n            const content = fs.readFileSync(resolvedBrowserEntry, 'utf-8')\n            if (\n              (/typeof exports\\s*==/.test(content) &&\n                /typeof module\\s*==/.test(content)) ||\n              /module\\.exports\\s*=/.test(content)\n            ) {\n              // likely UMD or CJS(!!! e.g. firebase 7.x), prefer module\n              entryPoint = data.module\n            }\n          }\n        } else {\n          entryPoint = browserEntry\n        }\n      }\n    }\n\n    if (!entryPoint || entryPoint.endsWith('.mjs')) {\n      for (const field of options.mainFields || DEFAULT_MAIN_FIELDS) {\n        if (typeof data[field] === 'string') {\n          entryPoint = data[field]\n          break\n        }\n      }\n    }\n\n    entryPoint = entryPoint || data.main || 'index.js'\n\n    // make sure we don't get scripts when looking for sass\n    if (\n      options.mainFields?.[0] === 'sass' &&\n      !options.extensions?.includes(path.extname(entryPoint))\n    ) {\n      entryPoint = ''\n      options.skipPackageJson = true\n    }\n\n    // resolve object browser field in package.json\n    const { browser: browserField } = data\n    if (targetWeb && isObject(browserField)) {\n      entryPoint = mapWithBrowserField(entryPoint, browserField) || entryPoint\n    }\n\n    entryPoint = path.join(dir, entryPoint)\n    const resolvedEntryPoint = tryFsResolve(entryPoint, options)\n\n    if (resolvedEntryPoint) {\n      isDebug &&\n        debug(\n          `[package entry] ${chalk.cyan(id)} -> ${chalk.dim(\n            resolvedEntryPoint\n          )}`\n        )\n      setResolvedCache('.', resolvedEntryPoint, targetWeb)\n      return resolvedEntryPoint\n    } else {\n      packageEntryFailure(id)\n    }\n  } catch (e) {\n    packageEntryFailure(id, e.message)\n  }\n}\n\nfunction packageEntryFailure(id: string, details?: string) {\n  throw new Error(\n    `Failed to resolve entry for package \"${id}\". ` +\n      `The package may have incorrect main/module/exports specified in its package.json` +\n      (details ? ': ' + details : '.')\n  )\n}\n\nfunction resolveExports(\n  pkg: PackageData['data'],\n  key: string,\n  options: InternalResolveOptions,\n  targetWeb: boolean\n) {\n  const conditions = [options.isProduction ? 'production' : 'development']\n  if (!options.isRequire) {\n    conditions.push('module')\n  }\n  if (options.conditions) {\n    conditions.push(...options.conditions)\n  }\n  return _resolveExports(pkg, key, {\n    browser: targetWeb,\n    require: options.isRequire,\n    conditions\n  })\n}\n\nfunction resolveDeepImport(\n  id: string,\n  {\n    webResolvedImports,\n    setResolvedCache,\n    getResolvedCache,\n    dir,\n    data\n  }: PackageData,\n  targetWeb: boolean,\n  options: InternalResolveOptions\n): string | undefined {\n  const cache = getResolvedCache(id, targetWeb)\n  if (cache) {\n    return cache\n  }\n\n  let relativeId: string | undefined | void = id\n  const { exports: exportsField, browser: browserField } = data\n\n  // map relative based on exports data\n  if (exportsField) {\n    if (isObject(exportsField) && !Array.isArray(exportsField)) {\n      relativeId = resolveExports(data, relativeId, options, targetWeb)\n    } else {\n      // not exposed\n      relativeId = undefined\n    }\n    if (!relativeId) {\n      throw new Error(\n        `Package subpath '${relativeId}' is not defined by \"exports\" in ` +\n          `${path.join(dir, 'package.json')}.`\n      )\n    }\n  } else if (targetWeb && isObject(browserField)) {\n    const mapped = mapWithBrowserField(relativeId, browserField)\n    if (mapped) {\n      relativeId = mapped\n    } else if (mapped === false) {\n      return (webResolvedImports[id] = browserExternalId)\n    }\n  }\n\n  if (relativeId) {\n    const resolved = tryFsResolve(\n      path.join(dir, relativeId),\n      options,\n      !exportsField, // try index only if no exports field\n      targetWeb\n    )\n    if (resolved) {\n      isDebug &&\n        debug(`[node/deep-import] ${chalk.cyan(id)} -> ${chalk.dim(resolved)}`)\n      setResolvedCache(id, resolved, targetWeb)\n      return resolved\n    }\n  }\n}\n\nfunction tryResolveBrowserMapping(\n  id: string,\n  importer: string | undefined,\n  options: InternalResolveOptions,\n  isFilePath: boolean\n) {\n  let res: string | undefined\n  const pkg = importer && idToPkgMap.get(importer)\n  if (pkg && isObject(pkg.data.browser)) {\n    const mapId = isFilePath ? './' + slash(path.relative(pkg.dir, id)) : id\n    const browserMappedPath = mapWithBrowserField(mapId, pkg.data.browser)\n    if (browserMappedPath) {\n      const fsPath = path.join(pkg.dir, browserMappedPath)\n      if ((res = tryFsResolve(fsPath, options))) {\n        isDebug &&\n          debug(`[browser mapped] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n        idToPkgMap.set(res, pkg)\n        return {\n          id: res,\n          moduleSideEffects: pkg.hasSideEffects(res)\n        }\n      }\n    } else if (browserMappedPath === false) {\n      return browserExternalId\n    }\n  }\n}\n\n/**\n * given a relative path in pkg dir,\n * return a relative path in pkg dir,\n * mapped with the \"map\" object\n *\n * - Returning `undefined` means there is no browser mapping for this id\n * - Returning `false` means this id is explicitly externalized for browser\n */\nfunction mapWithBrowserField(\n  relativePathInPkgDir: string,\n  map: Record<string, string | false>\n): string | false | undefined {\n  const normalizedPath = path.posix.normalize(relativePathInPkgDir)\n\n  for (const key in map) {\n    const normalizedKey = path.posix.normalize(key)\n    if (\n      normalizedPath === normalizedKey ||\n      equalWithoutSuffix(normalizedPath, normalizedKey, '.js') ||\n      equalWithoutSuffix(normalizedPath, normalizedKey, '/index.js')\n    ) {\n      return map[key]\n    }\n  }\n}\n\nfunction equalWithoutSuffix(path: string, key: string, suffix: string) {\n  return key.endsWith(suffix) && key.slice(0, -suffix.length) === path\n}\n\nfunction getRealPath(resolved: string, preserveSymlinks?: boolean): string {\n  resolved = ensureVolumeInPath(resolved)\n  if (!preserveSymlinks && browserExternalId !== resolved) {\n    resolved = fs.realpathSync(resolved)\n  }\n  return normalizePath(resolved)\n}\n","import fs from 'fs'\nimport path from 'path'\nimport { tryNodeResolve, InternalResolveOptions } from '../plugins/resolve'\nimport {\n  createDebugger,\n  isDefined,\n  lookupFile,\n  normalizePath,\n  resolveFrom\n} from '../utils'\nimport { Logger, ResolvedConfig } from '..'\nimport { createFilter } from '@rollup/pluginutils'\n\nconst debug = createDebugger('vite:ssr-external')\n\n/**\n * Heuristics for determining whether a dependency should be externalized for\n * server-side rendering.\n */\nexport function resolveSSRExternal(\n  config: ResolvedConfig,\n  knownImports: string[]\n): string[] {\n  const ssrConfig = config.ssr\n  if (ssrConfig?.noExternal === true) {\n    return []\n  }\n\n  const ssrExternals: Set<string> = new Set()\n  const seen: Set<string> = new Set()\n  ssrConfig?.external?.forEach((id) => {\n    ssrExternals.add(id)\n    seen.add(id)\n  })\n\n  collectExternals(\n    config.root,\n    config.resolve.preserveSymlinks,\n    ssrExternals,\n    seen,\n    config.logger\n  )\n\n  const importedDeps = knownImports.map(getNpmPackageName).filter(isDefined)\n  for (const dep of importedDeps) {\n    // Assume external if not yet seen\n    // At this point, the project root and any linked packages have had their dependencies checked,\n    // so we can safely mark any knownImports not yet seen as external. They are guaranteed to be\n    // dependencies of packages in node_modules.\n    if (!seen.has(dep)) {\n      ssrExternals.add(dep)\n    }\n  }\n\n  // ensure `vite/dynamic-import-polyfill` is bundled (issue #1865)\n  ssrExternals.delete('vite')\n\n  let externals = [...ssrExternals]\n  if (ssrConfig?.noExternal) {\n    externals = externals.filter(\n      createFilter(undefined, ssrConfig.noExternal, { resolve: false })\n    )\n  }\n  return externals\n}\n\n// do we need to do this ahead of time or could we do it lazily?\nfunction collectExternals(\n  root: string,\n  preserveSymlinks: boolean | undefined,\n  ssrExternals: Set<string>,\n  seen: Set<string>,\n  logger: Logger\n) {\n  const rootPkgContent = lookupFile(root, ['package.json'])\n  if (!rootPkgContent) {\n    return\n  }\n\n  const rootPkg = JSON.parse(rootPkgContent)\n  const deps = {\n    ...rootPkg.devDependencies,\n    ...rootPkg.dependencies\n  }\n\n  const resolveOptions: InternalResolveOptions = {\n    root,\n    preserveSymlinks,\n    isProduction: false,\n    isBuild: true\n  }\n\n  const depsToTrace = new Set<string>()\n\n  for (const id in deps) {\n    if (seen.has(id)) continue\n    seen.add(id)\n\n    let esmEntry: string | undefined\n    let requireEntry: string\n    try {\n      esmEntry = tryNodeResolve(\n        id,\n        undefined,\n        resolveOptions,\n        true, // we set `targetWeb` to `true` to get the ESM entry\n        undefined,\n        true\n      )?.id\n      // normalizePath required for windows. tryNodeResolve uses normalizePath\n      // which returns with '/', require.resolve returns with '\\\\'\n      requireEntry = normalizePath(require.resolve(id, { paths: [root] }))\n    } catch (e) {\n      try {\n        // no main entry, but deep imports may be allowed\n        const pkgPath = resolveFrom(`${id}/package.json`, root)\n        if (pkgPath.includes('node_modules')) {\n          ssrExternals.add(id)\n        } else {\n          depsToTrace.add(path.dirname(pkgPath))\n        }\n        continue\n      } catch {}\n\n      // resolve failed, assume include\n      debug(`Failed to resolve entries for package \"${id}\"\\n`, e)\n      continue\n    }\n    // no esm entry but has require entry\n    if (!esmEntry) {\n      ssrExternals.add(id)\n    }\n    // trace the dependencies of linked packages\n    else if (!esmEntry.includes('node_modules')) {\n      const pkgPath = resolveFrom(`${id}/package.json`, root)\n      depsToTrace.add(path.dirname(pkgPath))\n    }\n    // has separate esm/require entry, assume require entry is cjs\n    else if (esmEntry !== requireEntry) {\n      ssrExternals.add(id)\n    }\n    // if we're externalizing ESM and CJS should basically just always do it?\n    // or are there others like SystemJS / AMD that we'd need to handle?\n    // for now, we'll just leave this as is\n    else if (/\\.m?js$/.test(esmEntry)) {\n      const pkgPath = resolveFrom(`${id}/package.json`, root)\n      const pkgContent = fs.readFileSync(pkgPath, 'utf-8')\n\n      if (!pkgContent) {\n        continue\n      }\n      const pkg = JSON.parse(pkgContent)\n\n      if (pkg.type === 'module' || esmEntry.endsWith('.mjs')) {\n        ssrExternals.add(id)\n        continue\n      }\n      // check if the entry is cjs\n      const content = fs.readFileSync(esmEntry, 'utf-8')\n      if (/\\bmodule\\.exports\\b|\\bexports[.\\[]|\\brequire\\s*\\(/.test(content)) {\n        ssrExternals.add(id)\n        continue\n      }\n\n      logger.warn(\n        `${id} is incorrectly packaged. Please contact the package author to fix.`\n      )\n    }\n  }\n\n  for (const depRoot of depsToTrace) {\n    collectExternals(depRoot, preserveSymlinks, ssrExternals, seen, logger)\n  }\n}\n\nexport function shouldExternalizeForSSR(\n  id: string,\n  externals: string[]\n): boolean {\n  const should = externals.some((e) => {\n    if (id === e) {\n      return true\n    }\n    // deep imports, check ext before externalizing - only externalize\n    // extension-less imports and explicit .js imports\n    if (id.startsWith(e + '/') && (!path.extname(id) || id.endsWith('.js'))) {\n      return true\n    }\n  })\n  return should\n}\n\nfunction getNpmPackageName(importPath: string): string | null {\n  const parts = importPath.split('/')\n  if (parts[0].startsWith('@')) {\n    if (!parts[1]) return null\n    return `${parts[0]}/${parts[1]}`\n  } else {\n    return parts[0]\n  }\n}\n","import chalk from 'chalk'\nimport { RollupError } from 'rollup'\nimport { ViteDevServer } from '../..'\nimport { Connect } from 'types/connect'\nimport { pad } from '../../utils'\nimport strip from 'strip-ansi'\nimport { ErrorPayload } from 'types/hmrPayload'\n\nexport function prepareError(err: Error | RollupError): ErrorPayload['err'] {\n  // only copy the information we need and avoid serializing unnecessary\n  // properties, since some errors may attach full objects (e.g. PostCSS)\n  return {\n    message: strip(err.message),\n    stack: strip(cleanStack(err.stack || '')),\n    id: (err as RollupError).id,\n    frame: strip((err as RollupError).frame || ''),\n    plugin: (err as RollupError).plugin,\n    pluginCode: (err as RollupError).pluginCode,\n    loc: (err as RollupError).loc\n  }\n}\n\nexport function buildErrorMessage(\n  err: RollupError,\n  args: string[] = [],\n  includeStack = true\n): string {\n  if (err.plugin) args.push(`  Plugin: ${chalk.magenta(err.plugin)}`)\n  if (err.id) args.push(`  File: ${chalk.cyan(err.id)}`)\n  if (err.frame) args.push(chalk.yellow(pad(err.frame)))\n  if (includeStack && err.stack) args.push(pad(cleanStack(err.stack)))\n  return args.join('\\n')\n}\n\nfunction cleanStack(stack: string) {\n  return stack\n    .split(/\\n/g)\n    .filter((l) => /^\\s*at/.test(l))\n    .join('\\n')\n}\n\nexport function logError(server: ViteDevServer, err: RollupError): void {\n  const msg = buildErrorMessage(err, [\n    chalk.red(`Internal server error: ${err.message}`)\n  ])\n\n  server.config.logger.error(msg, {\n    clear: true,\n    timestamp: true,\n    error: err\n  })\n\n  server.ws.send({\n    type: 'error',\n    err: prepareError(err)\n  })\n}\n\nexport function errorMiddleware(\n  server: ViteDevServer,\n  allowNext = false\n): Connect.ErrorHandleFunction {\n  // note the 4 args must be kept for connect to treat this as error middleware\n  // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n  return function viteErrorMiddleware(err: RollupError, _req, res, next) {\n    logError(server, err)\n\n    if (allowNext) {\n      next()\n    } else {\n      res.statusCode = 500\n      res.end()\n    }\n  }\n}\n","/**\n * This file is refactored into TypeScript based on\n * https://github.com/preactjs/wmr/blob/main/packages/wmr/src/lib/rollup-plugin-container.js\n */\n\n/**\nhttps://github.com/preactjs/wmr/blob/master/LICENSE\n\nMIT License\n\nCopyright (c) 2020 The Preact Authors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n*/\n\nimport fs from 'fs'\nimport { join } from 'path'\nimport { Plugin } from '../plugin'\nimport {\n  InputOptions,\n  MinimalPluginContext,\n  OutputOptions,\n  ModuleInfo,\n  NormalizedInputOptions,\n  PartialResolvedId,\n  ResolvedId,\n  PluginContext as RollupPluginContext,\n  LoadResult,\n  SourceDescription,\n  EmittedFile,\n  SourceMap,\n  RollupError,\n  TransformResult\n} from 'rollup'\nimport * as acorn from 'acorn'\nimport acornClassFields from 'acorn-class-fields'\nimport acornStaticClassFeatures from 'acorn-static-class-features'\nimport { RawSourceMap } from '@ampproject/remapping/dist/types/types'\nimport { combineSourcemaps } from '../utils'\nimport MagicString from 'magic-string'\nimport { FSWatcher } from 'chokidar'\nimport {\n  createDebugger,\n  ensureWatchedFile,\n  generateCodeFrame,\n  isObject,\n  isExternalUrl,\n  normalizePath,\n  numberToPos,\n  prettifyUrl,\n  timeFrom\n} from '../utils'\nimport { FS_PREFIX } from '../constants'\nimport chalk from 'chalk'\nimport { ResolvedConfig } from '../config'\nimport { buildErrorMessage } from './middlewares/error'\nimport { ModuleGraph } from './moduleGraph'\nimport { performance } from 'perf_hooks'\n\nexport interface PluginContainerOptions {\n  cwd?: string\n  output?: OutputOptions\n  modules?: Map<string, { info: ModuleInfo }>\n  writeFile?: (name: string, source: string | Uint8Array) => void\n}\n\nexport interface PluginContainer {\n  options: InputOptions\n  getModuleInfo(id: string): ModuleInfo | null\n  buildStart(options: InputOptions): Promise<void>\n  resolveId(\n    id: string,\n    importer?: string,\n    options?: {\n      skip?: Set<Plugin>\n      ssr?: boolean\n    }\n  ): Promise<PartialResolvedId | null>\n  transform(\n    code: string,\n    id: string,\n    options?: {\n      inMap?: SourceDescription['map']\n      ssr?: boolean\n    }\n  ): Promise<SourceDescription | null>\n  load(\n    id: string,\n    options?: {\n      ssr?: boolean\n    }\n  ): Promise<LoadResult | null>\n  close(): Promise<void>\n}\n\ntype PluginContext = Omit<\n  RollupPluginContext,\n  // not documented\n  | 'cache'\n  // deprecated\n  | 'emitAsset'\n  | 'emitChunk'\n  | 'getAssetFileName'\n  | 'getChunkFileName'\n  | 'isExternal'\n  | 'moduleIds'\n  | 'resolveId'\n  | 'load'\n>\n\nexport let parser = acorn.Parser.extend(\n  acornClassFields,\n  acornStaticClassFeatures\n)\n\nexport async function createPluginContainer(\n  { plugins, logger, root, build: { rollupOptions } }: ResolvedConfig,\n  moduleGraph?: ModuleGraph,\n  watcher?: FSWatcher\n): Promise<PluginContainer> {\n  const isDebug = process.env.DEBUG\n\n  const seenResolves: Record<string, true | undefined> = {}\n  const debugResolve = createDebugger('vite:resolve')\n  const debugPluginResolve = createDebugger('vite:plugin-resolve', {\n    onlyWhenFocused: 'vite:plugin'\n  })\n  const debugPluginTransform = createDebugger('vite:plugin-transform', {\n    onlyWhenFocused: 'vite:plugin'\n  })\n\n  // ---------------------------------------------------------------------------\n\n  const watchFiles = new Set<string>()\n\n  // get rollup version\n  const minimalContext: MinimalPluginContext = {\n    meta: {\n      rollupVersion: '2.38.5',\n      watchMode: true\n    }\n  }\n\n  function warnIncompatibleMethod(method: string, plugin: string) {\n    logger.warn(\n      chalk.cyan(`[plugin:${plugin}] `) +\n        chalk.yellow(\n          `context method ${chalk.bold(\n            `${method}()`\n          )} is not supported in serve mode. This plugin is likely not vite-compatible.`\n        )\n    )\n  }\n\n  // throw when an unsupported ModuleInfo property is accessed,\n  // so that incompatible plugins fail in a non-cryptic way.\n  const ModuleInfoProxy: ProxyHandler<ModuleInfo> = {\n    get(info: any, key: string) {\n      if (key in info) {\n        return info[key]\n      }\n      throw Error(\n        `[vite] The \"${key}\" property of ModuleInfo is not supported.`\n      )\n    }\n  }\n\n  // same default value of \"moduleInfo.meta\" as in Rollup\n  const EMPTY_OBJECT = Object.freeze({})\n\n  function getModuleInfo(id: string) {\n    const module = moduleGraph?.getModuleById(id)\n    if (!module) {\n      return null\n    }\n    if (!module.info) {\n      module.info = new Proxy(\n        { id, meta: module.meta || EMPTY_OBJECT } as ModuleInfo,\n        ModuleInfoProxy\n      )\n    }\n    return module.info\n  }\n\n  function updateModuleInfo(id: string, { meta }: { meta?: object | null }) {\n    if (meta) {\n      const moduleInfo = getModuleInfo(id)\n      if (moduleInfo) {\n        moduleInfo.meta = { ...moduleInfo.meta, ...meta }\n      }\n    }\n  }\n\n  // we should create a new context for each async hook pipeline so that the\n  // active plugin in that pipeline can be tracked in a concurrency-safe manner.\n  // using a class to make creating new contexts more efficient\n  class Context implements PluginContext {\n    meta = minimalContext.meta\n    ssr = false\n    _activePlugin: Plugin | null\n    _activeId: string | null = null\n    _activeCode: string | null = null\n    _resolveSkips?: Set<Plugin>\n    _addedImports: Set<string> | null = null\n\n    constructor(initialPlugin?: Plugin) {\n      this._activePlugin = initialPlugin || null\n    }\n\n    parse(code: string, opts: any = {}) {\n      return parser.parse(code, {\n        sourceType: 'module',\n        ecmaVersion: 'latest',\n        locations: true,\n        ...opts\n      })\n    }\n\n    async resolve(\n      id: string,\n      importer?: string,\n      options?: { skipSelf?: boolean }\n    ) {\n      let skip: Set<Plugin> | undefined\n      if (options?.skipSelf && this._activePlugin) {\n        skip = new Set(this._resolveSkips)\n        skip.add(this._activePlugin)\n      }\n      let out = await container.resolveId(id, importer, { skip, ssr: this.ssr })\n      if (typeof out === 'string') out = { id: out }\n      return out as ResolvedId | null\n    }\n\n    getModuleInfo(id: string) {\n      return getModuleInfo(id)\n    }\n\n    getModuleIds() {\n      return moduleGraph\n        ? moduleGraph.idToModuleMap.keys()\n        : Array.prototype[Symbol.iterator]()\n    }\n\n    addWatchFile(id: string) {\n      watchFiles.add(id)\n      ;(this._addedImports || (this._addedImports = new Set())).add(id)\n      if (watcher) ensureWatchedFile(watcher, id, root)\n    }\n\n    getWatchFiles() {\n      return [...watchFiles]\n    }\n\n    emitFile(assetOrFile: EmittedFile) {\n      warnIncompatibleMethod(`emitFile`, this._activePlugin!.name)\n      return ''\n    }\n\n    setAssetSource() {\n      warnIncompatibleMethod(`setAssetSource`, this._activePlugin!.name)\n    }\n\n    getFileName() {\n      warnIncompatibleMethod(`getFileName`, this._activePlugin!.name)\n      return ''\n    }\n\n    warn(\n      e: string | RollupError,\n      position?: number | { column: number; line: number }\n    ) {\n      const err = formatError(e, position, this)\n      const msg = buildErrorMessage(\n        err,\n        [chalk.yellow(`warning: ${err.message}`)],\n        false\n      )\n      logger.warn(msg, {\n        clear: true,\n        timestamp: true\n      })\n    }\n\n    error(\n      e: string | RollupError,\n      position?: number | { column: number; line: number }\n    ): never {\n      // error thrown here is caught by the transform middleware and passed on\n      // the the error middleware.\n      throw formatError(e, position, this)\n    }\n  }\n\n  function formatError(\n    e: string | RollupError,\n    position: number | { column: number; line: number } | undefined,\n    ctx: Context\n  ) {\n    const err = (typeof e === 'string' ? new Error(e) : e) as RollupError\n    if (ctx._activePlugin) err.plugin = ctx._activePlugin.name\n    if (ctx._activeId && !err.id) err.id = ctx._activeId\n    if (ctx._activeCode) {\n      err.pluginCode = ctx._activeCode\n      const pos =\n        position != null\n          ? position\n          : err.pos != null\n          ? err.pos\n          : // some rollup plugins, e.g. json, sets position instead of pos\n            (err as any).position\n      if (pos != null) {\n        let errLocation\n        try {\n          errLocation = numberToPos(ctx._activeCode, pos)\n        } catch (err2) {\n          logger.error(\n            chalk.red(\n              `Error in error handler:\\n${err2.stack || err2.message}\\n`\n            ),\n            // print extra newline to separate the two errors\n            { error: err2 }\n          )\n          throw err\n        }\n        err.loc = err.loc || {\n          file: err.id,\n          ...errLocation\n        }\n        err.frame = err.frame || generateCodeFrame(ctx._activeCode, pos)\n      } else if (err.loc) {\n        // css preprocessors may report errors in an included file\n        if (!err.frame) {\n          let code = ctx._activeCode\n          if (err.loc.file) {\n            err.id = normalizePath(err.loc.file)\n            try {\n              code = fs.readFileSync(err.loc.file, 'utf-8')\n            } catch {}\n          }\n          err.frame = generateCodeFrame(code, err.loc)\n        }\n      } else if ((err as any).line && (err as any).column) {\n        err.loc = {\n          file: err.id,\n          line: (err as any).line,\n          column: (err as any).column\n        }\n        err.frame = err.frame || generateCodeFrame(ctx._activeCode, err.loc)\n      }\n    }\n    return err\n  }\n\n  class TransformContext extends Context {\n    filename: string\n    originalCode: string\n    originalSourcemap: SourceMap | null = null\n    sourcemapChain: NonNullable<SourceDescription['map']>[] = []\n    combinedMap: SourceMap | null = null\n\n    constructor(filename: string, code: string, inMap?: SourceMap | string) {\n      super()\n      this.filename = filename\n      this.originalCode = code\n      if (inMap) {\n        this.sourcemapChain.push(inMap)\n      }\n    }\n\n    _getCombinedSourcemap(createIfNull = false) {\n      let combinedMap = this.combinedMap\n      for (let m of this.sourcemapChain) {\n        if (typeof m === 'string') m = JSON.parse(m)\n        if (!('version' in (m as SourceMap))) {\n          // empty, nullified source map\n          combinedMap = this.combinedMap = null\n          this.sourcemapChain.length = 0\n          break\n        }\n        if (!combinedMap) {\n          combinedMap = m as SourceMap\n        } else {\n          combinedMap = combineSourcemaps(this.filename, [\n            {\n              ...(m as RawSourceMap),\n              sourcesContent: combinedMap.sourcesContent\n            },\n            combinedMap as RawSourceMap\n          ]) as SourceMap\n        }\n      }\n      if (!combinedMap) {\n        return createIfNull\n          ? new MagicString(this.originalCode).generateMap({\n              includeContent: true,\n              hires: true,\n              source: this.filename\n            })\n          : null\n      }\n      if (combinedMap !== this.combinedMap) {\n        this.combinedMap = combinedMap\n        this.sourcemapChain.length = 0\n      }\n      return this.combinedMap\n    }\n\n    getCombinedSourcemap() {\n      return this._getCombinedSourcemap(true) as SourceMap\n    }\n  }\n\n  let closed = false\n\n  const container: PluginContainer = {\n    options: await (async () => {\n      let options = rollupOptions\n      for (const plugin of plugins) {\n        if (!plugin.options) continue\n        options =\n          (await plugin.options.call(minimalContext, options)) || options\n      }\n      if (options.acornInjectPlugins) {\n        parser = acorn.Parser.extend(\n          ...[acornClassFields, acornStaticClassFeatures].concat(\n            options.acornInjectPlugins\n          )\n        )\n      }\n      return {\n        acorn,\n        acornInjectPlugins: [],\n        ...options\n      }\n    })(),\n\n    getModuleInfo,\n\n    async buildStart() {\n      await Promise.all(\n        plugins.map((plugin) => {\n          if (plugin.buildStart) {\n            return plugin.buildStart.call(\n              new Context(plugin) as any,\n              container.options as NormalizedInputOptions\n            )\n          }\n        })\n      )\n    },\n\n    async resolveId(rawId, importer = join(root, 'index.html'), options) {\n      const skip = options?.skip\n      const ssr = options?.ssr\n      const ctx = new Context()\n      ctx.ssr = !!ssr\n      ctx._resolveSkips = skip\n      const resolveStart = isDebug ? performance.now() : 0\n\n      let id: string | null = null\n      const partial: Partial<PartialResolvedId> = {}\n      for (const plugin of plugins) {\n        if (!plugin.resolveId) continue\n        if (skip?.has(plugin)) continue\n\n        ctx._activePlugin = plugin\n\n        const pluginResolveStart = isDebug ? performance.now() : 0\n        const result = await plugin.resolveId.call(\n          ctx as any,\n          rawId,\n          importer,\n          { ssr }\n        )\n        if (!result) continue\n\n        if (typeof result === 'string') {\n          id = result\n        } else {\n          id = result.id\n          Object.assign(partial, result)\n        }\n\n        isDebug &&\n          debugPluginResolve(\n            timeFrom(pluginResolveStart),\n            plugin.name,\n            prettifyUrl(id, root)\n          )\n\n        // resolveId() is hookFirst - first non-null result is returned.\n        break\n      }\n\n      if (isDebug && rawId !== id && !rawId.startsWith(FS_PREFIX)) {\n        const key = rawId + id\n        // avoid spamming\n        if (!seenResolves[key]) {\n          seenResolves[key] = true\n          debugResolve(\n            `${timeFrom(resolveStart)} ${chalk.cyan(rawId)} -> ${chalk.dim(id)}`\n          )\n        }\n      }\n\n      if (id) {\n        partial.id = isExternalUrl(id) ? id : normalizePath(id)\n        return partial as PartialResolvedId\n      } else {\n        return null\n      }\n    },\n\n    async load(id, options) {\n      const ssr = options?.ssr\n      const ctx = new Context()\n      ctx.ssr = !!ssr\n      for (const plugin of plugins) {\n        if (!plugin.load) continue\n        ctx._activePlugin = plugin\n        let result: LoadResult;\n        try {\n          result = await plugin.load.call(ctx as any, id, { ssr })\n        } catch (e) {\n          ctx.error(e);\n        }\n        if (result != null) {\n          if (isObject(result)) {\n            updateModuleInfo(id, result)\n          }\n          return result\n        }\n      }\n      return null\n    },\n\n    async transform(code, id, options) {\n      const inMap = options?.inMap\n      const ssr = options?.ssr\n      const ctx = new TransformContext(id, code, inMap as SourceMap)\n      ctx.ssr = !!ssr\n      for (const plugin of plugins) {\n        if (!plugin.transform) continue\n        ctx._activePlugin = plugin\n        ctx._activeId = id\n        ctx._activeCode = code\n        const start = isDebug ? performance.now() : 0\n        let result: TransformResult | string | undefined\n        try {\n          result = await plugin.transform.call(ctx as any, code, id, { ssr })\n        } catch (e) {\n          ctx.error(e)\n        }\n        if (!result) continue\n        isDebug &&\n          debugPluginTransform(\n            timeFrom(start),\n            plugin.name,\n            prettifyUrl(id, root)\n          )\n        if (isObject(result)) {\n          if (result.code !== undefined) {\n            code = result.code\n            if (result.map) {\n              ctx.sourcemapChain.push(result.map)\n            }\n          }\n          updateModuleInfo(id, result)\n        } else {\n          code = result\n        }\n      }\n      return {\n        code,\n        map: ctx._getCombinedSourcemap()\n      }\n    },\n\n    async close() {\n      if (closed) return\n      const ctx = new Context()\n      await Promise.all(\n        plugins.map((p) => p.buildEnd && p.buildEnd.call(ctx as any))\n      )\n      await Promise.all(\n        plugins.map((p) => p.closeBundle && p.closeBundle.call(ctx as any))\n      )\n      closed = true\n    }\n  }\n\n  return container\n}\n","import fs from 'fs'\nimport path from 'path'\nimport glob from 'fast-glob'\nimport { ResolvedConfig } from '..'\nimport { Loader, Plugin, build, transform, OnLoadResult } from 'esbuild'\nimport {\n  KNOWN_ASSET_TYPES,\n  JS_TYPES_RE,\n  SPECIAL_QUERY_RE,\n  OPTIMIZABLE_ENTRY_RE\n} from '../constants'\nimport {\n  createDebugger,\n  normalizePath,\n  isObject,\n  cleanUrl,\n  moduleListContains,\n  externalRE,\n  dataUrlRE,\n  multilineCommentsRE,\n  singlelineCommentsRE,\n  virtualModuleRE,\n  virtualModulePrefix\n} from '../utils'\nimport {\n  createPluginContainer,\n  PluginContainer\n} from '../server/pluginContainer'\nimport { init, parse } from 'es-module-lexer'\nimport MagicString from 'magic-string'\nimport { transformImportGlob } from '../importGlob'\nimport { performance } from 'perf_hooks'\nimport chalk from 'chalk'\n\nconst debug = createDebugger('vite:deps')\n\nconst htmlTypesRE = /\\.(html|vue|svelte|astro)$/\n\nconst setupRE = /<script\\s+setup/\n\n// A simple regex to detect import sources. This is only used on\n// <script lang=\"ts\"> blocks in vue (setup only) or svelte files, since\n// seemingly unused imports are dropped by esbuild when transpiling TS which\n// prevents it from crawling further.\n// We can't use es-module-lexer because it can't handle TS, and don't want to\n// use Acorn because it's slow. Luckily this doesn't have to be bullet proof\n// since even missed imports can be caught at runtime, and false positives will\n// simply be ignored.\n// BROWSER VITE patch: no lookbehind for safari support\nexport const importsRE =\n  /(?:^|;|\\*\\/)\\s*import(?!\\s+type)(?:[\\w*{}\\n\\r\\t, ]+from\\s*)?\\s*(\"[^\"]+\"|'[^']+')\\s*(?=$|;|\\/\\*)/gm\n\nexport async function scanImports(config: ResolvedConfig): Promise<{\n  deps: Record<string, string>\n  missing: Record<string, string>\n}> {\n  const start = performance.now()\n\n  let entries: string[] = []\n\n  const explicitEntryPatterns = config.optimizeDeps.entries\n  const buildInput = config.build.rollupOptions?.input\n\n  if (explicitEntryPatterns) {\n    entries = await globEntries(explicitEntryPatterns, config)\n  } else if (buildInput) {\n    const resolvePath = (p: string) => path.resolve(config.root, p)\n    if (typeof buildInput === 'string') {\n      entries = [resolvePath(buildInput)]\n    } else if (Array.isArray(buildInput)) {\n      entries = buildInput.map(resolvePath)\n    } else if (isObject(buildInput)) {\n      entries = Object.values(buildInput).map(resolvePath)\n    } else {\n      throw new Error('invalid rollupOptions.input value.')\n    }\n  } else {\n    entries = await globEntries('**/*.html', config)\n  }\n\n  // Non-supported entry file types and virtual files should not be scanned for\n  // dependencies.\n  entries = entries.filter((entry) =>\n    // BROWSER VITE patch: we want to parse md/mdx files as well with an injected plugin\n    // (JS_TYPES_RE.test(entry) || htmlTypesRE.test(entry)) &&\n    fs.existsSync(entry)\n  )\n\n  if (!entries.length) {\n    if (!explicitEntryPatterns && !config.optimizeDeps.include) {\n      config.logger.warn(\n        chalk.yellow(\n          '(!) Could not auto-determine entry point from rollupOptions or html files ' +\n            'and there are no explicit optimizeDeps.include patterns. ' +\n            'Skipping dependency pre-bundling.'\n        )\n      )\n    }\n    return { deps: {}, missing: {} }\n  } else {\n    debug(`Crawling dependencies using entries:\\n  ${entries.join('\\n  ')}`)\n  }\n\n  const deps: Record<string, string> = {}\n  const missing: Record<string, string> = {}\n  const container = await createPluginContainer(config)\n  const plugin = esbuildScanPlugin(config, container, deps, missing, entries)\n\n  const { plugins = [], ...esbuildOptions } =\n    config.optimizeDeps?.esbuildOptions ?? {}\n\n  // BROWSER VITE patch: single build for all entries\n  await build({\n    absWorkingDir: process.cwd(),\n    outdir: path.join(process.cwd(), 'dist'), // unused, but needs to differ src/dist files\n    write: false,\n    entryPoints: entries,\n    bundle: true,\n    format: 'esm',\n    logLevel: 'error',\n    plugins: [...plugins, plugin],\n    ...esbuildOptions\n  })\n\n  debug(`Scan completed in ${(performance.now() - start).toFixed(2)}ms:`, deps)\n\n  return {\n    deps,\n    missing\n  }\n}\n\nfunction globEntries(pattern: string | string[], config: ResolvedConfig) {\n  return glob(pattern, {\n    cwd: config.root,\n    ignore: [\n      '**/node_modules/**',\n      `**/${config.build.outDir}/**`,\n      `**/__tests__/**`\n    ],\n    absolute: true\n  })\n}\n\nconst scriptModuleRE =\n  /(<script\\b[^>]*type\\s*=\\s*(?:\"module\"|'module')[^>]*>)(.*?)<\\/script>/gims\nexport const scriptRE = /(<script\\b(?:\\s[^>]*>|>))(.*?)<\\/script>/gims\nexport const commentRE = /<!--(.|[\\r\\n])*?-->/\nconst srcRE = /\\bsrc\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/im\nconst typeRE = /\\btype\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/im\nconst langRE = /\\blang\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/im\nconst contextRE = /\\bcontext\\s*=\\s*(?:\"([^\"]+)\"|'([^']+)'|([^\\s'\">]+))/im\n\nfunction esbuildScanPlugin(\n  config: ResolvedConfig,\n  container: PluginContainer,\n  depImports: Record<string, string>,\n  missing: Record<string, string>,\n  entries: string[]\n): Plugin {\n  const seen = new Map<string, string | undefined>()\n\n  const resolve = async (id: string, importer?: string) => {\n    const key = id + (importer && path.dirname(importer))\n    if (seen.has(key)) {\n      return seen.get(key)\n    }\n    const resolved = await container.resolveId(\n      id,\n      importer && normalizePath(importer)\n    )\n    const res = resolved?.id\n    seen.set(key, res)\n    return res\n  }\n\n  const include = config.optimizeDeps?.include\n  const exclude = [\n    ...(config.optimizeDeps?.exclude || []),\n    '@vite/client',\n    '@vite/env'\n  ]\n\n  const externalUnlessEntry = ({ path }: { path: string }) => ({\n    path,\n    external: !entries.includes(path)\n  })\n\n  return {\n    name: 'vite:dep-scan',\n    setup(build) {\n      const localScripts: Record<string, OnLoadResult> = {}\n\n      // external urls\n      build.onResolve({ filter: externalRE }, ({ path }) => ({\n        path,\n        external: true\n      }))\n\n      // data urls\n      build.onResolve({ filter: dataUrlRE }, ({ path }) => ({\n        path,\n        external: true\n      }))\n\n      // local scripts (`<script>` in Svelte and `<script setup>` in Vue)\n      build.onResolve({ filter: virtualModuleRE }, ({ path }) => {\n        return {\n          // strip prefix to get valid filesystem path so esbuild can resolve imports in the file\n          path: path.replace(virtualModulePrefix, ''),\n          namespace: 'local-script'\n        }\n      })\n\n      build.onLoad({ filter: /.*/, namespace: 'local-script' }, ({ path }) => {\n        return localScripts[path]\n      })\n\n      // html types: extract script contents -----------------------------------\n      build.onResolve({ filter: htmlTypesRE }, async ({ path, importer }) => {\n        return {\n          path: await resolve(path, importer),\n          namespace: 'html'\n        }\n      })\n\n      // extract scripts inside HTML-like files and treat it as a js module\n      build.onLoad(\n        { filter: htmlTypesRE, namespace: 'html' },\n        async ({ path }) => {\n          let raw = fs.readFileSync(path, 'utf-8')\n          // Avoid matching the content of the comment\n          raw = raw.replace(commentRE, '<!---->')\n          const isHtml = path.endsWith('.html')\n          const regex = isHtml ? scriptModuleRE : scriptRE\n          regex.lastIndex = 0\n          let js = ''\n          let loader: Loader = 'js'\n          let match: RegExpExecArray | null\n          while ((match = regex.exec(raw))) {\n            const [, openTag, content] = match\n            const typeMatch = openTag.match(typeRE)\n            const type =\n              typeMatch && (typeMatch[1] || typeMatch[2] || typeMatch[3])\n            const langMatch = openTag.match(langRE)\n            const lang =\n              langMatch && (langMatch[1] || langMatch[2] || langMatch[3])\n            // skip type=\"application/ld+json\" and other non-JS types\n            if (\n              type &&\n              !(\n                type.includes('javascript') ||\n                type.includes('ecmascript') ||\n                type === 'module'\n              )\n            ) {\n              continue\n            }\n            if (lang === 'ts' || lang === 'tsx' || lang === 'jsx') {\n              loader = lang\n            }\n            const srcMatch = openTag.match(srcRE)\n            if (srcMatch) {\n              const src = srcMatch[1] || srcMatch[2] || srcMatch[3]\n              js += `import ${JSON.stringify(src)}\\n`\n            } else if (content.trim()) {\n              // There can be module scripts (`<script context=\"module\">` in Svelte and `<script>` in Vue)\n              // or local scripts (`<script>` in Svelte and `<script setup>` in Vue)\n              // We need to handle these separately in case variable names are reused between them\n              const contextMatch = openTag.match(contextRE)\n              const context =\n                contextMatch &&\n                (contextMatch[1] || contextMatch[2] || contextMatch[3])\n              if (\n                (path.endsWith('.vue') && setupRE.test(openTag)) ||\n                (path.endsWith('.svelte') && context !== 'module')\n              ) {\n                // append imports in TS to prevent esbuild from removing them\n                // since they may be used in the template\n                const localContent =\n                  content +\n                  (loader.startsWith('ts') ? extractImportPaths(content) : '')\n                localScripts[path] = {\n                  loader,\n                  contents: localContent\n                }\n                js += `import '${virtualModulePrefix}${path}';\\n`\n              } else {\n                js += content + '\\n'\n              }\n            }\n          }\n\n          // `<script>` in Svelte has imports that can be used in the template\n          // so we handle them here too\n          if (loader.startsWith('ts') && path.endsWith('.svelte')) {\n            js += extractImportPaths(js)\n          }\n\n          // This will trigger incorrectly if `export default` is contained\n          // anywhere in a string. Svelte and Astro files can't have\n          // `export default` as code so we know if it's encountered it's a\n          // false positive (e.g. contained in a string)\n          if (!path.endsWith('.vue') || !js.includes('export default')) {\n            js += '\\nexport default {}'\n          }\n\n          if (js.includes('import.meta.glob')) {\n            return {\n              // transformGlob already transforms to js\n              loader: 'js',\n              contents: await transformGlob(js, path, config.root, loader)\n            }\n          }\n\n          return {\n            loader,\n            contents: js\n          }\n        }\n      )\n\n      // bare imports: record and externalize ----------------------------------\n      build.onResolve(\n        {\n          // avoid matching windows volume\n          filter: /^[\\w@][^:]/\n        },\n        async ({ path: id, importer }) => {\n          if (moduleListContains(exclude, id)) {\n            return externalUnlessEntry({ path: id })\n          }\n          if (depImports[id]) {\n            return externalUnlessEntry({ path: id })\n          }\n          const resolved = await resolve(id, importer)\n          if (resolved) {\n            if (shouldExternalizeDep(resolved, id)) {\n              return externalUnlessEntry({ path: id })\n            }\n            if (resolved.includes('node_modules') || include?.includes(id)) {\n              // dependency or forced included, externalize and stop crawling\n              if (OPTIMIZABLE_ENTRY_RE.test(resolved)) {\n                depImports[id] = resolved\n              }\n              return externalUnlessEntry({ path: id })\n            } else {\n              const namespace = htmlTypesRE.test(resolved) ? 'html' : undefined\n              // linked package, keep crawling\n              return {\n                path: path.resolve(resolved),\n                namespace\n              }\n            }\n          } else {\n            missing[id] = normalizePath(importer)\n          }\n        }\n      )\n\n      // Externalized file types -----------------------------------------------\n      // these are done on raw ids using esbuild's native regex filter so it\n      // should be faster than doing it in the catch-all via js\n      // they are done after the bare import resolve because a package name\n      // may end with these extensions\n\n      // css & json\n      build.onResolve(\n        {\n          filter: /\\.(css|less|sass|scss|styl|stylus|pcss|postcss|json)$/\n        },\n        externalUnlessEntry\n      )\n\n      // known asset types\n      build.onResolve(\n        {\n          filter: new RegExp(`\\\\.(${KNOWN_ASSET_TYPES.join('|')})$`)\n        },\n        externalUnlessEntry\n      )\n\n      // known vite query types: ?worker, ?raw\n      build.onResolve({ filter: SPECIAL_QUERY_RE }, ({ path }) => ({\n        path,\n        external: true\n      }))\n\n      // catch all -------------------------------------------------------------\n\n      build.onResolve(\n        {\n          filter: /.*/\n        },\n        async ({ path: id, importer }) => {\n          // use vite resolver to support urls and omitted extensions\n          const resolved = await resolve(id, importer)\n          if (resolved) {\n            if (shouldExternalizeDep(resolved, id)) {\n              return externalUnlessEntry({ path: id })\n            }\n\n            const namespace = htmlTypesRE.test(resolved) ? 'html' : undefined\n\n            return {\n              path: path.resolve(cleanUrl(resolved)),\n              namespace\n            }\n          } else {\n            // resolve failed... probably unsupported type\n            return externalUnlessEntry({ path: id })\n          }\n        }\n      )\n\n      // for jsx/tsx, we need to access the content and check for\n      // presence of import.meta.glob, since it results in import relationships\n      // but isn't crawled by esbuild.\n      build.onLoad({ filter: JS_TYPES_RE }, ({ path: id }) => {\n        let ext = path.extname(id).slice(1)\n        if (ext === 'mjs') ext = 'js'\n\n        let contents = fs.readFileSync(id, 'utf-8')\n        if (ext.endsWith('x') && config.esbuild && config.esbuild.jsxInject) {\n          contents = config.esbuild.jsxInject + `\\n` + contents\n        }\n\n        if (contents.includes('import.meta.glob')) {\n          return transformGlob(contents, id, config.root, ext as Loader).then(\n            (contents) => ({\n              loader: ext as Loader,\n              contents\n            })\n          )\n        }\n        return {\n          loader: ext as Loader,\n          contents\n        }\n      })\n    }\n  }\n}\n\nasync function transformGlob(\n  source: string,\n  importer: string,\n  root: string,\n  loader: Loader\n) {\n  // transform the content first since es-module-lexer can't handle non-js\n  if (loader !== 'js') {\n    source = (await transform(source, { loader })).code\n  }\n\n  await init\n  const imports = parse(source)[0]\n  const s = new MagicString(source)\n  for (let index = 0; index < imports.length; index++) {\n    const { s: start, e: end, ss: expStart } = imports[index]\n    const url = source.slice(start, end)\n    if (url !== 'import.meta') continue\n    if (source.slice(end, end + 5) !== '.glob') continue\n    const { importsString, exp, endIndex } = await transformImportGlob(\n      source,\n      start,\n      normalizePath(importer),\n      index,\n      root\n    )\n    s.prepend(importsString)\n    s.overwrite(expStart, endIndex, exp)\n  }\n  return s.toString()\n}\n\n/**\n * when using TS + (Vue + `<script setup>`) or Svelte, imports may seem\n * unused to esbuild and dropped in the build output, which prevents\n * esbuild from crawling further.\n * the solution is to add `import 'x'` for every source to force\n * esbuild to keep crawling due to potential side effects.\n */\nfunction extractImportPaths(code: string) {\n  // empty singleline & multiline comments to avoid matching comments\n  code = code\n    .replace(multilineCommentsRE, '/* */')\n    .replace(singlelineCommentsRE, '')\n\n  let js = ''\n  let m\n  while ((m = importsRE.exec(code)) != null) {\n    // This is necessary to avoid infinite loops with zero-width matches\n    if (m.index === importsRE.lastIndex) {\n      importsRE.lastIndex++\n    }\n    js += `\\nimport ${m[1]}`\n  }\n  return js\n}\n\nexport function shouldExternalizeDep(\n  resolvedId: string,\n  rawId: string\n): boolean {\n  // not a valid file path\n  if (!path.isAbsolute(resolvedId)) {\n    return true\n  }\n  // virtual id\n  if (resolvedId === rawId || resolvedId.includes('\\0')) {\n    return true\n  }\n  // resolved is not a scannable type\n  if (!JS_TYPES_RE.test(resolvedId) && !htmlTypesRE.test(resolvedId)) {\n    return true\n  }\n  return false\n}\n","import fs from 'fs'\nimport path from 'path'\nimport chalk from 'chalk'\nimport { resolveConfig, InlineConfig, ResolvedConfig } from './config'\nimport Rollup, {\n  Plugin,\n  RollupBuild,\n  RollupOptions,\n  RollupWarning,\n  WarningHandler,\n  OutputOptions,\n  RollupOutput,\n  ExternalOption,\n  GetManualChunk,\n  GetModuleInfo,\n  WatcherOptions,\n  RollupWatcher,\n  RollupError,\n  ModuleFormat\n} from 'rollup'\nimport { buildReporterPlugin } from './plugins/reporter'\nimport { buildHtmlPlugin } from './plugins/html'\nimport { buildEsbuildPlugin } from './plugins/esbuild'\nimport { terserPlugin } from './plugins/terser'\nimport { Terser } from 'types/terser'\nimport { copyDir, emptyDir, lookupFile, normalizePath } from './utils'\nimport { manifestPlugin } from './plugins/manifest'\nimport commonjsPlugin from '@rollup/plugin-commonjs'\nimport { RollupCommonJSOptions } from 'types/commonjs'\nimport dynamicImportVars from '@rollup/plugin-dynamic-import-vars'\nimport { RollupDynamicImportVarsOptions } from 'types/dynamicImportVars'\nimport { Logger } from './logger'\nimport { TransformOptions } from 'esbuild'\nimport { dataURIPlugin } from './plugins/dataUri'\nimport { buildImportAnalysisPlugin } from './plugins/importAnalysisBuild'\nimport { resolveSSRExternal, shouldExternalizeForSSR } from './ssr/ssrExternal'\nimport { ssrManifestPlugin } from './ssr/ssrManifestPlugin'\nimport { isCSSRequest } from './plugins/css'\nimport { DepOptimizationMetadata } from './optimizer'\nimport { scanImports } from './optimizer/scan'\nimport { assetImportMetaUrlPlugin } from './plugins/assetImportMetaUrl'\nimport { loadFallbackPlugin } from './plugins/loadFallback'\nimport { watchPackageDataPlugin } from './packages'\n\nexport interface BuildOptions {\n  /**\n   * Base public path when served in production.\n   * @deprecated `base` is now a root-level config option.\n   */\n  base?: string\n  /**\n   * Compatibility transform target. The transform is performed with esbuild\n   * and the lowest supported target is es2015/es6. Note this only handles\n   * syntax transformation and does not cover polyfills (except for dynamic\n   * import)\n   *\n   * Default: 'modules' - Similar to `@babel/preset-env`'s targets.esmodules,\n   * transpile targeting browsers that natively support dynamic es module imports.\n   * https://caniuse.com/es6-module-dynamic-import\n   *\n   * Another special value is 'esnext' - which only performs minimal transpiling\n   * (for minification compat) and assumes native dynamic imports support.\n   *\n   * For custom targets, see https://esbuild.github.io/api/#target and\n   * https://esbuild.github.io/content-types/#javascript for more details.\n   */\n  target?: 'modules' | TransformOptions['target'] | false\n  /**\n   * whether to inject module preload polyfill.\n   * Note: does not apply to library mode.\n   * @default true\n   */\n  polyfillModulePreload?: boolean\n  /**\n   * whether to inject dynamic import polyfill.\n   * Note: does not apply to library mode.\n   * @default false\n   * @deprecated use plugin-legacy for browsers that don't support dynamic import\n   */\n  polyfillDynamicImport?: boolean\n  /**\n   * Directory relative from `root` where build output will be placed. If the\n   * directory exists, it will be removed before the build.\n   * @default 'dist'\n   */\n  outDir?: string\n  /**\n   * Directory relative from `outDir` where the built js/css/image assets will\n   * be placed.\n   * @default 'assets'\n   */\n  assetsDir?: string\n  /**\n   * Static asset files smaller than this number (in bytes) will be inlined as\n   * base64 strings. Default limit is `4096` (4kb). Set to `0` to disable.\n   * @default 4096\n   */\n  assetsInlineLimit?: number\n  /**\n   * Whether to code-split CSS. When enabled, CSS in async chunks will be\n   * inlined as strings in the chunk and inserted via dynamically created\n   * style tags when the chunk is loaded.\n   * @default true\n   */\n  cssCodeSplit?: boolean\n  /**\n   * An optional separate target for CSS minification.\n   * As esbuild only supports configuring targets to mainstream\n   * browsers, users may need this option when they are targeting\n   * a niche browser that comes with most modern JavaScript features\n   * but has poor CSS support, e.g. Android WeChat WebView, which\n   * doesn't support the #RGBA syntax.\n   */\n  cssTarget?: TransformOptions['target'] | false\n  /**\n   * If `true`, a separate sourcemap file will be created. If 'inline', the\n   * sourcemap will be appended to the resulting output file as data URI.\n   * 'hidden' works like `true` except that the corresponding sourcemap\n   * comments in the bundled files are suppressed.\n   * @default false\n   */\n  sourcemap?: boolean | 'inline' | 'hidden'\n  /**\n   * Set to `false` to disable minification, or specify the minifier to use.\n   * Available options are 'terser' or 'esbuild'.\n   * @default 'esbuild'\n   */\n  minify?: boolean | 'terser' | 'esbuild'\n  /**\n   * Options for terser\n   * https://terser.org/docs/api-reference#minify-options\n   */\n  terserOptions?: Terser.MinifyOptions\n  /**\n   * @deprecated Vite now uses esbuild for CSS minification.\n   */\n  cleanCssOptions?: any\n  /**\n   * Will be merged with internal rollup options.\n   * https://rollupjs.org/guide/en/#big-list-of-options\n   */\n  rollupOptions?: RollupOptions\n  /**\n   * Options to pass on to `@rollup/plugin-commonjs`\n   */\n  commonjsOptions?: RollupCommonJSOptions\n  /**\n   * Options to pass on to `@rollup/plugin-dynamic-import-vars`\n   */\n  dynamicImportVarsOptions?: RollupDynamicImportVarsOptions\n  /**\n   * Whether to write bundle to disk\n   * @default true\n   */\n  write?: boolean\n  /**\n   * Empty outDir on write.\n   * @default true when outDir is a sub directory of project root\n   */\n  emptyOutDir?: boolean | null\n  /**\n   * Whether to emit a manifest.json under assets dir to map hash-less filenames\n   * to their hashed versions. Useful when you want to generate your own HTML\n   * instead of using the one generated by Vite.\n   *\n   * Example:\n   *\n   * ```json\n   * {\n   *   \"main.js\": {\n   *     \"file\": \"main.68fe3fad.js\",\n   *     \"css\": \"main.e6b63442.css\",\n   *     \"imports\": [...],\n   *     \"dynamicImports\": [...]\n   *   }\n   * }\n   * ```\n   * @default false\n   */\n  manifest?: boolean\n  /**\n   * Build in library mode. The value should be the global name of the lib in\n   * UMD mode. This will produce esm + cjs + umd bundle formats with default\n   * configurations that are suitable for distributing libraries.\n   */\n  lib?: LibraryOptions | false\n  /**\n   * Produce SSR oriented build. Note this requires specifying SSR entry via\n   * `rollupOptions.input`.\n   */\n  ssr?: boolean | string\n  /**\n   * Generate SSR manifest for determining style links and asset preload\n   * directives in production.\n   */\n  ssrManifest?: boolean\n  /**\n   * Set to false to disable reporting compressed chunk sizes.\n   * Can slightly improve build speed.\n   */\n  reportCompressedSize?: boolean\n  /**\n   * Set to false to disable brotli compressed size reporting for build.\n   * Can slightly improve build speed.\n   * @deprecated use `build.reportCompressedSize` instead.\n   */\n  brotliSize?: boolean\n  /**\n   * Adjust chunk size warning limit (in kbs).\n   * @default 500\n   */\n  chunkSizeWarningLimit?: number\n  /**\n   * Rollup watch options\n   * https://rollupjs.org/guide/en/#watchoptions\n   */\n  watch?: WatcherOptions | null\n}\n\nexport interface LibraryOptions {\n  entry: string\n  name?: string\n  formats?: LibraryFormats[]\n  fileName?: string | ((format: ModuleFormat) => string)\n}\n\nexport type LibraryFormats = 'es' | 'cjs' | 'umd' | 'iife'\n\nexport type ResolvedBuildOptions = Required<\n  Omit<\n    BuildOptions,\n    // make deprecated options optional\n    'base' | 'cleanCssOptions' | 'polyfillDynamicImport' | 'brotliSize'\n  >\n>\n\nexport function resolveBuildOptions(\n  root: string,\n  raw?: BuildOptions\n): ResolvedBuildOptions {\n  const resolved: ResolvedBuildOptions = {\n    target: 'modules',\n    polyfillModulePreload: true,\n    outDir: 'dist',\n    assetsDir: 'assets',\n    assetsInlineLimit: 4096,\n    cssCodeSplit: !raw?.lib,\n    cssTarget: false,\n    sourcemap: false,\n    rollupOptions: {},\n    minify: raw?.ssr ? false : 'esbuild',\n    terserOptions: {},\n    write: true,\n    emptyOutDir: null,\n    manifest: false,\n    lib: false,\n    ssr: false,\n    ssrManifest: false,\n    reportCompressedSize: true,\n    // brotliSize: true,\n    chunkSizeWarningLimit: 500,\n    watch: null,\n    ...raw,\n    commonjsOptions: {\n      include: [/node_modules/],\n      extensions: ['.js', '.cjs'],\n      ...raw?.commonjsOptions\n    },\n    dynamicImportVarsOptions: {\n      warnOnError: true,\n      exclude: [/node_modules/],\n      ...raw?.dynamicImportVarsOptions\n    }\n  }\n\n  const resolve = (p: string) =>\n    p.startsWith('\\0') ? p : path.resolve(root, p)\n\n  resolved.outDir = resolve(resolved.outDir)\n\n  let input\n\n  if (raw?.rollupOptions?.input) {\n    input = Array.isArray(raw.rollupOptions.input)\n      ? raw.rollupOptions.input.map((input) => resolve(input))\n      : typeof raw.rollupOptions.input === 'object'\n      ? Object.fromEntries(\n          Object.entries(raw.rollupOptions.input).map(([key, value]) => [\n            key,\n            resolve(value)\n          ])\n        )\n      : resolve(raw.rollupOptions.input)\n  } else {\n    input = resolve(\n      raw?.lib\n        ? raw.lib.entry\n        : typeof raw?.ssr === 'string'\n        ? raw.ssr\n        : 'index.html'\n    )\n  }\n\n  if (!!raw?.ssr && typeof input === 'string' && input.endsWith('.html')) {\n    throw new Error(\n      `rollupOptions.input should not be an html file when building for SSR. ` +\n        `Please specify a dedicated SSR entry.`\n    )\n  }\n\n  resolved.rollupOptions.input = input\n\n  // handle special build targets\n  if (resolved.target === 'modules') {\n    // Support browserslist\n    // \"defaults and supports es6-module and supports es6-module-dynamic-import\",\n    resolved.target = [\n      'es2019',\n      'edge88',\n      'firefox78',\n      'chrome87',\n      'safari13.1'\n    ]\n  } else if (resolved.target === 'esnext' && resolved.minify === 'terser') {\n    // esnext + terser: limit to es2019 so it can be minified by terser\n    resolved.target = 'es2019'\n  }\n\n  if (!resolved.cssTarget) {\n    resolved.cssTarget = resolved.target\n  }\n\n  // normalize false string into actual false\n  if ((resolved.minify as any) === 'false') {\n    resolved.minify = false\n  }\n\n  if (resolved.minify === true) {\n    resolved.minify = 'esbuild'\n  }\n\n  return resolved\n}\n\nexport function resolveBuildPlugins(config: ResolvedConfig): {\n  pre: Plugin[]\n  post: Plugin[]\n} {\n  const options = config.build\n  return {\n    pre: [\n      watchPackageDataPlugin(config),\n      buildHtmlPlugin(config),\n      commonjsPlugin(options.commonjsOptions),\n      dataURIPlugin(),\n      dynamicImportVars(options.dynamicImportVarsOptions),\n      assetImportMetaUrlPlugin(config),\n      ...(options.rollupOptions.plugins\n        ? (options.rollupOptions.plugins.filter((p) => !!p) as Plugin[])\n        : [])\n    ],\n    post: [\n      buildImportAnalysisPlugin(config),\n      buildEsbuildPlugin(config),\n      ...(options.minify === 'terser' ? [terserPlugin(config)] : []),\n      ...(options.manifest ? [manifestPlugin(config)] : []),\n      ...(options.ssrManifest ? [ssrManifestPlugin(config)] : []),\n      buildReporterPlugin(config),\n      loadFallbackPlugin()\n    ]\n  }\n}\n\n/**\n * Track parallel build calls and only stop the esbuild service when all\n * builds are done. (#1098)\n */\nlet parallelCallCounts = 0\n// we use a separate counter to track since the call may error before the\n// bundle is even pushed.\nconst parallelBuilds: RollupBuild[] = []\n\n/**\n * Bundles the app for production.\n * Returns a Promise containing the build result.\n */\nexport async function build(\n  inlineConfig: InlineConfig = {}\n): Promise<RollupOutput | RollupOutput[] | RollupWatcher> {\n  parallelCallCounts++\n  try {\n    return await doBuild(inlineConfig)\n  } finally {\n    parallelCallCounts--\n    if (parallelCallCounts <= 0) {\n      await Promise.all(parallelBuilds.map((bundle) => bundle.close()))\n      parallelBuilds.length = 0\n    }\n  }\n}\n\nasync function doBuild(\n  inlineConfig: InlineConfig = {}\n): Promise<RollupOutput | RollupOutput[] | RollupWatcher> {\n  const config = await resolveConfig(inlineConfig, 'build', 'production')\n  const options = config.build\n  const input = options.rollupOptions.input\n  const outDir = options.outDir\n  const ssr = !!options.ssr\n  const libOptions = options.lib\n\n  config.logger.info(\n    chalk.cyan(\n      `vite v${require('vite/package.json').version} ${chalk.green(\n        `building ${ssr ? `SSR bundle ` : ``}for ${config.mode}...`\n      )}`\n    )\n  )\n\n  // inject ssr arg to plugin load/transform hooks\n  const plugins = (\n    ssr ? config.plugins.map((p) => injectSsrFlagToHooks(p)) : config.plugins\n  ) as Plugin[]\n\n  // inject ssrExternal if present\n  const userExternal = options.rollupOptions?.external\n  let external = userExternal\n  if (ssr) {\n    // see if we have cached deps data available\n    let knownImports: string[] | undefined\n    if (config.cacheDir) {\n      const dataPath = path.join(config.cacheDir, '_metadata.json')\n      try {\n        const data = JSON.parse(\n          fs.readFileSync(dataPath, 'utf-8')\n        ) as DepOptimizationMetadata\n        knownImports = Object.keys(data.optimized)\n      } catch (e) {}\n    }\n    if (!knownImports) {\n      // no dev deps optimization data, do a fresh scan\n      knownImports = Object.keys((await scanImports(config)).deps)\n    }\n    external = resolveExternal(\n      resolveSSRExternal(config, knownImports),\n      userExternal\n    )\n  }\n\n  const rollup = require('rollup') as typeof Rollup\n  const rollupOptions: RollupOptions = {\n    context: 'globalThis',\n    preserveEntrySignatures: ssr\n      ? 'allow-extension'\n      : libOptions\n      ? 'strict'\n      : false,\n    ...options.rollupOptions,\n    plugins,\n    external,\n    onwarn(warning, warn) {\n      onRollupWarning(warning, warn, config)\n    }\n  }\n\n  const outputBuildError = (e: RollupError) => {\n    let msg = chalk.red((e.plugin ? `[${e.plugin}] ` : '') + e.message)\n    if (e.id) {\n      msg += `\\nfile: ${chalk.cyan(\n        e.id + (e.loc ? `:${e.loc.line}:${e.loc.column}` : '')\n      )}`\n    }\n    if (e.frame) {\n      msg += `\\n` + chalk.yellow(e.frame)\n    }\n    config.logger.error(msg, { error: e })\n  }\n\n  try {\n    const buildOutputOptions = (output: OutputOptions = {}): OutputOptions => {\n      // @ts-ignore\n      if (output.output) {\n        config.logger.warn(\n          `You've set \"rollupOptions.output.output\" in your config. ` +\n            `This is deprecated and will override all Vite.js default output options. ` +\n            `Please use \"rollupOptions.output\" instead.`\n        )\n      }\n\n      return {\n        dir: outDir,\n        format: ssr ? 'cjs' : 'es',\n        exports: ssr ? 'named' : 'auto',\n        sourcemap: options.sourcemap,\n        name: libOptions ? libOptions.name : undefined,\n        entryFileNames: ssr\n          ? `[name].js`\n          : libOptions\n          ? resolveLibFilename(libOptions, output.format || 'es', config.root)\n          : path.posix.join(options.assetsDir, `[name].[hash].js`),\n        chunkFileNames: libOptions\n          ? `[name].js`\n          : path.posix.join(options.assetsDir, `[name].[hash].js`),\n        assetFileNames: libOptions\n          ? `[name].[ext]`\n          : path.posix.join(options.assetsDir, `[name].[hash].[ext]`),\n        // #764 add `Symbol.toStringTag` when build es module into cjs chunk\n        // #1048 add `Symbol.toStringTag` for module default export\n        namespaceToStringTag: true,\n        inlineDynamicImports: ssr && typeof input === 'string',\n        manualChunks:\n          !ssr &&\n          !libOptions &&\n          output?.format !== 'umd' &&\n          output?.format !== 'iife'\n            ? createMoveToVendorChunkFn(config)\n            : undefined,\n        ...output\n      }\n    }\n\n    // resolve lib mode outputs\n    const outputs = resolveBuildOutputs(\n      options.rollupOptions?.output,\n      libOptions,\n      config.logger\n    )\n\n    // watch file changes with rollup\n    if (config.build.watch) {\n      config.logger.info(chalk.cyanBright(`\\nwatching for file changes...`))\n\n      const output: OutputOptions[] = []\n      if (Array.isArray(outputs)) {\n        for (const resolvedOutput of outputs) {\n          output.push(buildOutputOptions(resolvedOutput))\n        }\n      } else {\n        output.push(buildOutputOptions(outputs))\n      }\n\n      const watcherOptions = config.build.watch\n      const watcher = rollup.watch({\n        ...rollupOptions,\n        output,\n        watch: {\n          ...watcherOptions,\n          chokidar: {\n            ignored: [\n              '**/node_modules/**',\n              '**/.git/**',\n              ...(watcherOptions?.chokidar?.ignored || [])\n            ],\n            ignoreInitial: true,\n            ignorePermissionErrors: true,\n            ...watcherOptions.chokidar\n          }\n        }\n      })\n\n      watcher.on('event', (event) => {\n        if (event.code === 'BUNDLE_START') {\n          config.logger.info(chalk.cyanBright(`\\nbuild started...`))\n          if (options.write) {\n            prepareOutDir(outDir, options.emptyOutDir, config)\n          }\n        } else if (event.code === 'BUNDLE_END') {\n          event.result.close()\n          config.logger.info(chalk.cyanBright(`built in ${event.duration}ms.`))\n        } else if (event.code === 'ERROR') {\n          outputBuildError(event.error)\n        }\n      })\n\n      // stop watching\n      watcher.close()\n\n      return watcher\n    }\n\n    // write or generate files with rollup\n    const bundle = await rollup.rollup(rollupOptions)\n    parallelBuilds.push(bundle)\n\n    const generate = (output: OutputOptions = {}) => {\n      return bundle[options.write ? 'write' : 'generate'](\n        buildOutputOptions(output)\n      )\n    }\n\n    if (options.write) {\n      prepareOutDir(outDir, options.emptyOutDir, config)\n    }\n\n    if (Array.isArray(outputs)) {\n      const res = []\n      for (const output of outputs) {\n        res.push(await generate(output))\n      }\n      return res\n    } else {\n      return await generate(outputs)\n    }\n  } catch (e) {\n    outputBuildError(e)\n    throw e\n  }\n}\n\nfunction prepareOutDir(\n  outDir: string,\n  emptyOutDir: boolean | null,\n  config: ResolvedConfig\n) {\n  if (fs.existsSync(outDir)) {\n    if (\n      emptyOutDir == null &&\n      !normalizePath(outDir).startsWith(config.root + '/')\n    ) {\n      // warn if outDir is outside of root\n      config.logger.warn(\n        chalk.yellow(\n          `\\n${chalk.bold(`(!)`)} outDir ${chalk.white.dim(\n            outDir\n          )} is not inside project root and will not be emptied.\\n` +\n            `Use --emptyOutDir to override.\\n`\n        )\n      )\n    } else if (emptyOutDir !== false) {\n      emptyDir(outDir, ['.git'])\n    }\n  }\n  if (config.publicDir && fs.existsSync(config.publicDir)) {\n    copyDir(config.publicDir, outDir)\n  }\n}\n\nfunction getPkgName(root: string) {\n  const { name } = JSON.parse(lookupFile(root, ['package.json']) || `{}`)\n\n  return name?.startsWith('@') ? name.split('/')[1] : name\n}\n\nfunction createMoveToVendorChunkFn(config: ResolvedConfig): GetManualChunk {\n  const cache = new Map<string, boolean>()\n  return (id, { getModuleInfo }) => {\n    if (\n      id.includes('node_modules') &&\n      !isCSSRequest(id) &&\n      staticImportedByEntry(id, getModuleInfo, cache)\n    ) {\n      return 'vendor'\n    }\n  }\n}\n\nfunction staticImportedByEntry(\n  id: string,\n  getModuleInfo: GetModuleInfo,\n  cache: Map<string, boolean>,\n  importStack: string[] = []\n): boolean {\n  if (cache.has(id)) {\n    return cache.get(id) as boolean\n  }\n  if (importStack.includes(id)) {\n    // circular deps!\n    cache.set(id, false)\n    return false\n  }\n  const mod = getModuleInfo(id)\n  if (!mod) {\n    cache.set(id, false)\n    return false\n  }\n\n  if (mod.isEntry) {\n    cache.set(id, true)\n    return true\n  }\n  const someImporterIs = mod.importers.some((importer) =>\n    staticImportedByEntry(\n      importer,\n      getModuleInfo,\n      cache,\n      importStack.concat(id)\n    )\n  )\n  cache.set(id, someImporterIs)\n  return someImporterIs\n}\n\nexport function resolveLibFilename(\n  libOptions: LibraryOptions,\n  format: ModuleFormat,\n  root: string\n): string {\n  if (typeof libOptions.fileName === 'function') {\n    return libOptions.fileName(format)\n  }\n\n  const name = libOptions.fileName || getPkgName(root)\n\n  if (!name)\n    throw new Error(\n      'Name in package.json is required if option \"build.lib.fileName\" is not provided.'\n    )\n\n  return `${name}.${format}.js`\n}\n\nfunction resolveBuildOutputs(\n  outputs: OutputOptions | OutputOptions[] | undefined,\n  libOptions: LibraryOptions | false,\n  logger: Logger\n): OutputOptions | OutputOptions[] | undefined {\n  if (libOptions) {\n    const formats = libOptions.formats || ['es', 'umd']\n    if (\n      (formats.includes('umd') || formats.includes('iife')) &&\n      !libOptions.name\n    ) {\n      throw new Error(\n        `Option \"build.lib.name\" is required when output formats ` +\n          `include \"umd\" or \"iife\".`\n      )\n    }\n    if (!outputs) {\n      return formats.map((format) => ({ format }))\n    } else if (!Array.isArray(outputs)) {\n      return formats.map((format) => ({ ...outputs, format }))\n    } else if (libOptions.formats) {\n      // user explicitly specifying own output array\n      logger.warn(\n        chalk.yellow(\n          `\"build.lib.formats\" will be ignored because ` +\n            `\"build.rollupOptions.output\" is already an array format`\n        )\n      )\n    }\n  }\n  return outputs\n}\n\nconst warningIgnoreList = [`CIRCULAR_DEPENDENCY`, `THIS_IS_UNDEFINED`]\nconst dynamicImportWarningIgnoreList = [\n  `Unsupported expression`,\n  `statically analyzed`\n]\n\nexport function onRollupWarning(\n  warning: RollupWarning,\n  warn: WarningHandler,\n  config: ResolvedConfig\n): void {\n  if (warning.code === 'UNRESOLVED_IMPORT') {\n    const id = warning.source\n    const importer = warning.importer\n    // throw unless it's commonjs external...\n    if (!importer || !/\\?commonjs-external$/.test(importer)) {\n      throw new Error(\n        `[vite]: Rollup failed to resolve import \"${id}\" from \"${importer}\".\\n` +\n          `This is most likely unintended because it can break your application at runtime.\\n` +\n          `If you do want to externalize this module explicitly add it to\\n` +\n          `\\`build.rollupOptions.external\\``\n      )\n    }\n  }\n\n  if (\n    warning.plugin === 'rollup-plugin-dynamic-import-variables' &&\n    dynamicImportWarningIgnoreList.some((msg) => warning.message.includes(msg))\n  ) {\n    return\n  }\n\n  if (!warningIgnoreList.includes(warning.code!)) {\n    const userOnWarn = config.build.rollupOptions?.onwarn\n    if (userOnWarn) {\n      userOnWarn(warning, warn)\n    } else if (warning.code === 'PLUGIN_WARNING') {\n      config.logger.warn(\n        `${chalk.bold.yellow(`[plugin:${warning.plugin}]`)} ${chalk.yellow(\n          warning.message\n        )}`\n      )\n    } else {\n      warn(warning)\n    }\n  }\n}\n\nfunction resolveExternal(\n  ssrExternals: string[],\n  user: ExternalOption | undefined\n): ExternalOption {\n  return ((id, parentId, isResolved) => {\n    if (shouldExternalizeForSSR(id, ssrExternals)) {\n      return true\n    }\n    if (user) {\n      if (typeof user === 'function') {\n        return user(id, parentId, isResolved)\n      } else if (Array.isArray(user)) {\n        return user.some((test) => isExternal(id, test))\n      } else {\n        return isExternal(id, user)\n      }\n    }\n  }) as ExternalOption\n}\n\nfunction isExternal(id: string, test: string | RegExp) {\n  if (typeof test === 'string') {\n    return id === test\n  } else {\n    return test.test(id)\n  }\n}\n\nfunction injectSsrFlagToHooks(p: Plugin): Plugin {\n  const { resolveId, load, transform } = p\n  return {\n    ...p,\n    resolveId: wrapSsrResolveId(resolveId),\n    load: wrapSsrLoad(load),\n    transform: wrapSsrTransform(transform)\n  }\n}\n\nfunction wrapSsrResolveId(fn: Function | undefined) {\n  if (!fn) return\n  return function (this: any, id: any, importer: any, options: any) {\n    return fn.call(this, id, importer, injectSsrFlag(options))\n  }\n}\n\nfunction wrapSsrLoad(fn: Function | undefined) {\n  if (!fn) return\n  // Receiving options param to be future-proof if Rollup adds it\n  return function (this: any, id: any, ...args: any[]) {\n    return fn.call(this, id, injectSsrFlag(args[0]))\n  }\n}\n\nfunction wrapSsrTransform(fn: Function | undefined) {\n  if (!fn) return\n  // Receiving options param to be future-proof if Rollup adds it\n  return function (this: any, code: any, importer: any, ...args: any[]) {\n    return fn.call(this, code, importer, injectSsrFlag(args[0]))\n  }\n}\n\nfunction injectSsrFlag(options: any = {}) {\n  return { ...options, ssr: true }\n}\n","import MagicString from 'magic-string'\nimport { SourceMap } from 'rollup'\nimport { TransformResult } from '../server/transformRequest'\nimport { parser } from '../server/pluginContainer'\nimport {\n  Identifier,\n  Node as _Node,\n  Property,\n  Function as FunctionNode\n} from 'estree'\nimport { extract_names as extractNames } from 'periscopic'\nimport { walk as eswalk } from 'estree-walker'\nimport { combineSourcemaps } from '../utils'\nimport { RawSourceMap } from '@ampproject/remapping/dist/types/types'\n\ntype Node = _Node & {\n  start: number\n  end: number\n}\n\nexport const ssrModuleExportsKey = `__vite_ssr_exports__`\nexport const ssrImportKey = `__vite_ssr_import__`\nexport const ssrDynamicImportKey = `__vite_ssr_dynamic_import__`\nexport const ssrExportAllKey = `__vite_ssr_exportAll__`\nexport const ssrImportMetaKey = `__vite_ssr_import_meta__`\n\nexport async function ssrTransform(\n  code: string,\n  inMap: SourceMap | null,\n  url: string\n): Promise<TransformResult | null> {\n  const s = new MagicString(code)\n\n  let ast: any\n  try {\n    ast = parser.parse(code, {\n      sourceType: 'module',\n      ecmaVersion: 'latest',\n      locations: true\n    })\n  } catch (err) {\n    if (!err.loc || !err.loc.line) throw err\n    const line = err.loc.line\n    throw new Error(\n      `Parse failure: ${err.message}\\nContents of line ${line}: ${\n        code.split('\\n')[line - 1]\n      }`\n    )\n  }\n\n  let uid = 0\n  const deps = new Set<string>()\n  const dynamicDeps = new Set<string>()\n  const idToImportMap = new Map<string, string>()\n  const declaredConst = new Set<string>()\n\n  function defineImport(node: Node, source: string) {\n    deps.add(source)\n    const importId = `__vite_ssr_import_${uid++}__`\n    s.appendLeft(\n      node.start,\n      `const ${importId} = await ${ssrImportKey}(${JSON.stringify(source)});\\n`\n    )\n    return importId\n  }\n\n  function defineExport(position: number, name: string, local = name) {\n    s.appendRight(\n      position,\n      `\\nObject.defineProperty(${ssrModuleExportsKey}, \"${name}\", ` +\n        `{ enumerable: true, configurable: true, get(){ return ${local} }});`\n    )\n  }\n\n  // 1. check all import statements and record id -> importName map\n  for (const node of ast.body as Node[]) {\n    // import foo from 'foo' --> foo -> __import_foo__.default\n    // import { baz } from 'foo' --> baz -> __import_foo__.baz\n    // import * as ok from 'foo' --> ok -> __import_foo__\n    if (node.type === 'ImportDeclaration') {\n      const importId = defineImport(node, node.source.value as string)\n      for (const spec of node.specifiers) {\n        if (spec.type === 'ImportSpecifier') {\n          idToImportMap.set(\n            spec.local.name,\n            `${importId}.${spec.imported.name}`\n          )\n        } else if (spec.type === 'ImportDefaultSpecifier') {\n          idToImportMap.set(spec.local.name, `${importId}.default`)\n        } else {\n          // namespace specifier\n          idToImportMap.set(spec.local.name, importId)\n        }\n      }\n      s.remove(node.start, node.end)\n    }\n  }\n\n  // 2. check all export statements and define exports\n  for (const node of ast.body as Node[]) {\n    // named exports\n    if (node.type === 'ExportNamedDeclaration') {\n      if (node.declaration) {\n        if (\n          node.declaration.type === 'FunctionDeclaration' ||\n          node.declaration.type === 'ClassDeclaration'\n        ) {\n          // export function foo() {}\n          defineExport(node.end, node.declaration.id!.name)\n        } else {\n          // export const foo = 1, bar = 2\n          for (const declaration of node.declaration.declarations) {\n            const names = extractNames(declaration.id as any)\n            for (const name of names) {\n              defineExport(node.end, name)\n            }\n          }\n        }\n        s.remove(node.start, (node.declaration as Node).start)\n      } else {\n        s.remove(node.start, node.end)\n        if (node.source) {\n          // export { foo, bar } from './foo'\n          const importId = defineImport(node, node.source.value as string)\n          for (const spec of node.specifiers) {\n            defineExport(\n              node.end,\n              spec.exported.name,\n              `${importId}.${spec.local.name}`\n            )\n          }\n        } else {\n          // export { foo, bar }\n          for (const spec of node.specifiers) {\n            const local = spec.local.name\n            const binding = idToImportMap.get(local)\n            defineExport(node.end, spec.exported.name, binding || local)\n          }\n        }\n      }\n    }\n\n    // default export\n    if (node.type === 'ExportDefaultDeclaration') {\n      if ('id' in node.declaration && node.declaration.id) {\n        // named hoistable/class exports\n        // export default function foo() {}\n        // export default class A {}\n        const { name } = node.declaration.id\n        s.remove(node.start, node.start + 15 /* 'export default '.length */)\n        s.append(\n          `\\nObject.defineProperty(${ssrModuleExportsKey}, \"default\", ` +\n            `{ enumerable: true, value: ${name} });`\n        )\n      } else {\n        // anonymous default exports\n        s.overwrite(\n          node.start,\n          node.start + 14 /* 'export default'.length */,\n          `${ssrModuleExportsKey}.default =`\n        )\n      }\n    }\n\n    // export * from './foo'\n    if (node.type === 'ExportAllDeclaration') {\n      if (node.exported) {\n        const importId = defineImport(node, node.source.value as string)\n        s.remove(node.start, node.end)\n        defineExport(node.end, node.exported.name, `${importId}`)\n      } else {\n        const importId = defineImport(node, node.source.value as string)\n        s.remove(node.start, node.end)\n        s.appendLeft(node.end, `${ssrExportAllKey}(${importId});`)\n      }\n    }\n  }\n\n  // 3. convert references to import bindings & import.meta references\n  walk(ast, {\n    onIdentifier(id, parent, parentStack) {\n      const binding = idToImportMap.get(id.name)\n      if (!binding) {\n        return\n      }\n      if (isStaticProperty(parent) && parent.shorthand) {\n        // let binding used in a property shorthand\n        // { foo } -> { foo: __import_x__.foo }\n        // skip for destructuring patterns\n        if (\n          !(parent as any).inPattern ||\n          isInDestructuringAssignment(parent, parentStack)\n        ) {\n          s.appendLeft(id.end, `: ${binding}`)\n        }\n      } else if (\n        parent.type === 'ClassDeclaration' &&\n        id === parent.superClass\n      ) {\n        if (!declaredConst.has(id.name)) {\n          declaredConst.add(id.name)\n          // locate the top-most node containing the class declaration\n          const topNode = parentStack[1]\n          s.prependRight(topNode.start, `const ${id.name} = ${binding};\\n`)\n        }\n      } else {\n        s.overwrite(id.start, id.end, binding)\n      }\n    },\n    onImportMeta(node) {\n      s.overwrite(node.start, node.end, ssrImportMetaKey)\n    },\n    onDynamicImport(node) {\n      s.overwrite(node.start, node.start + 6, ssrDynamicImportKey)\n      if (node.type === 'ImportExpression' && node.source.type === 'Literal') {\n        dynamicDeps.add(node.source.value as string)\n      }\n    }\n  })\n\n  let map = s.generateMap({ hires: true })\n  if (inMap && inMap.mappings && inMap.sources.length > 0) {\n    map = combineSourcemaps(url, [\n      {\n        ...map,\n        sources: inMap.sources,\n        sourcesContent: inMap.sourcesContent\n      } as RawSourceMap,\n      inMap as RawSourceMap\n    ]) as SourceMap\n  } else {\n    map.sources = [url]\n    map.sourcesContent = [code]\n  }\n\n  return {\n    code: s.toString(),\n    map,\n    deps: [...deps],\n    dynamicDeps: [...dynamicDeps]\n  }\n}\n\ninterface Visitors {\n  onIdentifier: (\n    node: Identifier & {\n      start: number\n      end: number\n    },\n    parent: Node,\n    parentStack: Node[]\n  ) => void\n  onImportMeta: (node: Node) => void\n  onDynamicImport: (node: Node) => void\n}\n\n/**\n * Same logic from \\@vue/compiler-core & \\@vue/compiler-sfc\n * Except this is using acorn AST\n */\nfunction walk(\n  root: Node,\n  { onIdentifier, onImportMeta, onDynamicImport }: Visitors\n) {\n  const parentStack: Node[] = []\n  const scope: Record<string, number> = Object.create(null)\n  const scopeMap = new WeakMap<_Node, Set<string>>()\n\n  const setScope = (node: FunctionNode, name: string) => {\n    let scopeIds = scopeMap.get(node)\n    if (scopeIds && scopeIds.has(name)) {\n      return\n    }\n    if (name in scope) {\n      scope[name]++\n    } else {\n      scope[name] = 1\n    }\n    if (!scopeIds) {\n      scopeIds = new Set()\n      scopeMap.set(node, scopeIds)\n    }\n    scopeIds.add(name)\n  }\n\n  ;(eswalk as any)(root, {\n    enter(node: Node, parent: Node | null) {\n      if (node.type === 'ImportDeclaration') {\n        return this.skip()\n      }\n\n      parent && parentStack.push(parent)\n\n      if (node.type === 'MetaProperty' && node.meta.name === 'import') {\n        onImportMeta(node)\n      } else if (node.type === 'ImportExpression') {\n        onDynamicImport(node)\n      }\n\n      if (node.type === 'Identifier') {\n        if (!scope[node.name] && isRefIdentifier(node, parent!, parentStack)) {\n          onIdentifier(node, parent!, parentStack)\n        }\n      } else if (isFunction(node)) {\n        // If it is a function declaration, it could be shadowing an import\n        // Add its name to the scope so it won't get replaced\n        if (node.type === 'FunctionDeclaration') {\n          const parentFunction = findParentFunction(parentStack)\n          if (parentFunction) {\n            setScope(parentFunction, node.id!.name)\n          }\n        }\n        // walk function expressions and add its arguments to known identifiers\n        // so that we don't prefix them\n        node.params.forEach((p) =>\n          (eswalk as any)(p.type === 'AssignmentPattern' ? p.left : p, {\n            enter(child: Node, parent: Node) {\n              if (child.type !== 'Identifier') return\n              // do not record as scope variable if is a destructuring keyword\n              if (isStaticPropertyKey(child, parent)) return\n              // do not record if this is a default value\n              // assignment of a destructuring variable\n              if (\n                (parent?.type === 'AssignmentPattern' &&\n                  parent?.right === child) ||\n                (parent?.type === 'TemplateLiteral' &&\n                  parent?.expressions.includes(child))\n              ) {\n                return\n              }\n              setScope(node, child.name)\n            }\n          })\n        )\n      } else if (node.type === 'Property' && parent!.type === 'ObjectPattern') {\n        // mark property in destructuring pattern\n        ;(node as any).inPattern = true\n      } else if (node.type === 'VariableDeclarator') {\n        const parentFunction = findParentFunction(parentStack)\n        if (parentFunction) {\n          if (node.id.type === 'ObjectPattern') {\n            node.id.properties.forEach((property) => {\n              if (property.type === 'RestElement') {\n                setScope(parentFunction, (property.argument as Identifier).name)\n              } else {\n                setScope(parentFunction, (property.value as Identifier).name)\n              }\n            })\n          } else if (node.id.type === 'ArrayPattern') {\n            node.id.elements.forEach((element) => {\n              setScope(parentFunction, (element as Identifier).name)\n            })\n          } else {\n            setScope(parentFunction, (node.id as Identifier).name)\n          }\n        }\n      }\n    },\n\n    leave(node: Node, parent: Node | null) {\n      parent && parentStack.pop()\n      const scopeIds = scopeMap.get(node)\n      if (scopeIds) {\n        scopeIds.forEach((id: string) => {\n          scope[id]--\n          if (scope[id] === 0) {\n            delete scope[id]\n          }\n        })\n      }\n    }\n  })\n}\n\nfunction isRefIdentifier(id: Identifier, parent: _Node, parentStack: _Node[]) {\n  // declaration id\n  if (\n    parent.type === 'CatchClause' ||\n    ((parent.type === 'VariableDeclarator' ||\n      parent.type === 'ClassDeclaration') &&\n      parent.id === id)\n  ) {\n    return false\n  }\n\n  if (isFunction(parent)) {\n    // function declaration/expression id\n    if ((parent as any).id === id) {\n      return false\n    }\n    // params list\n    if (parent.params.includes(id)) {\n      return false\n    }\n  }\n\n  // class method name\n  if (parent.type === 'MethodDefinition') {\n    return false\n  }\n\n  // property key\n  // this also covers object destructuring pattern\n  if (isStaticPropertyKey(id, parent) || (parent as any).inPattern) {\n    return false\n  }\n\n  // non-assignment array destructuring pattern\n  if (\n    parent.type === 'ArrayPattern' &&\n    !isInDestructuringAssignment(parent, parentStack)\n  ) {\n    return false\n  }\n\n  // member expression property\n  if (\n    parent.type === 'MemberExpression' &&\n    parent.property === id &&\n    !parent.computed\n  ) {\n    return false\n  }\n\n  if (parent.type === 'ExportSpecifier') {\n    return false\n  }\n\n  // is a special keyword but parsed as identifier\n  if (id.name === 'arguments') {\n    return false\n  }\n\n  return true\n}\n\nconst isStaticProperty = (node: _Node): node is Property =>\n  node && node.type === 'Property' && !node.computed\n\nconst isStaticPropertyKey = (node: _Node, parent: _Node) =>\n  isStaticProperty(parent) && parent.key === node\n\nfunction isFunction(node: _Node): node is FunctionNode {\n  return /Function(?:Expression|Declaration)$|Method$/.test(node.type)\n}\n\nfunction findParentFunction(parentStack: _Node[]): FunctionNode | undefined {\n  for (let i = parentStack.length - 1; i >= 0; i--) {\n    const node = parentStack[i]\n    if (isFunction(node)) {\n      return node\n    }\n  }\n}\n\nfunction isInDestructuringAssignment(\n  parent: _Node,\n  parentStack: _Node[]\n): boolean {\n  if (\n    parent &&\n    (parent.type === 'Property' || parent.type === 'ArrayPattern')\n  ) {\n    let i = parentStack.length\n    while (i--) {\n      const p = parentStack[i]\n      if (p.type === 'AssignmentExpression') {\n        return true\n      } else if (p.type !== 'Property' && !p.type.endsWith('Pattern')) {\n        break\n      }\n    }\n  }\n  return false\n}\n","import path from 'path'\nimport { promises as fs } from 'fs'\nimport { Logger } from '../logger'\nimport { createDebugger } from '../utils'\n\nconst isDebug = !!process.env.DEBUG\nconst debug = createDebugger('vite:sourcemap', {\n  onlyWhenFocused: true\n})\n\n// Virtual modules should be prefixed with a null byte to avoid a\n// false positive \"missing source\" warning. We also check for certain\n// prefixes used for special handling in esbuildDepPlugin.\nconst virtualSourceRE = /^(\\0|dep:|browser-external:)/\n\ninterface SourceMapLike {\n  sources: string[]\n  sourcesContent?: (string | null)[]\n  sourceRoot?: string\n}\n\nexport async function injectSourcesContent(\n  map: SourceMapLike,\n  file: string,\n  logger: Logger\n): Promise<void> {\n  let sourceRoot: string | undefined\n  try {\n    // The source root is undefined for virtual modules and permission errors.\n    sourceRoot = await fs.realpath(\n      path.resolve(path.dirname(file), map.sourceRoot || '')\n    )\n  } catch {}\n\n  const missingSources: string[] = []\n  map.sourcesContent = await Promise.all(\n    map.sources.map((sourcePath) => {\n      if (sourcePath && !virtualSourceRE.test(sourcePath)) {\n        sourcePath = decodeURI(sourcePath)\n        if (sourceRoot) {\n          sourcePath = path.resolve(sourceRoot, sourcePath)\n        }\n        return fs.readFile(sourcePath, 'utf-8').catch(() => {\n          missingSources.push(sourcePath)\n          return null\n        })\n      }\n      return null\n    })\n  )\n\n  // Use this command…\n  //    DEBUG=\"vite:sourcemap\" vite build\n  // …to log the missing sources.\n  if (missingSources.length) {\n    logger.warnOnce(`Sourcemap for \"${file}\" points to missing source files`)\n    isDebug && debug(`Missing sources:\\n  ` + missingSources.join(`\\n  `))\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport MagicString from 'magic-string'\nimport { AttributeNode, NodeTypes } from '@vue/compiler-dom'\nimport { Connect } from 'types/connect'\nimport {\n  addToHTMLProxyCache,\n  applyHtmlTransforms,\n  assetAttrsConfig,\n  getScriptInfo,\n  IndexHtmlTransformHook,\n  resolveHtmlTransforms,\n  traverseHtml\n} from '../../plugins/html'\nimport { ResolvedConfig, ViteDevServer } from '../..'\nimport { send } from '../send'\nimport { CLIENT_PUBLIC_PATH, FS_PREFIX } from '../../constants'\nimport { cleanUrl, fsPathFromId, normalizePath, injectQuery } from '../../utils'\nimport type { ModuleGraph } from '../moduleGraph'\n\nexport function createDevHtmlTransformFn(\n  server: ViteDevServer\n): (url: string, html: string, originalUrl: string) => Promise<string> {\n  const [preHooks, postHooks] = resolveHtmlTransforms(server.config.plugins)\n\n  return (url: string, html: string, originalUrl: string): Promise<string> => {\n    return applyHtmlTransforms(html, [...preHooks, devHtmlHook, ...postHooks], {\n      path: url,\n      filename: getHtmlFilename(url, server),\n      server,\n      originalUrl\n    })\n  }\n}\n\nfunction getHtmlFilename(url: string, server: ViteDevServer) {\n  if (url.startsWith(FS_PREFIX)) {\n    return decodeURIComponent(fsPathFromId(url))\n  } else {\n    return decodeURIComponent(path.join(server.config.root, url.slice(1)))\n  }\n}\n\nconst startsWithSingleSlashRE = /^\\/(?!\\/)/\nconst processNodeUrl = (\n  node: AttributeNode,\n  s: MagicString,\n  config: ResolvedConfig,\n  htmlPath: string,\n  originalUrl?: string,\n  moduleGraph?: ModuleGraph\n) => {\n  let url = node.value?.content || ''\n\n  if (moduleGraph) {\n    const mod = moduleGraph.urlToModuleMap.get(url)\n    if (mod && mod.lastHMRTimestamp > 0) {\n      url = injectQuery(url, `t=${mod.lastHMRTimestamp}`)\n    }\n  }\n  if (startsWithSingleSlashRE.test(url)) {\n    // prefix with base\n    s.overwrite(\n      node.value!.loc.start.offset,\n      node.value!.loc.end.offset,\n      `\"${config.base + url.slice(1)}\"`\n    )\n  } else if (\n    url.startsWith('.') &&\n    originalUrl &&\n    originalUrl !== '/' &&\n    htmlPath === '/index.html'\n  ) {\n    // #3230 if some request url (localhost:3000/a/b) return to fallback html, the relative assets\n    // path will add `/a/` prefix, it will caused 404.\n    // rewrite before `./index.js` -> `localhost:3000/a/index.js`.\n    // rewrite after `../index.js` -> `localhost:3000/index.js`.\n    s.overwrite(\n      node.value!.loc.start.offset,\n      node.value!.loc.end.offset,\n      `\"${path.posix.join(\n        path.posix.relative(originalUrl, '/'),\n        url.slice(1)\n      )}\"`\n    )\n  }\n}\nconst devHtmlHook: IndexHtmlTransformHook = async (\n  html,\n  { path: htmlPath, server, originalUrl }\n) => {\n  const { config, moduleGraph } = server!\n  const base = config.base || '/'\n\n  const s = new MagicString(html)\n  let scriptModuleIndex = -1\n  const filePath = cleanUrl(htmlPath)\n\n  await traverseHtml(html, htmlPath, (node) => {\n    if (node.type !== NodeTypes.ELEMENT) {\n      return\n    }\n\n    // script tags\n    if (node.tag === 'script') {\n      const { src, isModule } = getScriptInfo(node)\n      if (isModule) {\n        scriptModuleIndex++\n      }\n\n      if (src) {\n        processNodeUrl(src, s, config, htmlPath, originalUrl, moduleGraph)\n      } else if (isModule) {\n        const url = filePath.replace(normalizePath(config.root), '')\n\n        const contents = node.children\n          .map((child: any) => child.content || '')\n          .join('')\n\n        // add HTML Proxy to Map\n        addToHTMLProxyCache(config, url, scriptModuleIndex, contents)\n\n        // inline js module. convert to src=\"proxy\"\n        const modulePath = `${\n          config.base + htmlPath.slice(1)\n        }?html-proxy&index=${scriptModuleIndex}.js`\n\n        // invalidate the module so the newly cached contents will be served\n        const module = server?.moduleGraph.getModuleById(modulePath)\n        if (module) {\n          server?.moduleGraph.invalidateModule(module)\n        }\n\n        s.overwrite(\n          node.loc.start.offset,\n          node.loc.end.offset,\n          `<script type=\"module\" src=\"${modulePath}\"></script>`\n        )\n      }\n    }\n\n    // elements with [href/src] attrs\n    const assetAttrs = assetAttrsConfig[node.tag]\n    if (assetAttrs) {\n      for (const p of node.props) {\n        if (\n          p.type === NodeTypes.ATTRIBUTE &&\n          p.value &&\n          assetAttrs.includes(p.name)\n        ) {\n          processNodeUrl(p, s, config, htmlPath, originalUrl)\n        }\n      }\n    }\n  })\n\n  html = s.toString()\n\n  return {\n    html,\n    tags: [\n      {\n        tag: 'script',\n        attrs: {\n          type: 'module',\n          src: path.posix.join(base, CLIENT_PUBLIC_PATH)\n        },\n        injectTo: 'head-prepend'\n      }\n    ]\n  }\n}\n\nexport function indexHtmlMiddleware(\n  server: ViteDevServer\n): Connect.NextHandleFunction {\n  // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n  return async function viteIndexHtmlMiddleware(req, res, next) {\n    if (res.writableEnded) {\n      return next()\n    }\n\n    const url = req.url && cleanUrl(req.url)\n    // spa-fallback always redirects to /index.html\n    if (url?.endsWith('.html') && req.headers['sec-fetch-dest'] !== 'script') {\n      const filename = getHtmlFilename(url, server)\n      if (fs.existsSync(filename)) {\n        try {\n          let html = fs.readFileSync(filename, 'utf-8')\n          html = await server.transformIndexHtml(url, html, req.originalUrl)\n          return send(req, res, html, 'html')\n        } catch (e) {\n          return next(e)\n        }\n      }\n    }\n    next()\n  }\n}\n","import path from 'path'\nimport { ServerResponse } from 'http'\nimport sirv, { Options } from 'sirv'\nimport { Connect } from 'types/connect'\nimport { normalizePath, ViteDevServer } from '../..'\nimport { FS_PREFIX } from '../../constants'\nimport {\n  cleanUrl,\n  ensureLeadingSlash,\n  fsPathFromId,\n  isImportRequest,\n  isInternalRequest,\n  isWindows,\n  slash,\n  isFileReadable\n} from '../../utils'\nimport { isMatch } from 'micromatch'\n\nconst sirvOptions: Options = {\n  dev: true,\n  etag: true,\n  extensions: [],\n  setHeaders(res, pathname) {\n    // Matches js, jsx, ts, tsx.\n    // The reason this is done, is that the .ts file extension is reserved\n    // for the MIME type video/mp2t. In almost all cases, we can expect\n    // these files to be TypeScript files, and for Vite to serve them with\n    // this Content-Type.\n    if (/\\.[tj]sx?$/.test(pathname)) {\n      res.setHeader('Content-Type', 'application/javascript')\n    }\n  }\n}\n\nexport function servePublicMiddleware(dir: string): Connect.NextHandleFunction {\n  const serve = sirv(dir, sirvOptions)\n\n  // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n  return function viteServePublicMiddleware(req, res, next) {\n    // skip import request and internal requests `/@fs/ /@vite-client` etc...\n    if (isImportRequest(req.url!) || isInternalRequest(req.url!)) {\n      return next()\n    }\n    serve(req, res, next)\n  }\n}\n\nexport function serveStaticMiddleware(\n  dir: string,\n  server: ViteDevServer\n): Connect.NextHandleFunction {\n  const serve = sirv(dir, sirvOptions)\n\n  // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n  return function viteServeStaticMiddleware(req, res, next) {\n    // only serve the file if it's not an html request or ends with `/`\n    // so that html requests can fallthrough to our html middleware for\n    // special processing\n    // also skip internal requests `/@fs/ /@vite-client` etc...\n    const cleanedUrl = cleanUrl(req.url!)\n    if (\n      cleanedUrl.endsWith('/') ||\n      path.extname(cleanedUrl) === '.html' ||\n      isInternalRequest(req.url!)\n    ) {\n      return next()\n    }\n\n    const url = decodeURI(req.url!)\n\n    // apply aliases to static requests as well\n    let redirected: string | undefined\n    for (const { find, replacement } of server.config.resolve.alias) {\n      const matches =\n        typeof find === 'string' ? url.startsWith(find) : find.test(url)\n      if (matches) {\n        redirected = url.replace(find, replacement)\n        break\n      }\n    }\n    if (redirected) {\n      // dir is pre-normalized to posix style\n      if (redirected.startsWith(dir)) {\n        redirected = redirected.slice(dir.length)\n      }\n    }\n\n    const resolvedUrl = redirected || url\n    let fileUrl = path.resolve(dir, resolvedUrl.replace(/^\\//, ''))\n    if (resolvedUrl.endsWith('/') && !fileUrl.endsWith('/')) {\n      fileUrl = fileUrl + '/'\n    }\n    if (!ensureServingAccess(fileUrl, server, res, next)) {\n      return\n    }\n\n    if (redirected) {\n      req.url = redirected\n    }\n\n    serve(req, res, next)\n  }\n}\n\nexport function serveRawFsMiddleware(\n  server: ViteDevServer\n): Connect.NextHandleFunction {\n  const serveFromRoot = sirv('/', sirvOptions)\n\n  // Keep the named function. The name is visible in debug logs via `DEBUG=connect:dispatcher ...`\n  return function viteServeRawFsMiddleware(req, res, next) {\n    let url = req.url!\n    // In some cases (e.g. linked monorepos) files outside of root will\n    // reference assets that are also out of served root. In such cases\n    // the paths are rewritten to `/@fs/` prefixed paths and must be served by\n    // searching based from fs root.\n    if (url.startsWith(FS_PREFIX)) {\n      // restrict files outside of `fs.allow`\n      if (\n        !ensureServingAccess(\n          slash(path.resolve(fsPathFromId(url))),\n          server,\n          res,\n          next\n        )\n      ) {\n        return\n      }\n\n      url = url.slice(FS_PREFIX.length)\n      if (isWindows) url = url.replace(/^[A-Z]:/i, '')\n\n      req.url = url\n      serveFromRoot(req, res, next)\n    } else {\n      next()\n    }\n  }\n}\n\nconst _matchOptions = { matchBase: true }\n\nexport function isFileServingAllowed(\n  url: string,\n  server: ViteDevServer\n): boolean {\n  if (!server.config.server.fs.strict) return true\n\n  const cleanedUrl = cleanUrl(url)\n  const file = ensureLeadingSlash(normalizePath(cleanedUrl))\n\n  if (server.config.server.fs.deny.some((i) => isMatch(file, i, _matchOptions)))\n    return false\n\n  if (server.moduleGraph.safeModulesPath.has(file)) return true\n\n  if (server.config.server.fs.allow.some((i) => file.startsWith(i + '/')))\n    return true\n\n  return false\n}\n\nfunction ensureServingAccess(\n  url: string,\n  server: ViteDevServer,\n  res: ServerResponse,\n  next: Connect.NextFunction\n): boolean {\n  if (isFileServingAllowed(url, server)) {\n    return true\n  }\n  if (isFileReadable(cleanUrl(url))) {\n    const urlMessage = `The request url \"${url}\" is outside of Vite serving allow list.`\n    const hintMessage = `\n${server.config.server.fs.allow.map((i) => `- ${i}`).join('\\n')}\n\nRefer to docs https://vitejs.dev/config/#server-fs-allow for configurations and more details.`\n\n    server.config.logger.error(urlMessage)\n    server.config.logger.warnOnce(hintMessage + '\\n')\n    res.statusCode = 403\n    res.write(renderRestrictedErrorHTML(urlMessage + '\\n' + hintMessage))\n    res.end()\n  } else {\n    // if the file doesn't exist, we shouldn't restrict this path as it can\n    // be an API call. Middlewares would issue a 404 if the file isn't handled\n    next()\n  }\n  return false\n}\n\nfunction renderRestrictedErrorHTML(msg: string): string {\n  // to have syntax highlighting and autocompletion in IDE\n  const html = String.raw\n  return html`\n    <body>\n      <h1>403 Restricted</h1>\n      <p>${msg.replace(/\\n/g, '<br/>')}</p>\n      <style>\n        body {\n          padding: 1em 2em;\n        }\n      </style>\n    </body>\n  `\n}\n","import { promises as fs } from 'fs'\nimport path from 'path'\nimport getEtag from 'etag'\nimport * as convertSourceMap from 'convert-source-map'\nimport { SourceDescription, SourceMap } from 'rollup'\nimport { ViteDevServer } from '..'\nimport chalk from 'chalk'\nimport {\n  createDebugger,\n  cleanUrl,\n  prettifyUrl,\n  removeTimestampQuery,\n  timeFrom,\n  ensureWatchedFile,\n  isObject\n} from '../utils'\nimport { checkPublicFile } from '../plugins/asset'\nimport { ssrTransform } from '../ssr/ssrTransform'\nimport { injectSourcesContent } from './sourcemap'\nimport { isFileServingAllowed } from './middlewares/static'\nimport { performance } from 'perf_hooks'\n\nconst debugLoad = createDebugger('vite:load')\nconst debugTransform = createDebugger('vite:transform')\nconst debugCache = createDebugger('vite:cache')\nconst isDebug = !!process.env.DEBUG\n\nexport interface TransformResult {\n  code: string\n  map: SourceMap | null\n  etag?: string\n  deps?: string[]\n  dynamicDeps?: string[]\n}\n\nexport interface TransformOptions {\n  ssr?: boolean\n  html?: boolean\n}\n\nexport function transformRequest(\n  url: string,\n  server: ViteDevServer,\n  options: TransformOptions = {}\n): Promise<TransformResult | null> {\n  const cacheKey = (options.ssr ? 'ssr:' : options.html ? 'html:' : '') + url\n  let request = server._pendingRequests.get(cacheKey)\n  if (!request) {\n    request = doTransform(url, server, options)\n    server._pendingRequests.set(cacheKey, request)\n    const done = () => server._pendingRequests.delete(cacheKey)\n    request.then(done, done)\n  }\n  return request\n}\n\nasync function doTransform(\n  url: string,\n  server: ViteDevServer,\n  options: TransformOptions\n) {\n  url = removeTimestampQuery(url)\n  const { config, pluginContainer, moduleGraph, watcher } = server\n  const { root, logger } = config\n  const prettyUrl = isDebug ? prettifyUrl(url, root) : ''\n  const ssr = !!options.ssr\n\n  const module = await server.moduleGraph.getModuleByUrl(url, ssr)\n\n  // check if we have a fresh cache\n  const cached =\n    module && (ssr ? module.ssrTransformResult : module.transformResult)\n  if (cached) {\n    // TODO: check if the module is \"partially invalidated\" - i.e. an import\n    // down the chain has been fully invalidated, but this current module's\n    // content has not changed.\n    // in this case, we can reuse its previous cached result and only update\n    // its import timestamps.\n\n    isDebug && debugCache(`[memory] ${prettyUrl}`)\n    return cached\n  }\n\n  // resolve\n  const id =\n    (await pluginContainer.resolveId(url, undefined, { ssr }))?.id || url\n  const file = cleanUrl(id)\n\n  let code: string | null = null\n  let map: SourceDescription['map'] = null\n\n  // load\n  const loadStart = isDebug ? performance.now() : 0\n  const loadResult = await pluginContainer.load(id, { ssr })\n  if (loadResult == null) {\n    // if this is an html request and there is no load result, skip ahead to\n    // SPA fallback.\n    if (options.html && !id.endsWith('.html')) {\n      return null\n    }\n    // try fallback loading it from fs as string\n    // if the file is a binary, there should be a plugin that already loaded it\n    // as string\n    // only try the fallback if access is allowed, skip for out of root url\n    // like /service-worker.js or /api/users\n    if (options.ssr || isFileServingAllowed(file, server)) {\n      try {\n        code = await fs.readFile(file, 'utf-8')\n        isDebug && debugLoad(`${timeFrom(loadStart)} [fs] ${prettyUrl}`)\n      } catch (e) {\n        if (e.code !== 'ENOENT') {\n          throw e\n        }\n      }\n    }\n    if (code) {\n      try {\n        map = (\n          convertSourceMap.fromSource(code) ||\n          convertSourceMap.fromMapFileSource(code, path.dirname(file))\n        )?.toObject()\n      } catch (e) {\n        logger.warn(`Failed to load source map for ${url}.`, {\n          timestamp: true\n        })\n      }\n    }\n  } else {\n    isDebug && debugLoad(`${timeFrom(loadStart)} [plugin] ${prettyUrl}`)\n    if (isObject(loadResult)) {\n      code = loadResult.code\n      map = loadResult.map\n    } else {\n      code = loadResult\n    }\n  }\n  if (code == null) {\n    if (checkPublicFile(url, config)) {\n      throw new Error(\n        `Failed to load url ${url} (resolved id: ${id}). ` +\n          `This file is in /public and will be copied as-is during build without ` +\n          `going through the plugin transforms, and therefore should not be ` +\n          `imported from source code. It can only be referenced via HTML tags.`\n      )\n    } else {\n      return null\n    }\n  }\n\n  // ensure module in graph after successful load\n  const mod = await moduleGraph.ensureEntryFromUrl(url, ssr)\n  ensureWatchedFile(watcher, mod.file, root)\n\n  // transform\n  const transformStart = isDebug ? performance.now() : 0\n  const transformResult = await pluginContainer.transform(code, id, {\n    inMap: map,\n    ssr\n  })\n  if (\n    transformResult == null ||\n    (isObject(transformResult) && transformResult.code == null)\n  ) {\n    // no transform applied, keep code as-is\n    isDebug &&\n      debugTransform(\n        timeFrom(transformStart) + chalk.dim(` [skipped] ${prettyUrl}`)\n      )\n  } else {\n    isDebug && debugTransform(`${timeFrom(transformStart)} ${prettyUrl}`)\n    code = transformResult.code!\n    map = transformResult.map\n  }\n\n  if (map && mod.file) {\n    map = (typeof map === 'string' ? JSON.parse(map) : map) as SourceMap\n    if (map.mappings && !map.sourcesContent) {\n      await injectSourcesContent(map, mod.file, logger)\n    }\n  }\n\n  if (ssr) {\n    return (mod.ssrTransformResult = await ssrTransform(\n      code,\n      map as SourceMap,\n      url\n    ))\n  } else {\n    return (mod.transformResult = {\n      code,\n      map,\n      etag: getEtag(code, { weak: true })\n    } as TransformResult)\n  }\n}\n","import { extname } from 'path'\nimport { ModuleInfo, PartialResolvedId } from 'rollup'\nimport { parse as parseUrl } from 'url'\nimport { isDirectCSSRequest } from '../plugins/css'\nimport {\n  cleanUrl,\n  normalizePath,\n  removeImportQuery,\n  removeTimestampQuery\n} from '../utils'\nimport { FS_PREFIX } from '../constants'\nimport { TransformResult } from './transformRequest'\n\nexport class ModuleNode {\n  /**\n   * Public served url path, starts with /\n   */\n  url: string\n  /**\n   * Resolved file system path + query\n   */\n  id: string | null = null\n  file: string | null = null\n  type: 'js' | 'css'\n  info?: ModuleInfo\n  meta?: Record<string, any>\n  importers = new Set<ModuleNode>()\n  importedModules = new Set<ModuleNode>()\n  acceptedHmrDeps = new Set<ModuleNode>()\n  isSelfAccepting = false\n  transformResult: TransformResult | null = null\n  ssrTransformResult: TransformResult | null = null\n  ssrModule: Record<string, any> | null = null\n  lastHMRTimestamp = 0\n\n  constructor(url: string) {\n    this.url = url\n    this.type = isDirectCSSRequest(url) ? 'css' : 'js'\n  }\n}\n\nfunction invalidateSSRModule(mod: ModuleNode, seen: Set<ModuleNode>) {\n  if (seen.has(mod)) {\n    return\n  }\n  seen.add(mod)\n  mod.ssrModule = null\n  mod.importers.forEach((importer) => invalidateSSRModule(importer, seen))\n}\n\nexport type ResolvedUrl = [\n  url: string,\n  resolvedId: string,\n  meta: object | null | undefined\n]\n\nexport class ModuleGraph {\n  urlToModuleMap = new Map<string, ModuleNode>()\n  idToModuleMap = new Map<string, ModuleNode>()\n  // a single file may corresponds to multiple modules with different queries\n  fileToModulesMap = new Map<string, Set<ModuleNode>>()\n  safeModulesPath = new Set<string>()\n\n  constructor(\n    private resolveId: (\n      url: string,\n      ssr: boolean\n    ) => Promise<PartialResolvedId | null>\n  ) {}\n\n  async getModuleByUrl(\n    rawUrl: string,\n    ssr?: boolean\n  ): Promise<ModuleNode | undefined> {\n    const [url] = await this.resolveUrl(rawUrl, ssr)\n    return this.urlToModuleMap.get(url)\n  }\n\n  getModuleById(id: string): ModuleNode | undefined {\n    return this.idToModuleMap.get(removeTimestampQuery(id))\n  }\n\n  getModulesByFile(file: string): Set<ModuleNode> | undefined {\n    return this.fileToModulesMap.get(file)\n  }\n\n  onFileChange(file: string): void {\n    const mods = this.getModulesByFile(file)\n    if (mods) {\n      const seen = new Set<ModuleNode>()\n      mods.forEach((mod) => {\n        this.invalidateModule(mod, seen)\n      })\n    }\n  }\n\n  invalidateModule(mod: ModuleNode, seen: Set<ModuleNode> = new Set()): void {\n    mod.info = undefined\n    mod.transformResult = null\n    mod.ssrTransformResult = null\n    invalidateSSRModule(mod, seen)\n  }\n\n  invalidateAll(): void {\n    const seen = new Set<ModuleNode>()\n    this.idToModuleMap.forEach((mod) => {\n      this.invalidateModule(mod, seen)\n    })\n  }\n\n  /**\n   * Update the module graph based on a module's updated imports information\n   * If there are dependencies that no longer have any importers, they are\n   * returned as a Set.\n   */\n  async updateModuleInfo(\n    mod: ModuleNode,\n    importedModules: Set<string | ModuleNode>,\n    acceptedModules: Set<string | ModuleNode>,\n    isSelfAccepting: boolean,\n    ssr?: boolean\n  ): Promise<Set<ModuleNode> | undefined> {\n    mod.isSelfAccepting = isSelfAccepting\n    const prevImports = mod.importedModules\n    const nextImports = (mod.importedModules = new Set())\n    let noLongerImported: Set<ModuleNode> | undefined\n    // update import graph\n    for (const imported of importedModules) {\n      const dep =\n        typeof imported === 'string'\n          ? await this.ensureEntryFromUrl(imported, ssr)\n          : imported\n      dep.importers.add(mod)\n      nextImports.add(dep)\n    }\n    // remove the importer from deps that were imported but no longer are.\n    prevImports.forEach((dep) => {\n      if (!nextImports.has(dep)) {\n        dep.importers.delete(mod)\n        if (!dep.importers.size) {\n          // dependency no longer imported\n          ;(noLongerImported || (noLongerImported = new Set())).add(dep)\n        }\n      }\n    })\n    // update accepted hmr deps\n    const deps = (mod.acceptedHmrDeps = new Set())\n    for (const accepted of acceptedModules) {\n      const dep =\n        typeof accepted === 'string'\n          ? await this.ensureEntryFromUrl(accepted, ssr)\n          : accepted\n      deps.add(dep)\n    }\n    return noLongerImported\n  }\n\n  async ensureEntryFromUrl(rawUrl: string, ssr?: boolean): Promise<ModuleNode> {\n    const [url, resolvedId, meta] = await this.resolveUrl(rawUrl, ssr)\n    let mod = this.urlToModuleMap.get(url)\n    if (!mod) {\n      mod = new ModuleNode(url)\n      if (meta) mod.meta = meta\n      this.urlToModuleMap.set(url, mod)\n      mod.id = resolvedId\n      this.idToModuleMap.set(resolvedId, mod)\n      const file = (mod.file = cleanUrl(resolvedId))\n      let fileMappedModules = this.fileToModulesMap.get(file)\n      if (!fileMappedModules) {\n        fileMappedModules = new Set()\n        this.fileToModulesMap.set(file, fileMappedModules)\n      }\n      fileMappedModules.add(mod)\n    }\n    return mod\n  }\n\n  // some deps, like a css file referenced via @import, don't have its own\n  // url because they are inlined into the main css import. But they still\n  // need to be represented in the module graph so that they can trigger\n  // hmr in the importing css file.\n  createFileOnlyEntry(file: string): ModuleNode {\n    file = normalizePath(file)\n    let fileMappedModules = this.fileToModulesMap.get(file)\n    if (!fileMappedModules) {\n      fileMappedModules = new Set()\n      this.fileToModulesMap.set(file, fileMappedModules)\n    }\n\n    const url = `${FS_PREFIX}${file}`\n    for (const m of fileMappedModules) {\n      if (m.url === url || m.id === file) {\n        return m\n      }\n    }\n\n    const mod = new ModuleNode(url)\n    mod.file = file\n    fileMappedModules.add(mod)\n    return mod\n  }\n\n  // for incoming urls, it is important to:\n  // 1. remove the HMR timestamp query (?t=xxxx)\n  // 2. resolve its extension so that urls with or without extension all map to\n  // the same module\n  async resolveUrl(url: string, ssr?: boolean): Promise<ResolvedUrl> {\n    url = removeImportQuery(removeTimestampQuery(url))\n    const resolved = await this.resolveId(url, !!ssr)\n    const resolvedId = resolved?.id || url\n    const ext = extname(cleanUrl(resolvedId))\n    const { pathname, search, hash } = parseUrl(url)\n    if (ext && !pathname!.endsWith(ext)) {\n      url = pathname + ext + (search || '') + (hash || '')\n    }\n    return [url, resolvedId, resolved?.meta]\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport chalk from 'chalk'\nimport { ViteDevServer } from '..'\nimport { createDebugger, normalizePath } from '../utils'\nimport { ModuleNode } from './moduleGraph'\nimport { Update } from 'types/hmrPayload'\nimport { CLIENT_DIR } from '../constants'\nimport { RollupError } from 'rollup'\nimport { isMatch } from 'micromatch'\nimport { Server } from 'http'\nimport { isCSSRequest } from '../plugins/css'\n\nexport const debugHmr = createDebugger('vite:hmr')\n\nconst normalizedClientDir = normalizePath(CLIENT_DIR)\n\nexport interface HmrOptions {\n  protocol?: string\n  host?: string\n  port?: number\n  clientPort?: number\n  path?: string\n  timeout?: number\n  overlay?: boolean\n  server?: Server\n}\n\nexport interface HmrContext {\n  file: string\n  timestamp: number\n  modules: Array<ModuleNode>\n  read: () => string | Promise<string>\n  server: ViteDevServer\n}\n\nfunction getShortName(file: string, root: string) {\n  return file.startsWith(root + '/') ? path.posix.relative(root, file) : file\n}\n\nexport async function handleHMRUpdate(\n  file: string,\n  server: ViteDevServer\n): Promise<any> {\n  const { ws, config, moduleGraph } = server\n  const shortFile = getShortName(file, config.root)\n\n  const isConfig = file === config.configFile\n  const isConfigDependency = config.configFileDependencies.some(\n    (name) => file === path.resolve(name)\n  )\n  const isEnv =\n    config.inlineConfig.envFile !== false &&\n    (file === '.env' || file.startsWith('.env.'))\n  if (isConfig || isConfigDependency || isEnv) {\n    // auto restart server\n    debugHmr(`[config change] ${chalk.dim(shortFile)}`)\n    config.logger.info(\n      chalk.green(\n        `${path.relative(process.cwd(), file)} changed, restarting server...`\n      ),\n      { clear: true, timestamp: true }\n    )\n    await server.restart()\n    return\n  }\n\n  debugHmr(`[file change] ${chalk.dim(shortFile)}`)\n\n  // (dev only) the client itself cannot be hot updated.\n  if (file.startsWith(normalizedClientDir)) {\n    ws.send({\n      type: 'full-reload',\n      path: '*'\n    })\n    return\n  }\n\n  const mods = moduleGraph.getModulesByFile(file)\n\n  // check if any plugin wants to perform custom HMR handling\n  const timestamp = Date.now()\n  const hmrContext: HmrContext = {\n    file,\n    timestamp,\n    modules: mods ? [...mods] : [],\n    read: () => readModifiedFile(file),\n    server\n  }\n\n  for (const plugin of config.plugins) {\n    if (plugin.handleHotUpdate) {\n      const filteredModules = await plugin.handleHotUpdate(hmrContext)\n      if (filteredModules) {\n        hmrContext.modules = filteredModules\n      }\n    }\n  }\n\n  if (!hmrContext.modules.length) {\n    // html file cannot be hot updated\n    if (file.endsWith('.html')) {\n      config.logger.info(chalk.green(`page reload `) + chalk.dim(shortFile), {\n        clear: true,\n        timestamp: true\n      })\n      ws.send({\n        type: 'full-reload',\n        path: config.server.middlewareMode\n          ? '*'\n          : '/' + normalizePath(path.relative(config.root, file))\n      })\n    } else {\n      // loaded but not in the module graph, probably not js\n      debugHmr(`[no modules matched] ${chalk.dim(shortFile)}`)\n    }\n    return\n  }\n\n  updateModules(shortFile, hmrContext.modules, timestamp, server)\n}\n\nfunction updateModules(\n  file: string,\n  modules: ModuleNode[],\n  timestamp: number,\n  { config, ws }: ViteDevServer\n) {\n  const updates: Update[] = []\n  const invalidatedModules = new Set<ModuleNode>()\n  let needFullReload = false\n\n  for (const mod of modules) {\n    invalidate(mod, timestamp, invalidatedModules)\n    if (needFullReload) {\n      continue\n    }\n\n    const boundaries = new Set<{\n      boundary: ModuleNode\n      acceptedVia: ModuleNode\n    }>()\n    const hasDeadEnd = propagateUpdate(mod, boundaries)\n    if (hasDeadEnd) {\n      needFullReload = true\n      continue\n    }\n\n    updates.push(\n      ...[...boundaries].map(({ boundary, acceptedVia }) => ({\n        type: `${boundary.type}-update` as Update['type'],\n        timestamp,\n        path: boundary.url,\n        acceptedPath: acceptedVia.url\n      }))\n    )\n  }\n\n  if (needFullReload) {\n    config.logger.info(chalk.green(`page reload `) + chalk.dim(file), {\n      clear: true,\n      timestamp: true\n    })\n    ws.send({\n      type: 'full-reload'\n    })\n  } else {\n    config.logger.info(\n      updates\n        .map(({ path }) => chalk.green(`hmr update `) + chalk.dim(path))\n        .join('\\n'),\n      { clear: true, timestamp: true }\n    )\n    ws.send({\n      type: 'update',\n      updates\n    })\n  }\n}\n\nexport async function handleFileAddUnlink(\n  file: string,\n  server: ViteDevServer,\n  isUnlink = false\n): Promise<void> {\n  const modules = [...(server.moduleGraph.getModulesByFile(file) ?? [])]\n  if (isUnlink && file in server._globImporters) {\n    delete server._globImporters[file]\n  } else {\n    for (const i in server._globImporters) {\n      const { module, importGlobs } = server._globImporters[i]\n      for (const { base, pattern } of importGlobs) {\n        if (\n          isMatch(file, pattern) ||\n          isMatch(path.relative(base, file), pattern)\n        ) {\n          modules.push(module)\n          // We use `onFileChange` to invalidate `module.file` so that subsequent `ssrLoadModule()`\n          // calls get fresh glob import results with(out) the newly added(/removed) `file`.\n          server.moduleGraph.onFileChange(module.file!)\n          break\n        }\n      }\n    }\n  }\n  if (modules.length > 0) {\n    updateModules(\n      getShortName(file, server.config.root),\n      modules,\n      Date.now(),\n      server\n    )\n  }\n}\n\nfunction propagateUpdate(\n  node: ModuleNode,\n  boundaries: Set<{\n    boundary: ModuleNode\n    acceptedVia: ModuleNode\n  }>,\n  currentChain: ModuleNode[] = [node]\n): boolean /* hasDeadEnd */ {\n  if (node.isSelfAccepting) {\n    boundaries.add({\n      boundary: node,\n      acceptedVia: node\n    })\n\n    // additionally check for CSS importers, since a PostCSS plugin like\n    // Tailwind JIT may register any file as a dependency to a CSS file.\n    for (const importer of node.importers) {\n      if (isCSSRequest(importer.url) && !currentChain.includes(importer)) {\n        propagateUpdate(importer, boundaries, currentChain.concat(importer))\n      }\n    }\n\n    return false\n  }\n\n  if (!node.importers.size) {\n    return true\n  }\n\n  // #3716, #3913\n  // For a non-CSS file, if all of its importers are CSS files (registered via\n  // PostCSS plugins) it should be considered a dead end and force full reload.\n  if (\n    !isCSSRequest(node.url) &&\n    [...node.importers].every((i) => isCSSRequest(i.url))\n  ) {\n    return true\n  }\n\n  for (const importer of node.importers) {\n    const subChain = currentChain.concat(importer)\n    if (importer.acceptedHmrDeps.has(node)) {\n      boundaries.add({\n        boundary: importer,\n        acceptedVia: node\n      })\n      continue\n    }\n\n    if (currentChain.includes(importer)) {\n      // circular deps is considered dead end\n      return true\n    }\n\n    if (propagateUpdate(importer, boundaries, subChain)) {\n      return true\n    }\n  }\n  return false\n}\n\nfunction invalidate(mod: ModuleNode, timestamp: number, seen: Set<ModuleNode>) {\n  if (seen.has(mod)) {\n    return\n  }\n  seen.add(mod)\n  mod.lastHMRTimestamp = timestamp\n  mod.transformResult = null\n  mod.ssrModule = null\n  mod.ssrTransformResult = null\n  mod.importers.forEach((importer) => {\n    if (!importer.acceptedHmrDeps.has(mod)) {\n      invalidate(importer, timestamp, seen)\n    }\n  })\n}\n\nexport function handlePrunedModules(\n  mods: Set<ModuleNode>,\n  { ws }: ViteDevServer\n): void {\n  // update the disposed modules' hmr timestamp\n  // since if it's re-imported, it should re-apply side effects\n  // and without the timestamp the browser will not re-import it!\n  const t = Date.now()\n  mods.forEach((mod) => {\n    mod.lastHMRTimestamp = t\n    debugHmr(`[dispose] ${chalk.dim(mod.file)}`)\n  })\n  ws.send({\n    type: 'prune',\n    paths: [...mods].map((m) => m.url)\n  })\n}\n\nconst enum LexerState {\n  inCall,\n  inSingleQuoteString,\n  inDoubleQuoteString,\n  inTemplateString,\n  inArray\n}\n\n/**\n * Lex import.meta.hot.accept() for accepted deps.\n * Since hot.accept() can only accept string literals or array of string\n * literals, we don't really need a heavy @babel/parse call on the entire source.\n *\n * @returns selfAccepts\n */\nexport function lexAcceptedHmrDeps(\n  code: string,\n  start: number,\n  urls: Set<{ url: string; start: number; end: number }>\n): boolean {\n  let state: LexerState = LexerState.inCall\n  // the state can only be 2 levels deep so no need for a stack\n  let prevState: LexerState = LexerState.inCall\n  let currentDep: string = ''\n\n  function addDep(index: number) {\n    urls.add({\n      url: currentDep,\n      start: index - currentDep.length - 1,\n      end: index + 1\n    })\n    currentDep = ''\n  }\n\n  for (let i = start; i < code.length; i++) {\n    const char = code.charAt(i)\n    switch (state) {\n      case LexerState.inCall:\n      case LexerState.inArray:\n        if (char === `'`) {\n          prevState = state\n          state = LexerState.inSingleQuoteString\n        } else if (char === `\"`) {\n          prevState = state\n          state = LexerState.inDoubleQuoteString\n        } else if (char === '`') {\n          prevState = state\n          state = LexerState.inTemplateString\n        } else if (/\\s/.test(char)) {\n          continue\n        } else {\n          if (state === LexerState.inCall) {\n            if (char === `[`) {\n              state = LexerState.inArray\n            } else {\n              // reaching here means the first arg is neither a string literal\n              // nor an Array literal (direct callback) or there is no arg\n              // in both case this indicates a self-accepting module\n              return true // done\n            }\n          } else if (state === LexerState.inArray) {\n            if (char === `]`) {\n              return false // done\n            } else if (char === ',') {\n              continue\n            } else {\n              error(i)\n            }\n          }\n        }\n        break\n      case LexerState.inSingleQuoteString:\n        if (char === `'`) {\n          addDep(i)\n          if (prevState === LexerState.inCall) {\n            // accept('foo', ...)\n            return false\n          } else {\n            state = prevState\n          }\n        } else {\n          currentDep += char\n        }\n        break\n      case LexerState.inDoubleQuoteString:\n        if (char === `\"`) {\n          addDep(i)\n          if (prevState === LexerState.inCall) {\n            // accept('foo', ...)\n            return false\n          } else {\n            state = prevState\n          }\n        } else {\n          currentDep += char\n        }\n        break\n      case LexerState.inTemplateString:\n        if (char === '`') {\n          addDep(i)\n          if (prevState === LexerState.inCall) {\n            // accept('foo', ...)\n            return false\n          } else {\n            state = prevState\n          }\n        } else if (char === '$' && code.charAt(i + 1) === '{') {\n          error(i)\n        } else {\n          currentDep += char\n        }\n        break\n      default:\n        throw new Error('unknown import.meta.hot lexer state')\n    }\n  }\n  return false\n}\n\nfunction error(pos: number) {\n  const err = new Error(\n    `import.meta.accept() can only accept string literals or an ` +\n      `Array of string literals.`\n  ) as RollupError\n  err.pos = pos\n  throw err\n}\n\n// vitejs/vite#610 when hot-reloading Vue files, we read immediately on file\n// change event and sometimes this can be too early and get an empty buffer.\n// Poll until the file's modified time has changed before reading again.\nasync function readModifiedFile(file: string): Promise<string> {\n  const content = fs.readFileSync(file, 'utf-8')\n  if (!content) {\n    const mtime = fs.statSync(file).mtimeMs\n    await new Promise((r) => {\n      let n = 0\n      const poll = async () => {\n        n++\n        const newMtime = fs.statSync(file).mtimeMs\n        if (newMtime !== mtime || n > 10) {\n          r(0)\n        } else {\n          setTimeout(poll, 10)\n        }\n      }\n      setTimeout(poll, 10)\n    })\n    return fs.readFileSync(file, 'utf-8')\n  } else {\n    return content\n  }\n}\n","import { SourceMapConsumer, RawSourceMap } from 'source-map'\nimport { ModuleGraph } from '../server/moduleGraph'\n\nlet offset: number\ntry {\n  new Function('throw new Error(1)')()\n} catch (e) {\n  // in Node 12, stack traces account for the function wrapper.\n  // in Node 13 and later, the function wrapper adds two lines,\n  // which must be subtracted to generate a valid mapping\n  const match = /:(\\d+):\\d+\\)$/.exec(e.stack.split('\\n')[1])\n  offset = match ? +match[1] - 1 : 0\n}\n\nexport function ssrRewriteStacktrace(\n  stack: string,\n  moduleGraph: ModuleGraph\n): string {\n  return stack\n    .split('\\n')\n    .map((line) => {\n      return line.replace(\n        /^ {4}at (?:(.+?)\\s+\\()?(?:(.+?):(\\d+)(?::(\\d+))?)\\)?/,\n        (input, varName, url, line, column) => {\n          if (!url) return input\n\n          const mod = moduleGraph.urlToModuleMap.get(url)\n          const rawSourceMap = mod?.ssrTransformResult?.map\n\n          if (!rawSourceMap) {\n            return input\n          }\n\n          // In `source-map:v0.7.0+` this constructor returns a Promise...\n          // How can we make this block async?\n          const consumer = new SourceMapConsumer(\n            rawSourceMap as unknown as RawSourceMap\n          )\n\n          const pos = consumer.originalPositionFor({\n            line: Number(line) - offset,\n            column: Number(column),\n            bias: SourceMapConsumer.LEAST_UPPER_BOUND\n          })\n\n          if (!pos.source) {\n            return input\n          }\n\n          const source = `${pos.source}:${pos.line || 0}:${pos.column || 0}`\n          if (!varName || varName === 'eval') {\n            return `    at ${source}`\n          } else {\n            return `    at ${varName} (${source})`\n          }\n        }\n      )\n    })\n    .join('\\n')\n}\n\nexport function rebindErrorStacktrace(e: Error, stacktrace: string): void {\n  const { configurable, writable } = Object.getOwnPropertyDescriptor(\n    e,\n    'stack'\n  )!\n  if (configurable) {\n    Object.defineProperty(e, 'stack', {\n      value: stacktrace,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    })\n  } else if (writable) {\n    e.stack = stacktrace\n  }\n}\n","import chalk from 'chalk'\nimport { ViteDevServer } from '..'\nimport { resolveSSRExternal } from '../ssr/ssrExternal'\n\n/**\n * The amount to wait for requests to register newly found dependencies before triggering\n * a re-bundle + page reload\n */\nconst debounceMs = 100\n\nexport function createMissingImporterRegisterFn(\n  server: ViteDevServer, optimizeDeps: typeof import('./index')['optimizeDeps']\n): (id: string, resolved: string, ssr?: boolean) => void {\n  const { logger } = server.config\n  let knownOptimized = server._optimizeDepsMetadata!.optimized\n  let currentMissing: Record<string, string> = {}\n  let handle: NodeJS.Timeout | undefined\n\n  let pendingResolve: (() => void) | null = null\n\n  async function rerun(ssr: boolean | undefined) {\n    const newDeps = currentMissing\n    currentMissing = {}\n\n    logger.info(\n      chalk.yellow(\n        `new dependencies found: ${Object.keys(newDeps).join(\n          ', '\n        )}, updating...`\n      ),\n      {\n        timestamp: true\n      }\n    )\n\n    for (const id in knownOptimized) {\n      newDeps[id] = knownOptimized[id].src\n    }\n\n    try {\n      // Nullify previous metadata so that the resolver won't\n      // resolve to optimized files during the optimizer re-run\n      server._isRunningOptimizer = true\n      server._optimizeDepsMetadata = null\n\n      const newData = (server._optimizeDepsMetadata = await optimizeDeps(\n        server.config,\n        true,\n        false,\n        newDeps,\n        ssr\n      ))\n      knownOptimized = newData!.optimized\n\n      // update ssr externals\n      server._ssrExternals = resolveSSRExternal(\n        server.config,\n        Object.keys(knownOptimized)\n      )\n\n      logger.info(\n        chalk.greenBright(`✨ dependencies updated, reloading page...`),\n        { timestamp: true }\n      )\n    } catch (e) {\n      logger.error(\n        chalk.red(`error while updating dependencies:\\n${e.stack}`),\n        { timestamp: true, error: e }\n      )\n    } finally {\n      server._isRunningOptimizer = false\n      if (!handle) {\n        // No other rerun() pending so resolve and let pending requests proceed\n        pendingResolve && pendingResolve()\n        server._pendingReload = pendingResolve = null\n      }\n    }\n\n    // Cached transform results have stale imports (resolved to\n    // old locations) so they need to be invalidated before the page is\n    // reloaded.\n    server.moduleGraph.invalidateAll()\n\n    server.ws.send({\n      type: 'full-reload',\n      path: '*'\n    })\n  }\n\n  return function registerMissingImport(\n    id: string,\n    resolved: string,\n    ssr?: boolean\n  ) {\n    if (!knownOptimized[id]) {\n      currentMissing[id] = resolved\n      if (handle) clearTimeout(handle)\n      handle = setTimeout(() => {\n        handle = undefined\n        rerun(ssr)\n      }, debounceMs)\n      if (!server._pendingReload) {\n        server._pendingReload = new Promise((r) => {\n          pendingResolve = r\n        })\n      }\n    }\n  }\n}\n","/**\n * https://github.com/rollup/plugins/blob/master/packages/json/src/index.js\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file at\n * https://github.com/rollup/plugins/blob/master/LICENSE\n */\n\nimport { dataToEsm } from '@rollup/pluginutils'\nimport { Plugin } from 'rollup'\nimport { SPECIAL_QUERY_RE } from '../constants'\n\nexport interface JsonOptions {\n  /**\n   * Generate a named export for every property of the JSON object\n   * @default true\n   */\n  namedExports?: boolean\n  /**\n   * Generate performant output as JSON.parse(\"stringified\").\n   * Enabling this will disable namedExports.\n   * @default false\n   */\n  stringify?: boolean\n}\n\n// Custom json filter for vite\nconst jsonExtRE = /\\.json($|\\?)(?!commonjs-(proxy|external))/\n\nexport function jsonPlugin(\n  options: JsonOptions = {},\n  isBuild: boolean\n): Plugin {\n  return {\n    name: 'vite:json',\n\n    transform(json, id) {\n      if (!jsonExtRE.test(id)) return null\n      if (SPECIAL_QUERY_RE.test(id)) return null\n\n      try {\n        if (options.stringify) {\n          if (isBuild) {\n            return {\n              // during build, parse then double-stringify to remove all\n              // unnecessary whitespaces to reduce bundle size.\n              code: `export default JSON.parse(${JSON.stringify(\n                JSON.stringify(JSON.parse(json))\n              )})`,\n              map: { mappings: '' }\n            }\n          } else {\n            return `export default JSON.parse(${JSON.stringify(json)})`\n          }\n        }\n\n        const parsed = JSON.parse(json)\n        return {\n          code: dataToEsm(parsed, {\n            preferConst: true,\n            namedExports: options.namedExports\n          }),\n          map: { mappings: '' }\n        }\n      } catch (e) {\n        const errorMessageList = /[\\d]+/.exec(e.message)\n        const position = errorMessageList && parseInt(errorMessageList[0], 10)\n        const msg = position\n          ? `, invalid JSON syntax found at line ${position}`\n          : `.`\n        this.error(`Failed to parse JSON file` + msg, e.idx)\n      }\n    }\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport { Plugin } from '../plugin'\nimport { ResolvedConfig } from '../config'\nimport chalk from 'chalk'\nimport MagicString from 'magic-string'\nimport { init, parse as parseImports, ImportSpecifier } from 'es-module-lexer'\nimport { isCSSRequest, isDirectCSSRequest } from './css'\nimport {\n  isBuiltin,\n  cleanUrl,\n  createDebugger,\n  generateCodeFrame,\n  injectQuery,\n  isDataUrl,\n  isExternalUrl,\n  isJSRequest,\n  prettifyUrl,\n  timeFrom,\n  normalizePath,\n  removeImportQuery,\n  unwrapId,\n  moduleListContains\n} from '../utils'\nimport {\n  debugHmr,\n  handlePrunedModules,\n  lexAcceptedHmrDeps\n} from '../server/hmr'\nimport {\n  FS_PREFIX,\n  CLIENT_DIR,\n  CLIENT_PUBLIC_PATH,\n  DEP_VERSION_RE,\n  VALID_ID_PREFIX,\n  NULL_BYTE_PLACEHOLDER\n} from '../constants'\nimport { ViteDevServer } from '..'\nimport { checkPublicFile } from './asset'\nimport { parse as parseJS } from 'acorn'\nimport type { Node } from 'estree'\nimport { transformImportGlob } from '../importGlob'\nimport { makeLegalIdentifier } from '@rollup/pluginutils'\nimport { shouldExternalizeForSSR } from '../ssr/ssrExternal'\nimport { performance } from 'perf_hooks'\nimport { transformRequest } from '../server/transformRequest'\n\nconst isDebug = !!process.env.DEBUG\nconst debug = createDebugger('vite:import-analysis')\n\nconst clientDir = normalizePath(CLIENT_DIR)\n\nconst skipRE = /\\.(map|json)$/\nconst canSkip = (id: string) => skipRE.test(id) || isDirectCSSRequest(id)\n\nfunction isExplicitImportRequired(url: string) {\n  return !isJSRequest(cleanUrl(url)) && !isCSSRequest(url)\n}\n\nfunction markExplicitImport(url: string) {\n  if (isExplicitImportRequired(url)) {\n    return injectQuery(url, 'import')\n  }\n  return url\n}\n\n/**\n * Server-only plugin that lexes, resolves, rewrites and analyzes url imports.\n *\n * - Imports are resolved to ensure they exist on disk\n *\n * - Lexes HMR accept calls and updates import relationships in the module graph\n *\n * - Bare module imports are resolved (by @rollup-plugin/node-resolve) to\n * absolute file paths, e.g.\n *\n *     ```js\n *     import 'foo'\n *     ```\n *     is rewritten to\n *     ```js\n *     import '/@fs//project/node_modules/foo/dist/foo.js'\n *     ```\n *\n * - CSS imports are appended with `.js` since both the js module and the actual\n * css (referenced via <link>) may go through the transform pipeline:\n *\n *     ```js\n *     import './style.css'\n *     ```\n *     is rewritten to\n *     ```js\n *     import './style.css.js'\n *     ```\n */\nexport function importAnalysisPlugin(config: ResolvedConfig): Plugin {\n  const { root, base } = config\n  const clientPublicPath = path.posix.join(base, CLIENT_PUBLIC_PATH)\n\n  let server: ViteDevServer\n\n  return {\n    name: 'vite:import-analysis',\n\n    configureServer(_server) {\n      server = _server\n    },\n\n    async transform(source, importer, options) {\n      const ssr = options?.ssr === true\n      const prettyImporter = prettifyUrl(importer, root)\n\n      if (canSkip(importer)) {\n        isDebug && debug(chalk.dim(`[skipped] ${prettyImporter}`))\n        return null\n      }\n\n      const start = performance.now()\n      await init\n      let imports: readonly ImportSpecifier[] = []\n      // strip UTF-8 BOM\n      if (source.charCodeAt(0) === 0xfeff) {\n        source = source.slice(1)\n      }\n      try {\n        imports = parseImports(source)[0]\n      } catch (e: any) {\n        const isVue = importer.endsWith('.vue')\n        const maybeJSX = !isVue && isJSRequest(importer)\n\n        const msg = isVue\n          ? `Install @vitejs/plugin-vue to handle .vue files.`\n          : maybeJSX\n          ? `If you are using JSX, make sure to name the file with the .jsx or .tsx extension.`\n          : `You may need to install appropriate plugins to handle the ${path.extname(\n              importer\n            )} file format.`\n\n        this.error(\n          `Failed to parse source for import analysis because the content ` +\n            `contains invalid JS syntax. ` +\n            msg,\n          e.idx\n        )\n      }\n\n      if (!imports.length) {\n        isDebug &&\n          debug(\n            `${timeFrom(start)} ${chalk.dim(`[no imports] ${prettyImporter}`)}`\n          )\n        return source\n      }\n\n      let hasHMR = false\n      let isSelfAccepting = false\n      let hasEnv = false\n      let needQueryInjectHelper = false\n      let s: MagicString | undefined\n      const str = () => s || (s = new MagicString(source))\n      // vite-only server context\n      const { moduleGraph } = server\n      // since we are already in the transform phase of the importer, it must\n      // have been loaded so its entry is guaranteed in the module graph.\n      const importerModule = moduleGraph.getModuleById(importer)!\n      const importedUrls = new Set<string>()\n      const staticImportedUrls = new Set<string>()\n      const acceptedUrls = new Set<{\n        url: string\n        start: number\n        end: number\n      }>()\n      const toAbsoluteUrl = (url: string) =>\n        path.posix.resolve(path.posix.dirname(importerModule.url), url)\n\n      const normalizeUrl = async (\n        url: string,\n        pos: number\n      ): Promise<[string, string]> => {\n        if (base !== '/' && url.startsWith(base)) {\n          url = url.replace(base, '/')\n        }\n\n        let importerFile = importer\n        if (\n          moduleListContains(config.optimizeDeps?.exclude, url) &&\n          server._optimizeDepsMetadata\n        ) {\n          // if the dependency encountered in the optimized file was excluded from the optimization\n          // the dependency needs to be resolved starting from the original source location of the optimized file\n          // because starting from node_modules/.vite will not find the dependency if it was not hoisted\n          // (that is, if it is under node_modules directory in the package source of the optimized file)\n          for (const optimizedModule of Object.values(\n            server._optimizeDepsMetadata.optimized\n          )) {\n            if (optimizedModule.file === importerModule.file) {\n              importerFile = optimizedModule.src\n            }\n          }\n        }\n\n        const resolved = await this.resolve(url, importerFile)\n\n        if (!resolved) {\n          this.error(\n            `Failed to resolve import \"${url}\" from \"${path.relative(\n              process.cwd(),\n              importerFile\n            )}\". Does the file exist?`,\n            pos\n          )\n        }\n\n        const isRelative = url.startsWith('.')\n        const isSelfImport = !isRelative && cleanUrl(url) === cleanUrl(importer)\n\n        // normalize all imports into resolved URLs\n        // e.g. `import 'foo'` -> `import '/@fs/.../node_modules/foo/index.js`\n        if (resolved.id.startsWith(root + '/')) {\n          // in root: infer short absolute path from root\n          url = resolved.id.slice(root.length)\n        } else if (fs.existsSync(cleanUrl(resolved.id))) {\n          // exists but out of root: rewrite to absolute /@fs/ paths\n          url = path.posix.join(FS_PREFIX + resolved.id)\n        } else {\n          url = resolved.id\n        }\n\n        if (isExternalUrl(url)) {\n          return [url, url]\n        }\n\n        // if the resolved id is not a valid browser import specifier,\n        // prefix it to make it valid. We will strip this before feeding it\n        // back into the transform pipeline\n        if (!url.startsWith('.') && !url.startsWith('/')) {\n          url =\n            VALID_ID_PREFIX + resolved.id.replace('\\0', NULL_BYTE_PLACEHOLDER)\n        }\n\n        // make the URL browser-valid if not SSR\n        if (!ssr) {\n          // mark non-js/css imports with `?import`\n          url = markExplicitImport(url)\n\n          // for relative js/css imports, or self-module virtual imports\n          // (e.g. vue blocks), inherit importer's version query\n          // do not do this for unknown type imports, otherwise the appended\n          // query can break 3rd party plugin's extension checks.\n          if ((isRelative || isSelfImport) && !/[\\?&]import=?\\b/.test(url)) {\n            const versionMatch = importer.match(DEP_VERSION_RE)\n            if (versionMatch) {\n              url = injectQuery(url, versionMatch[1])\n            }\n          }\n\n          // check if the dep has been hmr updated. If yes, we need to attach\n          // its last updated timestamp to force the browser to fetch the most\n          // up-to-date version of this module.\n          try {\n            const depModule = await moduleGraph.ensureEntryFromUrl(url, ssr)\n            if (depModule.lastHMRTimestamp > 0) {\n              url = injectQuery(url, `t=${depModule.lastHMRTimestamp}`)\n            }\n          } catch (e: any) {\n            // it's possible that the dep fails to resolve (non-existent import)\n            // attach location to the missing import\n            e.pos = pos\n            throw e\n          }\n\n          // prepend base (dev base is guaranteed to have ending slash)\n          url = base + url.replace(/^\\//, '')\n        }\n\n        return [url, resolved.id]\n      }\n\n      for (let index = 0; index < imports.length; index++) {\n        const {\n          s: start,\n          e: end,\n          ss: expStart,\n          se: expEnd,\n          d: dynamicIndex,\n          // #2083 User may use escape path,\n          // so use imports[index].n to get the unescaped string\n          // @ts-ignore\n          n: specifier\n        } = imports[index]\n\n        const rawUrl = source.slice(start, end)\n\n        // check import.meta usage\n        if (rawUrl === 'import.meta') {\n          const prop = source.slice(end, end + 4)\n          if (prop === '.hot') {\n            hasHMR = true\n            if (source.slice(end + 4, end + 11) === '.accept') {\n              // further analyze accepted modules\n              if (\n                lexAcceptedHmrDeps(\n                  source,\n                  source.indexOf('(', end + 11) + 1,\n                  acceptedUrls\n                )\n              ) {\n                isSelfAccepting = true\n              }\n            }\n          } else if (prop === '.env') {\n            hasEnv = true\n          } else if (prop === '.glo' && source[end + 4] === 'b') {\n            // transform import.meta.glob()\n            // e.g. `import.meta.glob('glob:./dir/*.js')`\n            const {\n              imports,\n              importsString,\n              exp,\n              endIndex,\n              base,\n              pattern,\n              isEager\n            } = await transformImportGlob(\n              source,\n              start,\n              importer,\n              index,\n              root,\n              normalizeUrl\n            )\n            str().prepend(importsString)\n            str().overwrite(expStart, endIndex, exp)\n            imports.forEach((url) => {\n              url = url.replace(base, '/')\n              importedUrls.add(url)\n              if (isEager) staticImportedUrls.add(url)\n            })\n            if (!(importerModule.file! in server._globImporters)) {\n              server._globImporters[importerModule.file!] = {\n                module: importerModule,\n                importGlobs: []\n              }\n            }\n            server._globImporters[importerModule.file!].importGlobs.push({\n              base,\n              pattern\n            })\n          }\n          continue\n        }\n\n        const isDynamicImport = dynamicIndex >= 0\n\n        // static import or valid string in dynamic import\n        // If resolvable, let's resolve it\n        if (specifier) {\n          // skip external / data uri\n          // BROWSER VITE patch: support URL resolve in build mode\n          if (/*isExternalUrl(specifier) || */ isDataUrl(specifier)) {\n            continue\n          }\n          // skip ssr external\n          if (ssr) {\n            if (\n              server._ssrExternals &&\n              shouldExternalizeForSSR(specifier, server._ssrExternals)\n            ) {\n              continue\n            }\n            if (isBuiltin(specifier)) {\n              continue\n            }\n          }\n          // skip client\n          if (specifier === clientPublicPath) {\n            continue\n          }\n\n          // warn imports to non-asset /public files\n          if (\n            specifier.startsWith('/') &&\n            !config.assetsInclude(cleanUrl(specifier)) &&\n            !specifier.endsWith('.json') &&\n            checkPublicFile(specifier, config)\n          ) {\n            throw new Error(\n              `Cannot import non-asset file ${specifier} which is inside /public.` +\n                `JS/CSS files inside /public are copied as-is on build and ` +\n                `can only be referenced via <script src> or <link href> in html.`\n            )\n          }\n\n          // normalize\n          const [normalizedUrl, resolvedId] = await normalizeUrl(\n            specifier,\n            start\n          )\n          let url = normalizedUrl\n\n          // record as safe modules\n          server?.moduleGraph.safeModulesPath.add(\n            cleanUrl(url).slice(4 /* '/@fs'.length */)\n          )\n\n          // rewrite\n          if (url !== specifier) {\n            // for optimized cjs deps, support named imports by rewriting named\n            // imports to const assignments.\n            if (resolvedId.endsWith(`&es-interop`)) {\n              url = url.slice(0, -11)\n              if (isDynamicImport) {\n                // rewrite `import('package')` to expose the default directly\n                str().overwrite(\n                  dynamicIndex,\n                  end + 1,\n                  `import('${url}').then(m => m.default && m.default.__esModule ? m.default : ({ ...m.default, default: m.default }))`\n                )\n              } else {\n                const exp = source.slice(expStart, expEnd)\n                const rewritten = transformCjsImport(exp, url, rawUrl, index)\n                if (rewritten) {\n                  str().overwrite(expStart, expEnd, rewritten)\n                } else {\n                  // #1439 export * from '...'\n                  str().overwrite(start, end, url)\n                }\n              }\n            } else {\n              str().overwrite(start, end, isDynamicImport ? `'${url}'` : url)\n            }\n          }\n\n          // record for HMR import chain analysis\n          // make sure to normalize away base\n          const urlWithoutBase = url.replace(base, '/')\n          importedUrls.add(urlWithoutBase)\n          if (!isDynamicImport) {\n            // for pre-transforming\n            staticImportedUrls.add(urlWithoutBase)\n          }\n        } else if (!importer.startsWith(clientDir) && !ssr) {\n          // check @vite-ignore which suppresses dynamic import warning\n          const hasViteIgnore = /\\/\\*\\s*@vite-ignore\\s*\\*\\//.test(rawUrl)\n\n          const url = rawUrl\n            .replace(/\\/\\*[\\s\\S]*?\\*\\/|([^\\\\:]|^)\\/\\/.*$/gm, '')\n            .trim()\n          if (!hasViteIgnore && !isSupportedDynamicImport(url)) {\n            this.warn(\n              `\\n` +\n                chalk.cyan(importerModule.file) +\n                `\\n` +\n                generateCodeFrame(source, start) +\n                `\\nThe above dynamic import cannot be analyzed by vite.\\n` +\n                `See ${chalk.blue(\n                  `https://github.com/rollup/plugins/tree/master/packages/dynamic-import-vars#limitations`\n                )} ` +\n                `for supported dynamic import formats. ` +\n                `If this is intended to be left as-is, you can use the ` +\n                `/* @vite-ignore */ comment inside the import() call to suppress this warning.\\n`\n            )\n          }\n          if (\n            !/^('.*'|\".*\"|`.*`)$/.test(url) ||\n            isExplicitImportRequired(url.slice(1, -1))\n          ) {\n            needQueryInjectHelper = true\n            str().overwrite(start, end, `__vite__injectQuery(${url}, 'import')`)\n          }\n        }\n      }\n\n      if (hasEnv) {\n        // inject import.meta.env\n        let env = `import.meta.env = ${JSON.stringify({\n          ...config.env,\n          SSR: !!ssr\n        })};`\n        // account for user env defines\n        for (const key in config.define) {\n          if (key.startsWith(`import.meta.env.`)) {\n            const val = config.define[key]\n            env += `${key} = ${\n              typeof val === 'string' ? val : JSON.stringify(val)\n            };`\n          }\n        }\n        str().prepend(env)\n      }\n\n      if (hasHMR && !ssr) {\n        debugHmr(\n          `${\n            isSelfAccepting\n              ? `[self-accepts]`\n              : acceptedUrls.size\n              ? `[accepts-deps]`\n              : `[detected api usage]`\n          } ${prettyImporter}`\n        )\n        // inject hot context\n        str().prepend(\n          `import { createHotContext as __vite__createHotContext } from \"${clientPublicPath}\";` +\n            `import.meta.hot = __vite__createHotContext(${JSON.stringify(\n              importerModule.url\n            )});`\n        )\n      }\n\n      if (needQueryInjectHelper) {\n        str().prepend(\n          `import { injectQuery as __vite__injectQuery } from \"${clientPublicPath}\";`\n        )\n      }\n\n      // normalize and rewrite accepted urls\n      const normalizedAcceptedUrls = new Set<string>()\n      for (const { url, start, end } of acceptedUrls) {\n        const [normalized] = await moduleGraph.resolveUrl(\n          toAbsoluteUrl(markExplicitImport(url)),\n          ssr\n        )\n        normalizedAcceptedUrls.add(normalized)\n        str().overwrite(start, end, JSON.stringify(normalized))\n      }\n\n      // update the module graph for HMR analysis.\n      // node CSS imports does its own graph update in the css plugin so we\n      // only handle js graph updates here.\n      if (!isCSSRequest(importer)) {\n        // attached by pluginContainer.addWatchFile\n        const pluginImports = (this as any)._addedImports as\n          | Set<string>\n          | undefined\n        if (pluginImports) {\n          ;(\n            await Promise.all(\n              [...pluginImports].map((id) => normalizeUrl(id, 0))\n            )\n          ).forEach(([url]) => importedUrls.add(url))\n        }\n        // HMR transforms are no-ops in SSR, so an `accept` call will\n        // never be injected. Avoid updating the `isSelfAccepting`\n        // property for our module node in that case.\n        if (ssr && importerModule.isSelfAccepting) {\n          isSelfAccepting = true\n        }\n        const prunedImports = await moduleGraph.updateModuleInfo(\n          importerModule,\n          importedUrls,\n          normalizedAcceptedUrls,\n          isSelfAccepting,\n          ssr\n        )\n        if (hasHMR && prunedImports) {\n          handlePrunedModules(prunedImports, server)\n        }\n      }\n\n      isDebug &&\n        debug(\n          `${timeFrom(start)} ${chalk.dim(\n            `[${importedUrls.size} imports rewritten] ${prettyImporter}`\n          )}`\n        )\n\n      // pre-transform known direct imports\n      if (staticImportedUrls.size) {\n        staticImportedUrls.forEach((url) => {\n          transformRequest(unwrapId(removeImportQuery(url)), server, { ssr })\n        })\n      }\n\n      if (s) {\n        return s.toString()\n      } else {\n        return source\n      }\n    }\n  }\n}\n\n/**\n * https://github.com/rollup/plugins/tree/master/packages/dynamic-import-vars#limitations\n * This is probably less accurate but is much cheaper than a full AST parse.\n */\nfunction isSupportedDynamicImport(url: string) {\n  url = url.trim().slice(1, -1)\n  // must be relative\n  if (!url.startsWith('./') && !url.startsWith('../')) {\n    return false\n  }\n  // must have extension\n  if (!path.extname(url)) {\n    return false\n  }\n  // must be more specific if importing from same dir\n  if (url.startsWith('./${') && url.indexOf('/') === url.lastIndexOf('/')) {\n    return false\n  }\n  return true\n}\n\ntype ImportNameSpecifier = { importedName: string; localName: string }\n\n/**\n * Detect import statements to a known optimized CJS dependency and provide\n * ES named imports interop. We do this by rewriting named imports to a variable\n * assignment to the corresponding property on the `module.exports` of the cjs\n * module. Note this doesn't support dynamic re-assignments from within the cjs\n * module.\n *\n * Note that es-module-lexer treats `export * from '...'` as an import as well,\n * so, we may encounter ExportAllDeclaration here, in which case `undefined`\n * will be returned.\n *\n * Credits \\@csr632 via #837\n */\nexport function transformCjsImport(\n  importExp: string,\n  url: string,\n  rawUrl: string,\n  importIndex: number\n): string | undefined {\n  const node = (\n    parseJS(importExp, {\n      ecmaVersion: 'latest',\n      sourceType: 'module'\n    }) as any\n  ).body[0] as Node\n\n  if (\n    node.type === 'ImportDeclaration' ||\n    node.type === 'ExportNamedDeclaration'\n  ) {\n    if (!node.specifiers.length) {\n      return `import \"${url}\"`\n    }\n\n    const importNames: ImportNameSpecifier[] = []\n    const exportNames: string[] = []\n    let defaultExports: string = ''\n    for (const spec of node.specifiers) {\n      if (\n        spec.type === 'ImportSpecifier' &&\n        spec.imported.type === 'Identifier'\n      ) {\n        const importedName = spec.imported.name\n        const localName = spec.local.name\n        importNames.push({ importedName, localName })\n      } else if (spec.type === 'ImportDefaultSpecifier') {\n        importNames.push({\n          importedName: 'default',\n          localName: spec.local.name\n        })\n      } else if (spec.type === 'ImportNamespaceSpecifier') {\n        importNames.push({ importedName: '*', localName: spec.local.name })\n      } else if (\n        spec.type === 'ExportSpecifier' &&\n        spec.exported.type === 'Identifier'\n      ) {\n        // for ExportSpecifier, local name is same as imported name\n        const importedName = spec.local.name\n        // we want to specify exported name as variable and re-export it\n        const exportedName = spec.exported.name\n        if (exportedName === 'default') {\n          defaultExports = makeLegalIdentifier(\n            `__vite__cjsExportDefault_${importIndex}`\n          )\n          importNames.push({ importedName, localName: defaultExports })\n        } else {\n          importNames.push({ importedName, localName: exportedName })\n          exportNames.push(exportedName)\n        }\n      }\n    }\n\n    // If there is multiple import for same id in one file,\n    // importIndex will prevent the cjsModuleName to be duplicate\n    const cjsModuleName = makeLegalIdentifier(\n      `__vite__cjsImport${importIndex}_${rawUrl}`\n    )\n    const lines: string[] = [`import ${cjsModuleName} from \"${url}\"`]\n    importNames.forEach(({ importedName, localName }) => {\n      if (importedName === '*') {\n        lines.push(`const ${localName} = ${cjsModuleName}`)\n      } else if (importedName === 'default') {\n        lines.push(\n          `const ${localName} = ${cjsModuleName}.__esModule ? ${cjsModuleName}.default : ${cjsModuleName}`\n        )\n      } else {\n        lines.push(`const ${localName} = ${cjsModuleName}[\"${importedName}\"]`)\n      }\n    })\n    if (defaultExports) {\n      lines.push(`export default ${defaultExports}`)\n    }\n    if (exportNames.length) {\n      lines.push(`export { ${exportNames.join(', ')} }`)\n    }\n\n    return lines.join('; ')\n  }\n}\n","import path from 'path'\nimport { Plugin } from '../plugin'\nimport { ResolvedConfig } from '../config'\nimport { CLIENT_ENTRY, ENV_ENTRY } from '../constants'\nimport { normalizePath, isObject } from '../utils'\n\n// ids in transform are normalized to unix style\nconst normalizedClientEntry = normalizePath(CLIENT_ENTRY)\nconst normalizedEnvEntry = normalizePath(ENV_ENTRY)\n\n/**\n * some values used by the client needs to be dynamically injected by the server\n * @server-only\n */\nexport function clientInjectionsPlugin(config: ResolvedConfig): Plugin {\n  return {\n    name: 'vite:client-inject',\n    transform(code, id) {\n      if (id === normalizedClientEntry || id === normalizedEnvEntry) {\n        let options = config.server.hmr\n        options = options && typeof options !== 'boolean' ? options : {}\n        const host = options.host || null\n        const protocol = options.protocol || null\n        const timeout = options.timeout || 30000\n        const overlay = options.overlay !== false\n        let port: number | string | undefined\n        if (isObject(config.server.hmr)) {\n          port = config.server.hmr.clientPort || config.server.hmr.port\n        }\n        if (config.server.middlewareMode) {\n          port = String(port || 24678)\n        } else {\n          port = String(port || options.port || config.server.port!)\n        }\n        let hmrBase = config.base\n        if (options.path) {\n          hmrBase = path.posix.join(hmrBase, options.path)\n        }\n        if (hmrBase !== '/') {\n          port = path.posix.normalize(`${port}${hmrBase}`)\n        }\n\n        return code\n          .replace(`__MODE__`, JSON.stringify(config.mode))\n          .replace(`__BASE__`, JSON.stringify(config.base))\n          .replace(`__DEFINES__`, serializeDefine(config.define || {}))\n          .replace(`__HMR_PROTOCOL__`, JSON.stringify(protocol))\n          .replace(`__HMR_HOSTNAME__`, JSON.stringify(host))\n          .replace(`__HMR_PORT__`, JSON.stringify(port))\n          .replace(`__HMR_TIMEOUT__`, JSON.stringify(timeout))\n          .replace(`__HMR_ENABLE_OVERLAY__`, JSON.stringify(overlay))\n      } else if (code.includes('process.env.NODE_ENV')) {\n        // replace process.env.NODE_ENV\n        return code.replace(\n          /\\bprocess\\.env\\.NODE_ENV\\b/g,\n          JSON.stringify(config.mode)\n        )\n      }\n    }\n  }\n}\n\nfunction serializeDefine(define: Record<string, any>): string {\n  let res = `{`\n  for (const key in define) {\n    const val = define[key]\n    res += `${JSON.stringify(key)}: ${\n      typeof val === 'string' ? `(${val})` : JSON.stringify(val)\n    }, `\n  }\n  return res + `}`\n}\n","import { ResolvedConfig } from '../config'\nimport { Plugin } from '../plugin'\nimport { fileToUrl } from './asset'\n\nconst wasmHelperId = '/__vite-wasm-helper'\n\nconst wasmHelper = async (opts = {}, url: string) => {\n  let result\n  if (url.startsWith('data:')) {\n    // @ts-ignore\n    const binaryString = atob(url.replace(/^data:.*?base64,/, ''))\n    const bytes = new Uint8Array(binaryString.length)\n    for (let i = 0; i < binaryString.length; i++) {\n      bytes[i] = binaryString.charCodeAt(i)\n    }\n    // @ts-ignore\n    result = await WebAssembly.instantiate(bytes, opts)\n  } else {\n    // https://github.com/mdn/webassembly-examples/issues/5\n    // WebAssembly.instantiateStreaming requires the server to provide the\n    // correct MIME type for .wasm files, which unfortunately doesn't work for\n    // a lot of static file servers, so we just work around it by getting the\n    // raw buffer.\n    // @ts-ignore\n    const response = await fetch(url)\n    const contentType = response.headers.get('Content-Type') || ''\n    if (\n      // @ts-ignore\n      'instantiateStreaming' in WebAssembly &&\n      contentType.startsWith('application/wasm')\n    ) {\n      // @ts-ignore\n      result = await WebAssembly.instantiateStreaming(response, opts)\n    } else {\n      const buffer = await response.arrayBuffer()\n      // @ts-ignore\n      result = await WebAssembly.instantiate(buffer, opts)\n    }\n  }\n  return result.instance.exports\n}\n\nconst wasmHelperCode = wasmHelper.toString()\n\nexport const wasmPlugin = (config: ResolvedConfig): Plugin => {\n  return {\n    name: 'vite:wasm',\n\n    resolveId(id) {\n      if (id === wasmHelperId) {\n        return id\n      }\n    },\n\n    async load(id) {\n      if (id === wasmHelperId) {\n        return `export default ${wasmHelperCode}`\n      }\n\n      if (!id.endsWith('.wasm')) {\n        return\n      }\n\n      const url = await fileToUrl(id, config, this)\n\n      return `\nimport initWasm from \"${wasmHelperId}\"\nexport default opts => initWasm(opts, ${JSON.stringify(url)})\n`\n    }\n  }\n}\n","import MagicString from 'magic-string'\nimport { TransformResult } from 'rollup'\nimport { ResolvedConfig } from '../config'\nimport { Plugin } from '../plugin'\nimport { isCSSRequest } from './css'\n\nexport function definePlugin(config: ResolvedConfig): Plugin {\n  const isBuild = config.command === 'build'\n\n  const processNodeEnv: Record<string, string> = {\n    'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV || config.mode),\n    'global.process.env.NODE_ENV': JSON.stringify(\n      process.env.NODE_ENV || config.mode\n    ),\n    'globalThis.process.env.NODE_ENV': JSON.stringify(\n      process.env.NODE_ENV || config.mode\n    )\n  }\n\n  const userDefine: Record<string, string> = {}\n  for (const key in config.define) {\n    const val = config.define[key]\n    userDefine[key] = typeof val === 'string' ? val : JSON.stringify(val)\n  }\n\n  // during dev, import.meta properties are handled by importAnalysis plugin\n  const importMetaKeys: Record<string, string> = {}\n  if (isBuild) {\n    const env: Record<string, any> = {\n      ...config.env,\n      SSR: !!config.build.ssr\n    }\n    for (const key in env) {\n      importMetaKeys[`import.meta.env.${key}`] = JSON.stringify(env[key])\n    }\n    Object.assign(importMetaKeys, {\n      'import.meta.env.': `({}).`,\n      'import.meta.env': JSON.stringify(config.env),\n      'import.meta.hot': `false`\n    })\n  }\n\n  function generatePattern(\n    ssr: boolean\n  ): [Record<string, string | undefined>, RegExp] {\n    const processEnv: Record<string, string> = {}\n    if (!ssr || config.ssr?.target === 'webworker') {\n      Object.assign(processEnv, {\n        'process.env.': `({}).`,\n        'global.process.env.': `({}).`,\n        'globalThis.process.env.': `({}).`\n      })\n    }\n\n    const replacements: Record<string, string> = {\n      ...processNodeEnv,\n      ...userDefine,\n      ...importMetaKeys,\n      ...processEnv\n    }\n\n    const pattern = new RegExp(\n      // Do not allow preceding '.', but do allow preceding '...' for spread operations\n      // BROWSER VITE patch: no lookbehind for safari support\n      '(^|[^\\\\.]|\\\\.\\\\.\\\\.)\\\\b(' +\n        Object.keys(replacements)\n          .map((str) => {\n            return str.replace(/[-[\\]/{}()*+?.\\\\^$|]/g, '\\\\$&')\n          })\n          .join('|') +\n        ')\\\\b',\n      'g'\n    )\n\n    return [replacements, pattern]\n  }\n\n  const defaultPattern = generatePattern(false)\n  const ssrPattern = generatePattern(true)\n\n  return {\n    name: 'vite:define',\n    transform(code, id, options) {\n      const ssr = options?.ssr === true\n      if (!ssr && !isBuild) {\n        // for dev we inject actual global defines in the vite client to\n        // avoid the transform cost.\n        return\n      }\n\n      if (\n        // exclude css and static assets for performance\n        isCSSRequest(id) ||\n        config.assetsInclude(id)\n      ) {\n        return\n      }\n\n      const [replacements, pattern] = ssr ? ssrPattern : defaultPattern\n\n      if (ssr && !isBuild) {\n        // ssr + dev, simple replace\n        return code.replace(pattern, (_, prefix, match) => {\n          return prefix + replacements[match]\n        })\n      }\n\n      const s = new MagicString(code)\n      let hasReplaced = false\n      let match: RegExpExecArray | null\n\n      while ((match = pattern.exec(code))) {\n        hasReplaced = true\n        const start = match.index+match[1].length\n        const end = start + match[2].length\n        const replacement = '' + replacements[match[2]]\n        s.overwrite(start, end, replacement)\n      }\n\n      if (!hasReplaced) {\n        return null\n      }\n\n      const result: TransformResult = { code: s.toString() }\n      if (config.build.sourcemap) {\n        result.map = s.generateMap({ hires: true })\n      }\n      return result\n    }\n  }\n}\n","import fs from 'fs'\nimport path from 'path'\nimport { Plugin } from './plugin'\nimport { BuildOptions, resolveBuildOptions } from './build'\nimport {\n  ResolvedServerOptions,\n  resolveServerOptions,\n  ServerOptions\n} from './server'\nimport {\n  ResolvedPreviewOptions,\n  resolvePreviewOptions,\n  PreviewOptions\n} from './preview'\nimport { CSSOptions } from './plugins/css'\nimport {\n  arraify,\n  createDebugger,\n  isExternalUrl,\n  isObject,\n  lookupFile,\n  normalizePath,\n  dynamicImport\n} from './utils'\nimport { resolvePlugins } from './plugins'\nimport chalk from 'chalk'\nimport { ESBuildOptions } from './plugins/esbuild'\nimport dotenv from 'dotenv'\nimport dotenvExpand from 'dotenv-expand'\nimport { Alias, AliasOptions } from 'types/alias'\nimport { CLIENT_ENTRY, ENV_ENTRY, DEFAULT_ASSETS_RE } from './constants'\nimport {\n  InternalResolveOptions,\n  ResolveOptions,\n  resolvePlugin\n} from './plugins/resolve'\nimport { createLogger, Logger, LogLevel } from './logger'\nimport { DepOptimizationOptions } from './optimizer'\nimport { createFilter } from '@rollup/pluginutils'\nimport { ResolvedBuildOptions } from '.'\nimport { parse as parseUrl } from 'url'\nimport { JsonOptions } from './plugins/json'\nimport {\n  createPluginContainer,\n  PluginContainer\n} from './server/pluginContainer'\nimport aliasPlugin from '@rollup/plugin-alias'\nimport { build } from 'esbuild'\nimport { performance } from 'perf_hooks'\nimport { PackageCache } from './packages'\n\nconst debug = createDebugger('vite:config')\n\n// NOTE: every export in this file is re-exported from ./index.ts so it will\n// be part of the public API.\nexport interface ConfigEnv {\n  command: 'build' | 'serve'\n  mode: string\n}\n\nexport type UserConfigFn = (env: ConfigEnv) => UserConfig | Promise<UserConfig>\nexport type UserConfigExport = UserConfig | Promise<UserConfig> | UserConfigFn\n\n/**\n * Type helper to make it easier to use vite.config.ts\n * accepts a direct {@link UserConfig} object, or a function that returns it.\n * The function receives a {@link ConfigEnv} object that exposes two properties:\n * `command` (either `'build'` or `'serve'`), and `mode`.\n */\nexport function defineConfig(config: UserConfigExport): UserConfigExport {\n  return config\n}\n\nexport type PluginOption = Plugin | false | null | undefined\n\nexport interface UserConfig {\n  /**\n   * Project root directory. Can be an absolute path, or a path relative from\n   * the location of the config file itself.\n   * @default process.cwd()\n   */\n  root?: string\n  /**\n   * Base public path when served in development or production.\n   * @default '/'\n   */\n  base?: string\n  /**\n   * Directory to serve as plain static assets. Files in this directory are\n   * served and copied to build dist dir as-is without transform. The value\n   * can be either an absolute file system path or a path relative to <root>.\n   *\n   * Set to `false` or an empty string to disable copied static assets to build dist dir.\n   * @default 'public'\n   */\n  publicDir?: string | false\n  /**\n   * Directory to save cache files. Files in this directory are pre-bundled\n   * deps or some other cache files that generated by vite, which can improve\n   * the performance. You can use `--force` flag or manually delete the directory\n   * to regenerate the cache files. The value can be either an absolute file\n   * system path or a path relative to <root>.\n   * @default 'node_modules/.vite'\n   */\n  cacheDir?: string\n  /**\n   * Explicitly set a mode to run in. This will override the default mode for\n   * each command, and can be overridden by the command line --mode option.\n   */\n  mode?: string\n  /**\n   * Define global variable replacements.\n   * Entries will be defined on `window` during dev and replaced during build.\n   */\n  define?: Record<string, any>\n  /**\n   * Array of vite plugins to use.\n   */\n  plugins?: (PluginOption | PluginOption[])[]\n  /**\n   * Configure resolver\n   */\n  resolve?: ResolveOptions & { alias?: AliasOptions }\n  /**\n   * CSS related options (preprocessors and CSS modules)\n   */\n  css?: CSSOptions\n  /**\n   * JSON loading options\n   */\n  json?: JsonOptions\n  /**\n   * Transform options to pass to esbuild.\n   * Or set to `false` to disable esbuild.\n   */\n  esbuild?: ESBuildOptions | false\n  /**\n   * Specify additional picomatch patterns to be treated as static assets.\n   */\n  assetsInclude?: string | RegExp | (string | RegExp)[]\n  /**\n   * Server specific options, e.g. host, port, https...\n   */\n  server?: ServerOptions\n  /**\n   * Build specific options\n   */\n  build?: BuildOptions\n  /**\n   * Preview specific options, e.g. host, port, https...\n   */\n  preview?: PreviewOptions\n  /**\n   * Dep optimization options\n   */\n  optimizeDeps?: DepOptimizationOptions\n  /**\n   * SSR specific options\n   * @alpha\n   */\n  ssr?: SSROptions\n  /**\n   * Log level.\n   * Default: 'info'\n   */\n  logLevel?: LogLevel\n  /**\n   * Custom logger.\n   */\n  customLogger?: Logger\n  /**\n   * Default: true\n   */\n  clearScreen?: boolean\n  /**\n   * Environment files directory. Can be an absolute path, or a path relative from\n   * the location of the config file itself.\n   * @default root\n   */\n  envDir?: string\n  /**\n   * Env variables starts with `envPrefix` will be exposed to your client source code via import.meta.env.\n   * @default 'VITE_'\n   */\n  envPrefix?: string | string[]\n  /**\n   * Import aliases\n   * @deprecated use `resolve.alias` instead\n   */\n  alias?: AliasOptions\n  /**\n   * Force Vite to always resolve listed dependencies to the same copy (from\n   * project root).\n   * @deprecated use `resolve.dedupe` instead\n   */\n  dedupe?: string[]\n}\n\nexport type SSRTarget = 'node' | 'webworker'\n\nexport interface SSROptions {\n  external?: string[]\n  noExternal?: string | RegExp | (string | RegExp)[] | true\n  /**\n   * Define the target for the ssr build. The browser field in package.json\n   * is ignored for node but used if webworker is the target\n   * Default: 'node'\n   */\n  target?: SSRTarget\n}\n\nexport interface InlineConfig extends UserConfig {\n  configFile?: string | false\n  envFile?: false\n}\n\nexport type ResolvedConfig = Readonly<\n  Omit<\n    UserConfig,\n    'plugins' | 'alias' | 'dedupe' | 'assetsInclude' | 'optimizeDeps'\n  > & {\n    configFile: string | undefined\n    configFileDependencies: string[]\n    inlineConfig: InlineConfig\n    root: string\n    base: string\n    publicDir: string\n    command: 'build' | 'serve'\n    mode: string\n    isProduction: boolean\n    env: Record<string, any>\n    resolve: ResolveOptions & {\n      alias: Alias[]\n    }\n    plugins: readonly Plugin[]\n    server: ResolvedServerOptions\n    build: ResolvedBuildOptions\n    preview: ResolvedPreviewOptions\n    assetsInclude: (file: string) => boolean\n    logger: Logger\n    createResolver: (options?: Partial<InternalResolveOptions>) => ResolveFn\n    optimizeDeps: Omit<DepOptimizationOptions, 'keepNames'>\n    /** @internal */\n    packageCache: PackageCache\n  }\n>\n\nexport type ResolveFn = (\n  id: string,\n  importer?: string,\n  aliasOnly?: boolean,\n  ssr?: boolean\n) => Promise<string | undefined>\n\nexport async function resolveConfig(\n  inlineConfig: InlineConfig,\n  command: 'build' | 'serve',\n  defaultMode = 'development'\n): Promise<ResolvedConfig> {\n  let config = inlineConfig\n  let configFileDependencies: string[] = []\n  let mode = inlineConfig.mode || defaultMode\n\n  // some dependencies e.g. @vue/compiler-* relies on NODE_ENV for getting\n  // production-specific behavior, so set it here even though we haven't\n  // resolve the final mode yet\n  if (mode === 'production') {\n    process.env.NODE_ENV = 'production'\n  }\n\n  const configEnv = {\n    mode,\n    command\n  }\n\n  let { configFile } = config\n  if (configFile !== false) {\n    const loadResult = await loadConfigFromFile(\n      configEnv,\n      configFile,\n      config.root,\n      config.logLevel\n    )\n    if (loadResult) {\n      config = mergeConfig(loadResult.config, config)\n      configFile = loadResult.path\n      configFileDependencies = loadResult.dependencies\n    }\n  }\n\n  // Define logger\n  const logger = createLogger(config.logLevel, {\n    allowClearScreen: config.clearScreen,\n    customLogger: config.customLogger\n  })\n\n  // user config may provide an alternative mode. But --mode has a higher priority\n  mode = inlineConfig.mode || config.mode || mode\n  configEnv.mode = mode\n\n  // resolve plugins\n  const rawUserPlugins = (config.plugins || []).flat().filter((p) => {\n    if (!p) {\n      return false\n    } else if (!p.apply) {\n      return true\n    } else if (typeof p.apply === 'function') {\n      return p.apply({ ...config, mode }, configEnv)\n    } else {\n      return p.apply === command\n    }\n  }) as Plugin[]\n  const [prePlugins, normalPlugins, postPlugins] =\n    sortUserPlugins(rawUserPlugins)\n\n  // run config hooks\n  const userPlugins = [...prePlugins, ...normalPlugins, ...postPlugins]\n  for (const p of userPlugins) {\n    if (p.config) {\n      const res = await p.config(config, configEnv)\n      if (res) {\n        config = mergeConfig(config, res)\n      }\n    }\n  }\n\n  // resolve root\n  const resolvedRoot = normalizePath(\n    config.root ? path.resolve(config.root) : process.cwd()\n  )\n\n  const clientAlias = [\n    { find: /^[\\/]?@vite\\/env/, replacement: () => ENV_ENTRY },\n    { find: /^[\\/]?@vite\\/client/, replacement: () => CLIENT_ENTRY }\n  ]\n\n  // resolve alias with internal client alias\n  const resolvedAlias = mergeAlias(\n    // @ts-ignore because @rollup/plugin-alias' type doesn't allow function\n    // replacement, but its implementation does work with function values.\n    clientAlias,\n    config.resolve?.alias || config.alias || []\n  )\n\n  const resolveOptions: ResolvedConfig['resolve'] = {\n    dedupe: config.dedupe,\n    ...config.resolve,\n    alias: resolvedAlias\n  }\n\n  // load .env files\n  const envDir = config.envDir\n    ? normalizePath(path.resolve(resolvedRoot, config.envDir))\n    : resolvedRoot\n  const userEnv =\n    inlineConfig.envFile !== false &&\n    loadEnv(mode, envDir, resolveEnvPrefix(config))\n\n  // Note it is possible for user to have a custom mode, e.g. `staging` where\n  // production-like behavior is expected. This is indicated by NODE_ENV=production\n  // loaded from `.staging.env` and set by us as VITE_USER_NODE_ENV\n  const isProduction = (process.env.VITE_USER_NODE_ENV || mode) === 'production'\n  if (isProduction) {\n    // in case default mode was not production and is overwritten\n    process.env.NODE_ENV = 'production'\n  }\n\n  // resolve public base url\n  const BASE_URL = resolveBaseUrl(config.base, command === 'build', logger)\n  const resolvedBuildOptions = resolveBuildOptions(resolvedRoot, config.build)\n\n  // resolve cache directory\n  const pkgPath = lookupFile(\n    resolvedRoot,\n    [`package.json`],\n    true /* pathOnly */\n  )\n  const cacheDir = config.cacheDir\n    ? path.resolve(resolvedRoot, config.cacheDir)\n    : pkgPath && path.join(path.dirname(pkgPath), `node_modules/.vite`)\n\n  const assetsFilter = config.assetsInclude\n    ? createFilter(config.assetsInclude)\n    : () => false\n\n  // create an internal resolver to be used in special scenarios, e.g.\n  // optimizer & handling css @imports\n  const createResolver: ResolvedConfig['createResolver'] = (options) => {\n    let aliasContainer: PluginContainer | undefined\n    let resolverContainer: PluginContainer | undefined\n    const createAliasPlugin = () =>\n      aliasPlugin({\n        entries: resolved.resolve.alias,\n        customResolver: function (this, updatedId, importer) {\n          return this.resolve(updatedId, importer, { skipSelf: true })\n        }\n      })\n    return async (id, importer, aliasOnly, ssr) => {\n      let container: PluginContainer\n      if (aliasOnly) {\n        container =\n          aliasContainer ||\n          (aliasContainer = await createPluginContainer({\n            ...resolved,\n            plugins: [createAliasPlugin()]\n          }))\n      } else {\n        container =\n          resolverContainer ||\n          (resolverContainer = await createPluginContainer({\n            ...resolved,\n            plugins: [\n              createAliasPlugin(),\n              resolvePlugin({\n                ...resolved.resolve,\n                root: resolvedRoot,\n                isProduction,\n                isBuild: command === 'build',\n                ssrConfig: resolved.ssr,\n                asSrc: true,\n                preferRelative: false,\n                tryIndex: true,\n                ...options\n              })\n            ]\n          }))\n      }\n      return (await container.resolveId(id, importer, { ssr }))?.id\n    }\n  }\n\n  const { publicDir } = config\n  const resolvedPublicDir =\n    publicDir !== false && publicDir !== ''\n      ? path.resolve(\n          resolvedRoot,\n          typeof publicDir === 'string' ? publicDir : 'public'\n        )\n      : ''\n\n  const server = resolveServerOptions(resolvedRoot, config.server)\n\n  const resolved: ResolvedConfig = {\n    ...config,\n    configFile: configFile ? normalizePath(configFile) : undefined,\n    configFileDependencies,\n    inlineConfig,\n    root: resolvedRoot,\n    base: BASE_URL,\n    resolve: resolveOptions,\n    publicDir: resolvedPublicDir,\n    cacheDir,\n    command,\n    mode,\n    isProduction,\n    plugins: userPlugins,\n    server,\n    build: resolvedBuildOptions,\n    preview: resolvePreviewOptions(config.preview, server),\n    env: {\n      ...userEnv,\n      BASE_URL,\n      MODE: mode,\n      DEV: !isProduction,\n      PROD: isProduction\n    },\n    assetsInclude(file: string) {\n      return DEFAULT_ASSETS_RE.test(file) || assetsFilter(file)\n    },\n    logger,\n    packageCache: new Map(),\n    createResolver,\n    optimizeDeps: {\n      ...config.optimizeDeps,\n      esbuildOptions: {\n        keepNames: config.optimizeDeps?.keepNames,\n        preserveSymlinks: config.resolve?.preserveSymlinks,\n        ...config.optimizeDeps?.esbuildOptions\n      }\n    }\n  }\n\n  ;(resolved.plugins as Plugin[]) = await resolvePlugins(\n    resolved,\n    prePlugins,\n    normalPlugins,\n    postPlugins\n  )\n\n  // call configResolved hooks\n  await Promise.all(userPlugins.map((p) => p.configResolved?.(resolved)))\n\n  if (process.env.DEBUG) {\n    debug(`using resolved config: %O`, {\n      ...resolved,\n      plugins: resolved.plugins.map((p) => p.name)\n    })\n  }\n\n  // TODO Deprecation warnings - remove when out of beta\n\n  const logDeprecationWarning = (\n    deprecatedOption: string,\n    hint: string,\n    error?: Error\n  ) => {\n    logger.warn(\n      chalk.yellow.bold(\n        `(!) \"${deprecatedOption}\" option is deprecated. ${hint}${\n          error ? `\\n${error.stack}` : ''\n        }`\n      )\n    )\n  }\n\n  if (config.build?.base) {\n    logDeprecationWarning(\n      'build.base',\n      '\"base\" is now a root-level config option.'\n    )\n    config.base = config.build.base\n  }\n  Object.defineProperty(resolvedBuildOptions, 'base', {\n    enumerable: false,\n    get() {\n      logDeprecationWarning(\n        'build.base',\n        '\"base\" is now a root-level config option.',\n        new Error()\n      )\n      return resolved.base\n    }\n  })\n\n  if (config.alias) {\n    logDeprecationWarning('alias', 'Use \"resolve.alias\" instead.')\n  }\n  Object.defineProperty(resolved, 'alias', {\n    enumerable: false,\n    get() {\n      logDeprecationWarning(\n        'alias',\n        'Use \"resolve.alias\" instead.',\n        new Error()\n      )\n      return resolved.resolve.alias\n    }\n  })\n\n  if (config.dedupe) {\n    logDeprecationWarning('dedupe', 'Use \"resolve.dedupe\" instead.')\n  }\n  Object.defineProperty(resolved, 'dedupe', {\n    enumerable: false,\n    get() {\n      logDeprecationWarning(\n        'dedupe',\n        'Use \"resolve.dedupe\" instead.',\n        new Error()\n      )\n      return resolved.resolve.dedupe\n    }\n  })\n\n  if (config.optimizeDeps?.keepNames) {\n    logDeprecationWarning(\n      'optimizeDeps.keepNames',\n      'Use \"optimizeDeps.esbuildOptions.keepNames\" instead.'\n    )\n  }\n  Object.defineProperty(resolved.optimizeDeps, 'keepNames', {\n    enumerable: false,\n    get() {\n      logDeprecationWarning(\n        'optimizeDeps.keepNames',\n        'Use \"optimizeDeps.esbuildOptions.keepNames\" instead.',\n        new Error()\n      )\n      return resolved.optimizeDeps.esbuildOptions?.keepNames\n    }\n  })\n\n  if (config.build?.polyfillDynamicImport) {\n    logDeprecationWarning(\n      'build.polyfillDynamicImport',\n      '\"polyfillDynamicImport\" has been removed. Please use @vitejs/plugin-legacy if your target browsers do not support dynamic imports.'\n    )\n  }\n\n  Object.defineProperty(resolvedBuildOptions, 'polyfillDynamicImport', {\n    enumerable: false,\n    get() {\n      logDeprecationWarning(\n        'build.polyfillDynamicImport',\n        '\"polyfillDynamicImport\" has been removed. Please use @vitejs/plugin-legacy if your target browsers do not support dynamic imports.',\n        new Error()\n      )\n      return false\n    }\n  })\n\n  if (config.build?.cleanCssOptions) {\n    logDeprecationWarning(\n      'build.cleanCssOptions',\n      'Vite now uses esbuild for CSS minification.'\n    )\n  }\n\n  if (config.build?.terserOptions && config.build.minify === 'esbuild') {\n    logger.warn(\n      chalk.yellow(\n        `build.terserOptions is specified but build.minify is not set to use Terser. ` +\n          `Note Vite now defaults to use esbuild for minification. If you still ` +\n          `prefer Terser, set build.minify to \"terser\".`\n      )\n    )\n  }\n\n  return resolved\n}\n\n/**\n * Resolve base. Note that some users use Vite to build for non-web targets like\n * electron or expects to deploy\n */\nexport function resolveBaseUrl(\n  base: UserConfig['base'] = '/',\n  isBuild: boolean,\n  logger: Logger\n): string {\n  // #1669 special treatment for empty for same dir relative base\n  if (base === '' || base === './') {\n    return isBuild ? base : '/'\n  }\n  if (base.startsWith('.')) {\n    logger.warn(\n      chalk.yellow.bold(\n        `(!) invalid \"base\" option: ${base}. The value can only be an absolute ` +\n          `URL, ./, or an empty string.`\n      )\n    )\n    base = '/'\n  }\n\n  // external URL\n  if (isExternalUrl(base)) {\n    if (!isBuild) {\n      // get base from full url during dev\n      const parsed = parseUrl(base)\n      base = parsed.pathname || '/'\n    }\n  } else {\n    // ensure leading slash\n    if (!base.startsWith('/')) {\n      logger.warn(\n        chalk.yellow.bold(`(!) \"base\" option should start with a slash.`)\n      )\n      base = '/' + base\n    }\n  }\n\n  // ensure ending slash\n  if (!base.endsWith('/')) {\n    logger.warn(chalk.yellow.bold(`(!) \"base\" option should end with a slash.`))\n    base += '/'\n  }\n\n  return base\n}\n\nfunction mergeConfigRecursively(\n  a: Record<string, any>,\n  b: Record<string, any>,\n  rootPath: string\n) {\n  const merged: Record<string, any> = { ...a }\n  for (const key in b) {\n    const value = b[key]\n    if (value == null) {\n      continue\n    }\n\n    const existing = merged[key]\n    if (Array.isArray(existing) && Array.isArray(value)) {\n      merged[key] = [...existing, ...value]\n      continue\n    }\n    if (isObject(existing) && isObject(value)) {\n      merged[key] = mergeConfigRecursively(\n        existing,\n        value,\n        rootPath ? `${rootPath}.${key}` : key\n      )\n      continue\n    }\n\n    // fields that require special handling\n    if (existing != null) {\n      if (key === 'alias' && (rootPath === 'resolve' || rootPath === '')) {\n        merged[key] = mergeAlias(existing, value)\n        continue\n      } else if (key === 'assetsInclude' && rootPath === '') {\n        merged[key] = [].concat(existing, value)\n        continue\n      } else if (key === 'noExternal' && existing === true) {\n        continue\n      }\n    }\n\n    merged[key] = value\n  }\n  return merged\n}\n\nexport function mergeConfig(\n  a: Record<string, any>,\n  b: Record<string, any>,\n  isRoot = true\n): Record<string, any> {\n  return mergeConfigRecursively(a, b, isRoot ? '' : '.')\n}\n\nexport function mergeAlias(\n  a: AliasOptions = [],\n  b: AliasOptions = []\n): Alias[] {\n  return [...normalizeAlias(a), ...normalizeAlias(b)]\n}\n\nfunction normalizeAlias(o: AliasOptions): Alias[] {\n  return Array.isArray(o)\n    ? o.map(normalizeSingleAlias)\n    : Object.keys(o).map((find) =>\n        normalizeSingleAlias({\n          find,\n          replacement: (o as any)[find]\n        })\n      )\n}\n\n// https://github.com/vitejs/vite/issues/1363\n// work around https://github.com/rollup/plugins/issues/759\nfunction normalizeSingleAlias({ find, replacement }: Alias): Alias {\n  if (\n    typeof find === 'string' &&\n    find.endsWith('/') &&\n    replacement.endsWith('/')\n  ) {\n    find = find.slice(0, find.length - 1)\n    replacement = replacement.slice(0, replacement.length - 1)\n  }\n  return { find, replacement }\n}\n\nexport function sortUserPlugins(\n  plugins: (Plugin | Plugin[])[] | undefined\n): [Plugin[], Plugin[], Plugin[]] {\n  const prePlugins: Plugin[] = []\n  const postPlugins: Plugin[] = []\n  const normalPlugins: Plugin[] = []\n\n  if (plugins) {\n    plugins.flat().forEach((p) => {\n      if (p.enforce === 'pre') prePlugins.push(p)\n      else if (p.enforce === 'post') postPlugins.push(p)\n      else normalPlugins.push(p)\n    })\n  }\n\n  return [prePlugins, normalPlugins, postPlugins]\n}\n\nexport async function loadConfigFromFile(\n  configEnv: ConfigEnv,\n  configFile?: string,\n  configRoot: string = process.cwd(),\n  logLevel?: LogLevel\n): Promise<{\n  path: string\n  config: UserConfig\n  dependencies: string[]\n} | null> {\n  const start = performance.now()\n  const getTime = () => `${(performance.now() - start).toFixed(2)}ms`\n\n  let resolvedPath: string | undefined\n  let isTS = false\n  let isESM = false\n  let dependencies: string[] = []\n\n  // check package.json for type: \"module\" and set `isMjs` to true\n  try {\n    const pkg = lookupFile(configRoot, ['package.json'])\n    if (pkg && JSON.parse(pkg).type === 'module') {\n      isESM = true\n    }\n  } catch (e) {}\n\n  if (configFile) {\n    // explicit config path is always resolved from cwd\n    resolvedPath = path.resolve(configFile)\n    isTS = configFile.endsWith('.ts')\n\n    if (configFile.endsWith('.mjs')) {\n      isESM = true\n    }\n  } else {\n    // implicit config file loaded from inline root (if present)\n    // otherwise from cwd\n    const jsconfigFile = path.resolve(configRoot, 'vite.config.js')\n    if (fs.existsSync(jsconfigFile)) {\n      resolvedPath = jsconfigFile\n    }\n\n    if (!resolvedPath) {\n      const mjsconfigFile = path.resolve(configRoot, 'vite.config.mjs')\n      if (fs.existsSync(mjsconfigFile)) {\n        resolvedPath = mjsconfigFile\n        isESM = true\n      }\n    }\n\n    if (!resolvedPath) {\n      const tsconfigFile = path.resolve(configRoot, 'vite.config.ts')\n      if (fs.existsSync(tsconfigFile)) {\n        resolvedPath = tsconfigFile\n        isTS = true\n      }\n    }\n  }\n\n  if (!resolvedPath) {\n    debug('no config file found.')\n    return null\n  }\n\n  try {\n    let userConfig: UserConfigExport | undefined\n\n    if (isESM) {\n      const fileUrl = require('url').pathToFileURL(resolvedPath)\n      const bundled = await bundleConfigFile(resolvedPath, true)\n      dependencies = bundled.dependencies\n      if (isTS) {\n        // before we can register loaders without requiring users to run node\n        // with --experimental-loader themselves, we have to do a hack here:\n        // bundle the config file w/ ts transforms first, write it to disk,\n        // load it with native Node ESM, then delete the file.\n        fs.writeFileSync(resolvedPath + '.js', bundled.code)\n        userConfig = (await dynamicImport(`${fileUrl}.js?t=${Date.now()}`))\n          .default\n        fs.unlinkSync(resolvedPath + '.js')\n        debug(`TS + native esm config loaded in ${getTime()}`, fileUrl)\n      } else {\n        // using Function to avoid this from being compiled away by TS/Rollup\n        // append a query so that we force reload fresh config in case of\n        // server restart\n        userConfig = (await dynamicImport(`${fileUrl}?t=${Date.now()}`)).default\n        debug(`native esm config loaded in ${getTime()}`, fileUrl)\n      }\n    }\n\n    if (!userConfig) {\n      // Bundle config file and transpile it to cjs using esbuild.\n      const bundled = await bundleConfigFile(resolvedPath)\n      dependencies = bundled.dependencies\n      userConfig = await loadConfigFromBundledFile(resolvedPath, bundled.code)\n      debug(`bundled config file loaded in ${getTime()}`)\n    }\n\n    const config = await (typeof userConfig === 'function'\n      ? userConfig(configEnv)\n      : userConfig)\n    if (!isObject(config)) {\n      throw new Error(`config must export or return an object.`)\n    }\n    return {\n      path: normalizePath(resolvedPath),\n      config,\n      dependencies\n    }\n  } catch (e) {\n    createLogger(logLevel).error(\n      chalk.red(`failed to load config from ${resolvedPath}`),\n      { error: e }\n    )\n    throw e\n  }\n}\n\nasync function bundleConfigFile(\n  fileName: string,\n  isESM = false\n): Promise<{ code: string; dependencies: string[] }> {\n  const result = await build({\n    absWorkingDir: process.cwd(),\n    entryPoints: [fileName],\n    outfile: 'out.js',\n    write: false,\n    platform: 'node',\n    bundle: true,\n    format: isESM ? 'esm' : 'cjs',\n    sourcemap: 'inline',\n    metafile: true,\n    plugins: [\n      {\n        name: 'externalize-deps',\n        setup(build) {\n          build.onResolve({ filter: /.*/ }, (args) => {\n            const id = args.path\n            if (id[0] !== '.' && !path.isAbsolute(id)) {\n              return {\n                external: true\n              }\n            }\n          })\n        }\n      },\n      {\n        name: 'replace-import-meta',\n        setup(build) {\n          build.onLoad({ filter: /\\.[jt]s$/ }, async (args) => {\n            const contents = await fs.promises.readFile(args.path, 'utf8')\n            return {\n              loader: args.path.endsWith('.ts') ? 'ts' : 'js',\n              contents: contents\n                .replace(\n                  /\\bimport\\.meta\\.url\\b/g,\n                  JSON.stringify(`file://${args.path}`)\n                )\n                .replace(\n                  /\\b__dirname\\b/g,\n                  JSON.stringify(path.dirname(args.path))\n                )\n                .replace(/\\b__filename\\b/g, JSON.stringify(args.path))\n            }\n          })\n        }\n      }\n    ]\n  })\n  const { text } = result.outputFiles[0]\n  return {\n    code: text,\n    dependencies: result.metafile ? Object.keys(result.metafile.inputs) : []\n  }\n}\n\ninterface NodeModuleWithCompile extends NodeModule {\n  _compile(code: string, filename: string): any\n}\n\nasync function loadConfigFromBundledFile(\n  fileName: string,\n  bundledCode: string\n): Promise<UserConfig> {\n  const extension = path.extname(fileName)\n  const defaultLoader = require.extensions[extension]!\n  require.extensions[extension] = (module: NodeModule, filename: string) => {\n    if (filename === fileName) {\n      ;(module as NodeModuleWithCompile)._compile(bundledCode, filename)\n    } else {\n      defaultLoader(module, filename)\n    }\n  }\n  // clear cache in case of server restart\n  delete require.cache[require.resolve(fileName)]\n  const raw = require(fileName)\n  const config = raw.__esModule ? raw.default : raw\n  require.extensions[extension] = defaultLoader\n  return config\n}\n\nexport function loadEnv(\n  mode: string,\n  envDir: string,\n  prefixes: string | string[] = 'VITE_'\n): Record<string, string> {\n  if (mode === 'local') {\n    throw new Error(\n      `\"local\" cannot be used as a mode name because it conflicts with ` +\n        `the .local postfix for .env files.`\n    )\n  }\n  prefixes = arraify(prefixes)\n  const env: Record<string, string> = {}\n  const envFiles = [\n    /** mode local file */ `.env.${mode}.local`,\n    /** mode file */ `.env.${mode}`,\n    /** local file */ `.env.local`,\n    /** default file */ `.env`\n  ]\n\n  // check if there are actual env variables starting with VITE_*\n  // these are typically provided inline and should be prioritized\n  for (const key in process.env) {\n    if (\n      prefixes.some((prefix) => key.startsWith(prefix)) &&\n      env[key] === undefined\n    ) {\n      env[key] = process.env[key] as string\n    }\n  }\n\n  for (const file of envFiles) {\n    const path = lookupFile(envDir, [file], true)\n    if (path) {\n      const parsed = dotenv.parse(fs.readFileSync(path), {\n        debug: !!process.env.DEBUG || undefined\n      })\n\n      // let environment variables use each other\n      dotenvExpand({\n        parsed,\n        // prevent process.env mutation\n        ignoreProcessEnv: true\n      } as any)\n\n      // only keys that start with prefix are exposed to client\n      for (const [key, value] of Object.entries(parsed)) {\n        if (\n          prefixes.some((prefix) => key.startsWith(prefix)) &&\n          env[key] === undefined\n        ) {\n          env[key] = value\n        } else if (key === 'NODE_ENV') {\n          // NODE_ENV override in .env file\n          process.env.VITE_USER_NODE_ENV = value\n        }\n      }\n    }\n  }\n  return env\n}\n\nexport function resolveEnvPrefix({\n  envPrefix = 'VITE_'\n}: UserConfig): string[] {\n  envPrefix = arraify(envPrefix)\n  if (envPrefix.some((prefix) => prefix === '')) {\n    throw new Error(\n      `envPrefix option contains value '', which could lead unexpected exposure of sensitive information.`\n    )\n  }\n  return envPrefix\n}\n","import path from 'path'\nimport type { Plugin } from '../../node/plugin'\nimport chalk from 'chalk'\nimport { FS_PREFIX, DEFAULT_EXTENSIONS } from '../../node/constants'\nimport {\n  createDebugger,\n  isExternalUrl,\n  fsPathFromId,\n  isDataUrl,\n  isTsRequest,\n  isPossibleTsOutput,\n  getTsSrcPath\n} from '../../node/utils'\nimport type { ViteDevServer, InternalResolveOptions } from '../../node'\nimport type { PartialResolvedId } from 'rollup'\nimport { resolve as _resolveExports } from 'resolve.exports'\nimport fs from 'fs'\n\nconst isDebug = process.env.DEBUG\nconst debug = createDebugger('vite:resolve-details', {\n  onlyWhenFocused: true\n})\n\nexport function resolvePlugin(baseOptions: InternalResolveOptions): Plugin {\n  const {\n    root,\n    // isProduction,\n    asSrc,\n    // ssrConfig,\n    preferRelative = false\n  } = baseOptions\n  let server: ViteDevServer | undefined\n\n  return {\n    name: 'vite:browser:resolve',\n\n    configureServer(_server) {\n      server = _server\n    },\n\n    resolveId(id, importer, resolveOpts) {\n      const ssr = resolveOpts?.ssr === true\n\n      // this is passed by @rollup/plugin-commonjs\n      const isRequire: boolean =\n        resolveOpts?.custom?.['node-resolve']?.isRequire ?? false\n\n      const options: InternalResolveOptions = {\n        isRequire,\n\n        ...baseOptions,\n        isFromTsImporter: isTsRequest(importer ?? '')\n      }\n\n      let res: string | PartialResolvedId | undefined\n\n      // explicit fs paths that starts with /@fs/*\n      if (asSrc && id.startsWith(FS_PREFIX)) {\n        const fsPath = fsPathFromId(id)\n        res = tryFsResolve(fsPath, options)\n        isDebug && debug(`[@fs] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n        // always return here even if res doesn't exist since /@fs/ is explicit\n        // if the file doesn't exist it should be a 404\n        return res || fsPath\n      }\n\n      // URL\n      // /foo -> /fs-root/foo\n      if (asSrc && id.startsWith('/')) {\n        const fsPath = path.resolve(root, id.slice(1))\n        if ((res = tryFsResolve(fsPath, options))) {\n          isDebug && debug(`[url] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n          return res\n        }\n      }\n\n      // relative\n      if (id.startsWith('.') || (preferRelative && /^\\w/.test(id))) {\n        const basedir = importer ? path.dirname(importer) : process.cwd()\n        const fsPath = path.resolve(basedir, id)\n        // handle browser field mapping for relative imports\n\n        if ((res = tryFsResolve(fsPath, options))) {\n          return res\n        }\n      }\n\n      // absolute fs paths\n      if (path.isAbsolute(id) && (res = tryFsResolve(id, options))) {\n        isDebug && debug(`[fs] ${chalk.cyan(id)} -> ${chalk.dim(res)}`)\n        return res\n      }\n\n      // external\n      if (isExternalUrl(id)) {\n        return {\n          id,\n          external: true\n        }\n      }\n\n      // data uri: pass through (this only happens during build and will be\n      // handled by dedicated plugin)\n      if (isDataUrl(id)) {\n        return null\n      }\n\n      isDebug && debug(`[fallthrough] ${chalk.dim(id)}`)\n    }\n  }\n}\n\nfunction tryFsResolve(\n  fsPath: string,\n  options: InternalResolveOptions,\n  tryIndex = true,\n  targetWeb = true\n): string | undefined {\n  let file = fsPath\n  let postfix = ''\n\n  let postfixIndex = fsPath.indexOf('?')\n  if (postfixIndex < 0) {\n    postfixIndex = fsPath.indexOf('#')\n  }\n  if (postfixIndex > 0) {\n    file = fsPath.slice(0, postfixIndex)\n    postfix = fsPath.slice(postfixIndex)\n  }\n\n  let res: string | undefined\n\n  // if we fould postfix exist, we should first try resolving file with postfix. details see #4703.\n  if (\n    postfix &&\n    (res = tryResolveFile(\n      fsPath,\n      '',\n      options,\n      false,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  if (\n    (res = tryResolveFile(\n      file,\n      postfix,\n      options,\n      false,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  for (const ext of options.extensions || DEFAULT_EXTENSIONS) {\n    if (\n      postfix &&\n      (res = tryResolveFile(\n        fsPath + ext,\n        '',\n        options,\n        false,\n        targetWeb,\n        options.tryPrefix,\n        options.skipPackageJson\n      ))\n    ) {\n      return res\n    }\n\n    if (\n      (res = tryResolveFile(\n        file + ext,\n        postfix,\n        options,\n        false,\n        targetWeb,\n        options.tryPrefix,\n        options.skipPackageJson\n      ))\n    ) {\n      return res\n    }\n  }\n\n  if (\n    postfix &&\n    (res = tryResolveFile(\n      fsPath,\n      '',\n      options,\n      tryIndex,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n\n  if (\n    (res = tryResolveFile(\n      file,\n      postfix,\n      options,\n      tryIndex,\n      targetWeb,\n      options.tryPrefix,\n      options.skipPackageJson\n    ))\n  ) {\n    return res\n  }\n}\n\nfunction tryResolveFile(\n  file: string,\n  postfix: string,\n  options: InternalResolveOptions,\n  tryIndex: boolean,\n  targetWeb: boolean,\n  tryPrefix?: string,\n  skipPackageJson?: boolean\n): string | undefined {\n  if (!file.startsWith(options.root)) return undefined\n  if (fs.existsSync(file)) {\n    return file + postfix\n  } else if (tryIndex) {\n    const index = tryFsResolve(file + '/index', options, false)\n    if (index) return index + postfix\n  }\n\n  const tryTsExtension = options.isFromTsImporter && isPossibleTsOutput(file)\n  if (tryTsExtension) {\n    const tsSrcPath = getTsSrcPath(file)\n    return tryResolveFile(\n      tsSrcPath,\n      postfix,\n      options,\n      tryIndex,\n      targetWeb,\n      tryPrefix,\n      skipPackageJson\n    )\n  }\n\n  if (tryPrefix) {\n    const prefixed = `${path.dirname(file)}/${tryPrefix}${path.basename(file)}`\n    return tryResolveFile(prefixed, postfix, options, tryIndex, targetWeb)\n  }\n}\n\nexport function tryOptimizedResolve(\n  id: string,\n  server: ViteDevServer,\n  importer?: string\n): string | undefined {\n  const cacheDir = server.config.cacheDir\n  const depData = server._optimizeDepsMetadata\n\n  if (!cacheDir || !depData) return\n\n  const getOptimizedUrl = (optimizedData: typeof depData.optimized[string]) => {\n    return optimizedData.file //+\n    // `?v=${depData.browserHash}${\n    //   optimizedData.needsInterop ? `&es-interop` : ``\n    // }`\n  }\n\n  // check if id has been optimized\n  const isOptimized = depData.optimized[id]\n  if (isOptimized) {\n    return getOptimizedUrl(isOptimized)\n  }\n\n  if (!importer) return\n}\n","import type { ViteDevServer } from '../../node/server'\nimport type { Plugin } from '../../node/plugin'\nimport { bareImportRE } from '../../node/utils'\nimport { tryOptimizedResolve } from './resolve'\n\n/**\n * A plugin to avoid an aliased AND optimized dep from being aliased in src\n */\nexport function preAliasPlugin(): Plugin {\n  let server: ViteDevServer\n  return {\n    name: 'vite:browser:pre-alias',\n    configureServer(_server) {\n      server = _server\n    },\n    resolveId(id, importer, options) {\n      if (!options?.ssr && bareImportRE.test(id)) {\n        return tryOptimizedResolve(id, server, importer)\n      }\n    }\n  }\n}\n","import { resolvePlugin } from './resolve'\nimport aliasPlugin from '@rollup/plugin-alias'\nimport type { ResolvedConfig } from '../../node/config'\nimport type { Plugin } from '../../node/plugin'\nimport { preAliasPlugin } from './preAlias'\nimport { htmlInlineScriptProxyPlugin } from '../../node/plugins/html'\nimport { cssPlugin, cssPostPlugin } from '../../node/plugins/css'\nimport { esbuildPlugin } from '../../node/plugins/esbuild'\nimport { jsonPlugin } from '../../node/plugins/json'\nimport { assetPlugin } from '../../node/plugins/asset'\nimport { definePlugin } from '../../node/plugins/define'\nimport { clientInjectionsPlugin } from '../../node/plugins/clientInjections'\nimport { importAnalysisPlugin } from '../../node/plugins/importAnalysis'\n\nexport async function resolvePlugins(\n  config: ResolvedConfig,\n  prePlugins: Plugin[],\n  normalPlugins: Plugin[],\n  postPlugins: Plugin[]\n): Promise<Plugin[]> {\n  const isBuild = config.command === 'build'\n\n  const buildPlugins = { pre: [], post: [] }\n\n  return [\n    isBuild ? null : preAliasPlugin(),\n    aliasPlugin({\n      entries: config.resolve.alias,\n      customResolver: function (this, updatedId, importer) {\n        return this.resolve(updatedId, importer, { skipSelf: true })\n      }\n    }),\n    ...prePlugins,\n    // config.build.polyfillModulePreload\n    //   ? modulePreloadPolyfillPlugin(config)\n    //   : null,\n    resolvePlugin({\n      ...config.resolve,\n      root: config.root,\n      isProduction: config.isProduction,\n      isBuild,\n      packageCache: config.packageCache,\n      ssrConfig: config.ssr,\n      asSrc: true\n    }),\n    // config.build.ssr ? ssrRequireHookPlugin(config) : null,\n    htmlInlineScriptProxyPlugin(config),\n    cssPlugin(config),\n    config.esbuild !== false ? esbuildPlugin(config.esbuild) : null,\n    jsonPlugin(\n      {\n        namedExports: true,\n        ...config.json\n      },\n      isBuild\n    ),\n    // wasmPlugin(config),\n    // webWorkerPlugin(config),\n    assetPlugin(config),\n    ...normalPlugins,\n    definePlugin(config),\n    cssPostPlugin(config),\n    ...buildPlugins.pre,\n    ...postPlugins,\n    ...buildPlugins.post,\n    // internal server-only plugins are always applied after everything else\n    ...(isBuild\n      ? []\n      : [clientInjectionsPlugin(config), importAnalysisPlugin(config)])\n  ].filter(Boolean) as Plugin[]\n}\n","import type { ResolvedServerOptions, ServerOptions } from '../../node/server'\n\nexport function resolveServerOptions(\n  root: string,\n  raw?: ServerOptions\n): ResolvedServerOptions {\n  const server = raw || {}\n  let allowDirs = server.fs?.allow\n  const deny = server.fs?.deny || ['.env', '.env.*', '*.{crt,pem}']\n\n  if (!allowDirs) {\n    allowDirs = [root]\n  }\n\n  server.fs = {\n    strict: server.fs?.strict ?? true,\n    allow: allowDirs,\n    deny\n  }\n  return server as ResolvedServerOptions\n}\n","import path from 'path'\nimport type { Logger } from '../node/logger'\nimport type { Plugin } from '../node/plugin'\nimport {\n  mergeAlias,\n  mergeConfig,\n  resolveBaseUrl,\n  sortUserPlugins,\n  InlineConfig,\n  ResolvedConfig\n} from '../node/config'\nimport { normalizePath } from '../node/utils'\nimport { resolveBuildOptions } from '../node/build'\nimport { CLIENT_ENTRY, DEFAULT_ASSETS_RE, ENV_ENTRY } from '../node/constants'\nimport { resolvePlugins } from './plugins'\nimport { resolveServerOptions } from './server'\nimport { PluginContainer } from '../node'\nimport aliasPlugin from '@rollup/plugin-alias'\nimport { resolvePlugin } from './plugins/resolve'\nimport { createPluginContainer } from '../node/server/pluginContainer'\n\nexport async function resolveConfig(\n  inlineConfig: InlineConfig,\n  command: 'build' | 'serve',\n  defaultMode = 'development'\n): Promise<ResolvedConfig> {\n  let config = inlineConfig\n  const mode = defaultMode\n  const isProduction = false\n\n  const configEnv = {\n    mode,\n    command\n  }\n\n  // Define logger\n  const logger: Logger = {\n    info: (s) => console.log(s),\n    warn: (s) => console.log(s),\n    error: (s) => console.log(s),\n    clearScreen: () => {\n      /* empty */\n    },\n    hasErrorLogged: () => false,\n    hasWarned: false,\n    warnOnce: (s) => console.warn(s)\n  }\n\n  // resolve plugins\n  const rawUserPlugins = (config.plugins || []).flat().filter((p) => {\n    if (!p) {\n      return false\n    } else if (!p.apply) {\n      return true\n    } else if (typeof p.apply === 'function') {\n      return p.apply({ ...config, mode }, configEnv)\n    } else {\n      return p.apply === command\n    }\n  }) as Plugin[]\n  const [prePlugins, normalPlugins, postPlugins] =\n    sortUserPlugins(rawUserPlugins)\n\n  // run config hooks\n  const userPlugins = [...prePlugins, ...normalPlugins, ...postPlugins]\n  for (const p of userPlugins) {\n    if (p.config) {\n      const res = await p.config(config, configEnv)\n      if (res) {\n        config = mergeConfig(config, res)\n      }\n    }\n  }\n\n  // resolve root\n  const resolvedRoot = normalizePath(\n    config.root ? path.resolve(config.root) : process.cwd()\n  )\n\n  const clientAlias = [\n    { find: /^[\\/]?@vite\\/env/, replacement: () => ENV_ENTRY },\n    { find: /^[\\/]?@vite\\/client/, replacement: () => CLIENT_ENTRY }\n  ]\n\n  // resolve alias with internal client alias\n  const resolvedAlias = mergeAlias(\n    // @ts-ignore because @rollup/plugin-alias' type doesn't allow function\n    // replacement, but its implementation does work with function values.\n    clientAlias,\n    config.resolve?.alias || config.alias || []\n  )\n\n  const resolveOptions: ResolvedConfig['resolve'] = {\n    dedupe: config.dedupe,\n    ...config.resolve,\n    alias: resolvedAlias\n  }\n\n  // resolve public base url\n  const BASE_URL = resolveBaseUrl(config.base, command === 'build', logger)\n  const resolvedBuildOptions = resolveBuildOptions(resolvedRoot, config.build)\n\n  const cacheDir = config.cacheDir\n\n  // create an internal resolver to be used in special scenarios, e.g.\n  // optimizer & handling css @imports\n  const createResolver: ResolvedConfig['createResolver'] = (options) => {\n    let aliasContainer: PluginContainer | undefined\n    let resolverContainer: PluginContainer | undefined\n    const createAliasPlugin = () =>\n      aliasPlugin({\n        entries: resolved.resolve.alias,\n        customResolver: function (this, updatedId, importer) {\n          return this.resolve(updatedId, importer, { skipSelf: true })\n        }\n      })\n    return async (id, importer, aliasOnly, ssr) => {\n      let container: PluginContainer\n      if (aliasOnly) {\n        container =\n          aliasContainer ||\n          (aliasContainer = await createPluginContainer({\n            ...resolved,\n            plugins: [createAliasPlugin()]\n          }))\n      } else {\n        container =\n          resolverContainer ||\n          (resolverContainer = await createPluginContainer({\n            ...resolved,\n            plugins: [\n              createAliasPlugin(),\n              resolvePlugin({\n                ...resolved.resolve,\n                root: resolvedRoot,\n                isProduction,\n                isBuild: command === 'build',\n                ssrConfig: resolved.ssr,\n                asSrc: true,\n                preferRelative: false,\n                tryIndex: true,\n                ...options\n              })\n            ]\n          }))\n      }\n      return (await container.resolveId(id, importer, { ssr }))?.id\n    }\n  }\n\n  const { publicDir } = config\n  const resolvedPublicDir =\n    publicDir !== false && publicDir !== ''\n      ? path.resolve(\n          resolvedRoot,\n          typeof publicDir === 'string' ? publicDir : 'public'\n        )\n      : ''\n\n  const server = resolveServerOptions(resolvedRoot, config.server)\n\n  const resolved: ResolvedConfig = {\n    ...config,\n    configFile: undefined as any,\n    configFileDependencies: [],\n    inlineConfig,\n    root: resolvedRoot,\n    base: BASE_URL,\n    resolve: resolveOptions,\n    publicDir: resolvedPublicDir,\n    cacheDir,\n    command,\n    mode,\n    isProduction,\n    plugins: userPlugins,\n    server,\n    build: resolvedBuildOptions,\n    preview: undefined as any,\n    env: {\n      BASE_URL,\n      MODE: mode,\n      DEV: !isProduction,\n      PROD: isProduction\n    },\n    assetsInclude(file: string) {\n      return DEFAULT_ASSETS_RE.test(file)\n    },\n    logger,\n    packageCache: new Map(),\n    createResolver,\n    optimizeDeps: {\n      ...config.optimizeDeps,\n      esbuildOptions: {\n        keepNames: config.optimizeDeps?.keepNames,\n        preserveSymlinks: config.resolve?.preserveSymlinks,\n        ...config.optimizeDeps?.esbuildOptions\n      }\n    }\n  }\n\n  ;(resolved.plugins as Plugin[]) = await resolvePlugins(\n    resolved,\n    prePlugins,\n    normalPlugins,\n    postPlugins\n  )\n\n  // call configResolved hooks\n  await Promise.all(userPlugins.map((p) => p.configResolved?.(resolved)))\n\n  return resolved\n}\n","import path from 'path'\nimport chalk from 'chalk'\nimport type { ViteDevServer } from '../../node/server'\nimport { createDebugger, normalizePath } from '../../node/utils'\nimport type { ModuleNode } from '../../node/server/moduleGraph'\nimport type { Update } from 'types/hmrPayload'\nimport { CLIENT_DIR } from '../../node/constants'\nimport { isCSSRequest } from '../../node/plugins/css'\nimport type { HmrContext } from '../../node/server/hmr'\n\nexport const debugHmr = createDebugger('vite:hmr')\n\nconst normalizedClientDir = normalizePath(CLIENT_DIR)\n\nfunction getShortName(file: string, root: string) {\n  return file.startsWith(root + '/') ? path.posix.relative(root, file) : file\n}\n\nexport async function handleHMRUpdate(\n  file: string,\n  content: string,\n  server: ViteDevServer\n): Promise<any> {\n  const { ws, config, moduleGraph } = server\n  const shortFile = getShortName(file, config.root)\n\n  const isConfig = file === config.configFile\n  const isConfigDependency = config.configFileDependencies.some(\n    (name) => file === path.resolve(name)\n  )\n  const isEnv =\n    config.inlineConfig.envFile !== false &&\n    (file === '.env' || file.startsWith('.env.'))\n  if (isConfig || isConfigDependency || isEnv) {\n    // auto restart server\n    debugHmr(`[config change] ${chalk.dim(shortFile)}`)\n    config.logger.info(\n      chalk.green(\n        `${path.relative(process.cwd(), file)} changed, restarting server...`\n      ),\n      { clear: true, timestamp: true }\n    )\n    await server.restart()\n    return\n  }\n\n  debugHmr(`[file change] ${chalk.dim(shortFile)}`)\n\n  // (dev only) the client itself cannot be hot updated.\n  if (file.startsWith(normalizedClientDir)) {\n    ws.send({\n      type: 'full-reload',\n      path: '*'\n    })\n    return\n  }\n\n  const mods = moduleGraph.getModulesByFile(file)\n\n  // check if any plugin wants to perform custom HMR handling\n  const timestamp = Date.now()\n  const hmrContext: HmrContext = {\n    file,\n    timestamp,\n    modules: mods ? [...mods] : [],\n    read: () => content,\n    server\n  }\n\n  for (const plugin of config.plugins) {\n    if (plugin.handleHotUpdate) {\n      const filteredModules = await plugin.handleHotUpdate(hmrContext)\n      if (filteredModules) {\n        hmrContext.modules = filteredModules\n      }\n    }\n  }\n\n  if (!hmrContext.modules.length) {\n    // html file cannot be hot updated\n    if (file.endsWith('.html')) {\n      config.logger.info(chalk.green(`page reload `) + chalk.dim(shortFile), {\n        clear: true,\n        timestamp: true\n      })\n      ws.send({\n        type: 'full-reload',\n        path: config.server.middlewareMode\n          ? '*'\n          : '/' + normalizePath(path.relative(config.root, file))\n      })\n    } else {\n      // loaded but not in the module graph, probably not js\n      debugHmr(`[no modules matched] ${chalk.dim(shortFile)}`)\n    }\n    return\n  }\n\n  updateModules(shortFile, hmrContext.modules, timestamp, server)\n}\n\nfunction updateModules(\n  file: string,\n  modules: ModuleNode[],\n  timestamp: number,\n  { config, ws }: ViteDevServer\n) {\n  const updates: Update[] = []\n  const invalidatedModules = new Set<ModuleNode>()\n  let needFullReload = false\n\n  for (const mod of modules) {\n    invalidate(mod, timestamp, invalidatedModules)\n    if (needFullReload) {\n      continue\n    }\n\n    const boundaries = new Set<{\n      boundary: ModuleNode\n      acceptedVia: ModuleNode\n    }>()\n    const hasDeadEnd = propagateUpdate(mod, boundaries)\n    if (hasDeadEnd) {\n      needFullReload = true\n      continue\n    }\n\n    updates.push(\n      ...[...boundaries].map(({ boundary, acceptedVia }) => ({\n        type: `${boundary.type}-update` as Update['type'],\n        timestamp,\n        path: boundary.url,\n        acceptedPath: acceptedVia.url\n      }))\n    )\n  }\n\n  if (needFullReload) {\n    config.logger.info(chalk.green(`page reload `) + chalk.dim(file), {\n      clear: true,\n      timestamp: true\n    })\n    ws.send({\n      type: 'full-reload'\n    })\n  } else {\n    config.logger.info(\n      updates\n        .map(({ path }) => chalk.green(`hmr update `) + chalk.dim(path))\n        .join('\\n'),\n      { clear: true, timestamp: true }\n    )\n    ws.send({\n      type: 'update',\n      updates\n    })\n  }\n}\n\nexport async function handleFileAddUnlink(\n  file: string,\n  server: ViteDevServer,\n  isUnlink = false\n): Promise<void> {\n  const modules = [...(server.moduleGraph.getModulesByFile(file) ?? [])]\n  if (isUnlink && file in server._globImporters) {\n    delete server._globImporters[file]\n  } else {\n    // TODO BROWSER SUPPORT\n    // for (const i in server._globImporters) {\n    //   const { module, importGlobs } = server._globImporters[i]\n    //   for (const { base, pattern } of importGlobs) {\n    //     if (match(file, pattern) || match(path.relative(base, file), pattern)) {\n    //       modules.push(module);\n    //       // We use `onFileChange` to invalidate `module.file` so that subsequent `ssrLoadModule()`\n    //       // calls get fresh glob import results with(out) the newly added(/removed) `file`.\n    //       server.moduleGraph.onFileChange(module.file!);\n    //       break;\n    //     }\n    //   }\n    // }\n  }\n  if (modules.length > 0) {\n    updateModules(\n      getShortName(file, server.config.root),\n      modules,\n      Date.now(),\n      server\n    )\n  }\n}\n\nfunction propagateUpdate(\n  node: ModuleNode,\n  boundaries: Set<{\n    boundary: ModuleNode\n    acceptedVia: ModuleNode\n  }>,\n  currentChain: ModuleNode[] = [node]\n): boolean /* hasDeadEnd */ {\n  if (node.isSelfAccepting) {\n    boundaries.add({\n      boundary: node,\n      acceptedVia: node\n    })\n\n    // additionally check for CSS importers, since a PostCSS plugin like\n    // Tailwind JIT may register any file as a dependency to a CSS file.\n    for (const importer of node.importers) {\n      if (isCSSRequest(importer.url) && !currentChain.includes(importer)) {\n        propagateUpdate(importer, boundaries, currentChain.concat(importer))\n      }\n    }\n\n    return false\n  }\n\n  if (!node.importers.size) {\n    return true\n  }\n\n  // #3716, #3913\n  // For a non-CSS file, if all of its importers are CSS files (registered via\n  // PostCSS plugins) it should be considered a dead end and force full reload.\n  if (\n    !isCSSRequest(node.url) &&\n    [...node.importers].every((i) => isCSSRequest(i.url))\n  ) {\n    return true\n  }\n\n  for (const importer of node.importers) {\n    const subChain = currentChain.concat(importer)\n    if (importer.acceptedHmrDeps.has(node)) {\n      boundaries.add({\n        boundary: importer,\n        acceptedVia: node\n      })\n      continue\n    }\n\n    if (currentChain.includes(importer)) {\n      // circular deps is considered dead end\n      return true\n    }\n\n    if (propagateUpdate(importer, boundaries, subChain)) {\n      return true\n    }\n  }\n  return false\n}\n\nfunction invalidate(mod: ModuleNode, timestamp: number, seen: Set<ModuleNode>) {\n  if (seen.has(mod)) {\n    return\n  }\n  seen.add(mod)\n  mod.lastHMRTimestamp = timestamp\n  mod.transformResult = null\n  mod.ssrModule = null\n  mod.ssrTransformResult = null\n  mod.importers.forEach((importer) => {\n    if (!importer.acceptedHmrDeps.has(mod)) {\n      invalidate(importer, timestamp, seen)\n    }\n  })\n}\n","import path from 'path'\nimport { pathToFileURL } from 'url'\nimport type { ViteDevServer } from '../../node/server'\nimport { unwrapId } from '../../node/utils'\nimport {\n  ssrExportAllKey,\n  ssrModuleExportsKey,\n  ssrImportKey,\n  ssrImportMetaKey,\n  ssrDynamicImportKey\n} from '../../node/ssr/ssrTransform'\nimport { transformRequest } from '../../node/server/transformRequest'\nimport type { InternalResolveOptions } from '../../node/plugins/resolve'\n\ninterface SSRContext {\n  global: typeof globalThis\n}\n\ntype SSRModule = Record<string, any>\n\nconst pendingModules = new Map<string, Promise<SSRModule>>()\nconst pendingImports = new Map<string, string[]>()\n\nexport async function ssrLoadModule(\n  url: string,\n  server: ViteDevServer,\n  nodeImport: (id: string) => Promise<any>,\n  context: SSRContext = { global },\n  urlStack: string[] = []\n): Promise<SSRModule> {\n  url = unwrapId(url)\n\n  // when we instantiate multiple dependency modules in parallel, they may\n  // point to shared modules. We need to avoid duplicate instantiation attempts\n  // by register every module as pending synchronously so that all subsequent\n  // request to that module are simply waiting on the same promise.\n  const pending = pendingModules.get(url)\n  if (pending) {\n    return pending\n  }\n\n  const modulePromise = instantiateModule(\n    url,\n    server,\n    nodeImport,\n    context,\n    urlStack\n  )\n  pendingModules.set(url, modulePromise)\n  modulePromise\n    .catch(() => {\n      pendingImports.delete(url)\n    })\n    .finally(() => {\n      pendingModules.delete(url)\n    })\n  return modulePromise\n}\n\nasync function instantiateModule(\n  url: string,\n  server: ViteDevServer,\n  nodeImport: (id: string) => Promise<any>,\n  context: SSRContext = { global },\n  urlStack: string[] = []\n): Promise<SSRModule> {\n  const { moduleGraph } = server\n  const mod = await moduleGraph.ensureEntryFromUrl(url, true)\n\n  if (mod.ssrModule) {\n    return mod.ssrModule\n  }\n\n  const result =\n    mod.ssrTransformResult ||\n    (await transformRequest(url, server, { ssr: true }))\n  if (!result) {\n    // TODO more info? is this even necessary?\n    throw new Error(`failed to load module for ssr: ${url}`)\n  }\n\n  const ssrModule = {\n    [Symbol.toStringTag]: 'Module'\n  }\n  Object.defineProperty(ssrModule, '__esModule', { value: true })\n\n  // Tolerate circular imports by ensuring the module can be\n  // referenced before it's been instantiated.\n  mod.ssrModule = ssrModule\n\n  const ssrImportMeta = {\n    // The filesystem URL, matching native Node.js modules\n    url: pathToFileURL(mod.file!).toString()\n  }\n\n  urlStack = urlStack.concat(url)\n  const isCircular = (url: string) => urlStack.includes(url)\n\n  const {\n    isProduction,\n    resolve: { dedupe, preserveSymlinks },\n    root\n  } = server.config\n\n  // The `extensions` and `mainFields` options are used to ensure that\n  // CommonJS modules are preferred. We want to avoid ESM->ESM imports\n  // whenever possible, because `hookNodeResolve` can't intercept them.\n  const resolveOptions: InternalResolveOptions = {\n    dedupe,\n    extensions: ['.js', '.cjs', '.json'],\n    isBuild: true,\n    isProduction,\n    isRequire: true,\n    mainFields: ['main'],\n    preserveSymlinks,\n    root\n  }\n\n  // Since dynamic imports can happen in parallel, we need to\n  // account for multiple pending deps and duplicate imports.\n  const pendingDeps: string[] = []\n\n  const ssrImport = async (dep: string) => {\n    dep = unwrapId(dep)\n    if (dep[0] !== '.' && dep[0] !== '/') {\n      return proxyESM(await nodeImport(dep))\n    }\n    if (!isCircular(dep) && !pendingImports.get(dep)?.some(isCircular)) {\n      pendingDeps.push(dep)\n      if (pendingDeps.length === 1) {\n        pendingImports.set(url, pendingDeps)\n      }\n      const mod = await ssrLoadModule(\n        dep,\n        server,\n        nodeImport,\n        context,\n        urlStack\n      )\n      if (pendingDeps.length === 1) {\n        pendingImports.delete(url)\n      } else {\n        pendingDeps.splice(pendingDeps.indexOf(dep), 1)\n      }\n      // return local module to avoid race condition #5470\n      return mod\n    }\n    return moduleGraph.urlToModuleMap.get(dep)?.ssrModule\n  }\n\n  const ssrDynamicImport = (dep: string) => {\n    // #3087 dynamic import vars is ignored at rewrite import path,\n    // so here need process relative path\n    if (dep[0] === '.') {\n      dep = path.posix.resolve(path.dirname(url), dep)\n    }\n    return ssrImport(dep)\n  }\n\n  function ssrExportAll(sourceModule: any) {\n    for (const key in sourceModule) {\n      if (key !== 'default') {\n        Object.defineProperty(ssrModule, key, {\n          enumerable: true,\n          configurable: true,\n          get() {\n            return sourceModule[key]\n          }\n        })\n      }\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  const AsyncFunction = async function () {}.constructor as typeof Function\n  const initModule = new AsyncFunction(\n    `global`,\n    ssrModuleExportsKey,\n    ssrImportMetaKey,\n    ssrImportKey,\n    ssrDynamicImportKey,\n    ssrExportAllKey,\n    result.code + `\\n//# sourceURL=${mod.url}`\n  )\n  await initModule(\n    context.global,\n    ssrModule,\n    ssrImportMeta,\n    ssrImport,\n    ssrDynamicImport,\n    ssrExportAll\n  )\n\n  return Object.freeze(ssrModule)\n}\n\n// rollup-style default import interop for cjs\nfunction proxyESM(mod: any) {\n  // This is the only sensible option when the exports object is a primitve\n  if (isPrimitive(mod)) return { default: mod }\n\n  let defaultExport = 'default' in mod ? mod.default : mod\n\n  if (!isPrimitive(defaultExport) && '__esModule' in defaultExport) {\n    mod = defaultExport\n    if ('default' in defaultExport) {\n      defaultExport = defaultExport.default\n    }\n  }\n\n  return new Proxy(mod, {\n    get(mod, prop) {\n      if (prop === 'default') return defaultExport\n      return mod[prop] ?? defaultExport?.[prop]\n    }\n  })\n}\n\nfunction isPrimitive(value: any) {\n  return !value || (typeof value !== 'object' && typeof value !== 'function')\n}\n"],"names":["Mime"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;;;;ACuBA;;;;AAKA;;;;AAKA;;;;;;;;;;;;;AAeA;AACA;;AAEA;;;AAIA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9BA;AACA;;;AAGA;;AAQA;AACA;;;;;;;;;;;;;;;;;;AAmBA;;;AAOA;;;AAMA;;;AAEE;AAEF;;;;;;;;AAcA;AAEA;;;;;;;;;;;;;AAgBA;AAEA;AACA;AAEA;;;;;;;;;;;;AAyBA;AAGA;;;AAIA;;;;;;AAOA;;;AAIA;;;;;;;;;;AAiBA;;;;;;;;;;AAUA;AAEA;AACA;;;;AAOA;AAQA;;;AAOA;;;;;;;;;;;;;;;AAkBA;AAEA;;;AAGA;;;;;;;;;;;;AAiBA;AAcA;;;;;;;;;;;;;;;;;;;;;;;AAsBA;;;AAIA;;;AAIA;;;;;;;;;;;;AAiBA;AAEA;AAEA;;;;AAKA;;;;;;;;;;;AAcA;;;;;;;;;;;;;;;;;;;;AAyBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4CA;AAaA;;;;;;;;;;;;;;AAaA;;;AAyCA;;;;;;;;;;;AAkBA;AAMA;;;;;;;;;;;;;;;;;;;;;;;AA8BA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CA;;;AAiDA;;;;AAMA;;;;;;;;;;;;;AC5mBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAA;AACA;AACA;AACA;AACA;IACA;;IChGA;;ACEA;IACA;;;ACYA;AACA;;AAIA;AAEA;AAIA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkGA;;;;;;;;AASA;;;;;;;;;;;;;;AAiBA;;;;;;;;AAYA;AAEA;;;;;;;;;;;;;;;;;;AAeA;;;;AAOA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0EA;AAEA;;;;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuEA;;;AAIA;;AC1VA;;ACAA;;ACqFA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAuBA;;;AAeA;AAKA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyHA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmQA;AAQA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CA;AAEA;;AAIA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgNA;AAOA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA;AAMA;AACA;;AAGA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA;AACA;AAEA;;;;;AAQA;AAEA;;;;;;AAWA;AACA;;;;;;;;;;;AAgBA;AAEA;;;;;;;;;;;AAaA;AAEA;AACA;AACA;AACA;;;AAGA;AAEA;;;;;;;;;;;;;;AAcA;AACA;AAsCA;AASA;;;;;;;;;;;;;;;;;;;;;;AAuBA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8DA;AAEA;;;;AAWA;;;;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiCA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCA;AAEA;;;AAGA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgEA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;AA6BA;AAEA;;;;;;;AAWA;AAEA;;;;;;;AAQA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtqCA;AASA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CA;AAEA;;;;AAMA;;AC9JA;;;;;;;;;ACgBA;AAGA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmCA;AAEA;;;;;;;;;AAcA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuCA;;;;;;;;;;;;;;;;;;;;AAuBA;AAEA;;;;;;;;;;;AAWA;;;;;;;;;;;;;;;;;;;AA8YA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAwDA;AAcA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;;;;;;;;;;;;;;;;;;;;AAgCA;AAEA;;;;;;;;;;;;;;;;;;;;;;;AAmCA;AAEA;;;;;;;;;AASA;AAEA;AAEA;;;;;;;AAYA;AAEA;;;;;;;;AAUA;AAEA;;;;;;;;;;;AAUA;AAEA;;AAEA;;ACpuBA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmCA;AAyDA;;;;;;;;;;;;;AAcA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;AAsBA;AAEA;;;;;;;;;;;;;;;;AAqBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7OA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoDA;;ACzFA;AACA;;AA4PA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6GA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoDA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoJA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiKA;AAEA;;;;AAMA;AAEA;;;;;;;;;;;;;AAkBA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyDA;AA8BA;;;;;;;;AAQA;;;;;;;;;;AAgBA;AAEA;;AAEA;AAEA;;;;;;AAMA;;AC14BA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiDA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0GA;;;;;;;;;;;;;AAiBA;AAEA;;;;;;;;;;AAQA;;;;;;;;;;;;ACxKA;AAEA;;;;;AAKA;;ACvCA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgmBA;;AC9jBA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkFA;AAEA;;;;;;;;;;AAUA;AAEA;;;AAIA;AACA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiSA;AAEA;;;;;;;;;;;;;;;;;;;;AA8BA;AAEA;;;;;;;AAOA;;;;;;;;;;;;;;;AAgBA;;;;;;;;;;;;;;;AAmBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChLA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrGA;AAeA;;;;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgHA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4DA;AAEA;AAGA;AAGA;;AAEA;AAEA;;;;;;;AAOA;AAEA;;;;;;;;;;;;;;;AAmBA;;AChdA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CA;;;;;;;;;;;;ACzBA;AAEA;;;;;;;AAMA;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;AA0CA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoFA;;AC/BA;;;;;;;;;;;;;AAoBA;;;;;;;;;;;;AC1GA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0IA;;;;;;;;;;;;;;;;;;;;;ACzJA;;;;;;;AAOA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACoQA;AAUA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6GA;AAEA;;;;;AAOA;;AChbA;;;AAEE;;;;;;;ACFF;;;;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoGA;;AC5GA;;;;;;;AA0BA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CA;;ACxBA;AAEA;AACA;AAEA;;AAEA;AAEA;;;;;AAKA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmgBA;AAEA;;;;AAIA;;;;;;;;;;;;;;;AAeA;AAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkGA;;AC1rBA;AACA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkDA;AAEA;;;;;;;AASA;;ACjEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC0FA;;AC2eA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CA;;;AAQA;;;AAOA;AAEA;;;;;;;AASA;AAEA;AACA;AACA;;;;;;;;AAUA;;;;;;;;;;;;;;;;AAkBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACppBA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6GA;AAEA;;;;;;;;;;;;;;;;;;;;AAmCA;;;;;;;;;;;;;;;;;;;AA0BA;;ACvRA;;;;;;;;;;;;;;;;AAgBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACiDA;;;;;;;;;;;;;;;;AClDA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC+LA;;;ACvMA;AAEA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmFA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAwDA;;;;;;;;;;AAiCA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2DA;AAEA;;;;;;;;;;;;;;AAcA;;ACvPA;AACA;;;;;;;;;;;;;;;;;;;;;AAoCA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuIA;AAEA;AACA;;;;;;;;;;;;;;;;;;;AAmBA;AAEA;;AAEA;;;;"}